{"helptext": ["", "    ===========================================================================", "    afni_proc.py        - generate a tcsh script for an AFNI process stream", "", "    Purpose: ~1~", "", "       This program is meant to create single subject processing scripts for", "       task, resting state or surface-based analyses.  The processing scripts", "       are written in the tcsh language.", "", "       The typical goal is to create volumes of aligned response magnitudes", "       (stimulus beta weights) to use as input for a group analysis.", "", "    Inputs (only EPI is required): ~1~", "", "       - anatomical dataset", "       - EPI time series datasets", "       - stimulus timing files", "       - processing and design decisions:", "           e.g. TRs to delete, blur size, censoring options, basis functions", "", "    Main outputs (many datasets are created): ~1~", "", "       - for task-based analysis: stats dataset (and anat_final)", "       - for resting-state analysis: errts datasets (\"cleaned up\" EPI)", "", "    Basic script outline: ~1~", "", "       - copy all inputs to new 'results' directory", "       - process data: e.g. despike,tshift/align/tlrc/volreg/blur/scale/regress", "       - leave all (well, most) results there, so user can review processing", "       - create @ss_review scripts to help user with basic quality control", "", "    The exact processing steps are controlled by the user, including which main", "    processing blocks to use, and their order.  See the 'DEFAULTS' section for", "    a description of the default options for each block.", "", "    The output script (when executed) would create a results directory, copy", "    input files into it, and perform all processing there.  So the user can", "    delete the results directory and modify/re-run the script at their whim.", "", "    Note that the user need not actually run the output script.  The user", "    should feel free to modify the script for their own evil purposes, or to", "    just compare the processing steps with those in their own scripts.  Also,", "    even if a user is writing their own processing scripts, it is a good idea", "    to get some independent confirmation of the processing, such as by using", "    afni_proc.py to compare the results on occasion.", "", "    The text interface can be accessed via the -ask_me option.  It invokes a", "    question & answer session, during which this program sets user options on", "    the fly.  The user may elect to enter some of the options on the command", "    line, even if using -ask_me.  See \"-ask_me EXAMPLES\", below.", "", "    ** However, -ask_me has not been touched in many years.  I suggest starting", "       with the 'modern' examples (for task/rest/surface), or by using the", "       uber_subject.py GUI (graphical user interface) to generate an initial", "       afni_proc.py command script.", "", "       See uber_subject.py -help (or just start the GUI) for details.", "", "    ==================================================", "    SECTIONS: order of sections in the \"afni_proc.py -help\" output ~1~", "", "        program introduction    : (above) basic overview of afni_proc.py", "        PROCESSING BLOCKS       : list of possible processing blocks", "        DEFAULTS                : basic default operations, per block", "        EXAMPLES                : various examples of running this program", "        NOTE sections           : details on various topics", "            GENERAL ANALYSIS NOTE, QUALITY CONTROL NOTE,", "            RESTING STATE NOTE, FREESURFER NOTE,", "            TIMING FILE NOTE, MASKING NOTE,", "            ANAT/EPI ALIGNMENT CASES NOTE, ANAT/EPI ALIGNMENT CORRECTIONS NOTE,", "            WARP TO TLRC NOTE,", "            RETROICOR NOTE, RUNS OF DIFFERENT LENGTHS NOTE,", "            SCRIPT EXECUTION NOTE", "        OPTIONS                 : desriptions of all program options", "            informational       : options to get quick info and quit", "            general execution   : options not specific to a processing block", "            block options       : specific to blocks, in default block order", "", "    ==================================================", "    PROCESSING BLOCKS (of the output script): ~1~", "", "    The output script will go through the following steps, unless the user", "    specifies otherwise.", "", "    automatic blocks (the tcsh script will always perform these): ~2~", "", "        setup       : check subject arg, set run list, create output dir, and", "                      copy stim files", "        tcat        : copy input datasets and remove unwanted initial TRs", "", "    default blocks (the user may skip these, or alter their order): ~2~", "", "        tshift      : slice timing alignment on volumes (default is -time 0)", "        volreg      : volume registration (default to third volume)", "        blur        : blur each volume (default is 4mm fwhm)", "        mask        : create a 'brain' mask from the EPI data (dilate 1 voxel)", "        scale       : scale each run mean to 100, for each voxel (max of 200)", "        regress     : regression analysis (default is GAM, peak 1, with motion", "                      params)", "", "    optional blocks (the default is to _not_ apply these blocks) ~2~", "", "        align       : align EPI anat anatomy (via align_epi_anat.py)", "        despike     : truncate spikes in each voxel's time series", "        empty       : placeholder for some user command (uses 3dTcat as sample)", "        ricor       : RETROICOR - removal of cardiac/respiratory regressors", "        tlrc        : warp anat to standard space", "", "    ==================================================", "    DEFAULTS: basic defaults for each block (blocks listed in default order) ~1~", "", "        A : denotes automatic block that is not a 'processing' option", "        D : denotes a default processing block (others must be requested)", "", "    A   setup:    - use 'SUBJ' for the subject id", "                        (option: -subj_id SUBJ)", "                  - create a t-shell script called 'proc_subj'", "                        (option: -script proc_subj)", "                  - use results directory 'SUBJ.results'", "                        (option: -out_dir SUBJ.results)", "", "    A   tcat:     - do not remove any of the first TRs", "", "        despike:  - NOTE: by default, this block is _not_ used", "                  - automasking is not done (requires -despike_mask)", "", "        ricor:    - NOTE: by default, this block is _not_ used", "                  - polort based on twice the actual run length", "                  - solver is OLSQ, not REML", "                  - do not remove any first TRs from the regressors", "", "    D   tshift:   - align slices to the beginning of the TR", "                  - use quintic interpolation for time series resampling", "                        (option: -tshift_interp -quintic)", "", "        align:    - align the anatomy to match the EPI", "                    (also required for the option of aligning EPI to anat)", "", "        tlrc:     - use TT_N27+tlrc as the base (-tlrc_base TT_N27+tlrc)", "                  - no additional suffix (-tlrc_suffix NONE)", "                  - use affine registration (no -tlrc_NL_warp)", "", "    D   volreg:   - align to third volume of first run, -zpad 1", "                        (option: -volreg_align_to third)", "                        (option: -volreg_zpad 1)", "                  - use cubic interpolation for volume resampling", "                        (option: -volreg_interp -cubic)", "                  - apply motion params as regressors across all runs at once", "                  - do not align EPI to anat", "                  - do not warp to standard space", "", "    D   blur:     - blur data using a 4 mm FWHM filter with 3dmerge", "                        (option: -blur_filter -1blur_fwhm)", "                        (option: -blur_size 4)", "                        (option: -blur_in_mask no)", "", "    D   mask:     - create a union of masks from 3dAutomask on each run", "                  - not applied in regression without -regress_apply_mask", "                  - if possible, create a subject anatomy mask", "                  - if possible, create a group anatomy mask (tlrc base)", "", "    D   scale:    - scale each voxel to mean of 100, clip values at 200", "", "    D   regress:  - use GAM regressor for each stim", "                        (option: -regress_basis)", "                  - compute the baseline polynomial degree, based on run length", "                        (e.g. option: -regress_polort 2)", "                  - do not censor large motion", "                  - output fit time series", "                  - output ideal curves for GAM/BLOCK regressors", "                  - output iresp curves for non-GAM/non-BLOCK regressors", "", "        empty:    - do nothing (just copy the data using 3dTcat)", "", "", "    ==================================================", "    EXAMPLES (options can be provided in any order): ~1~", "", "        Example 1. Minimum use. ~2~", "", "           Provide datasets and stim files (or stim_times files).  Note that a", "           dataset suffix (e.g. HEAD) must be used with wildcards, so that", "           datasets are not applied twice.  In this case, a stim_file with many", "           columns is given, where the script to changes it to stim_times files.", "", "                afni_proc.py -dsets epiRT*.HEAD              \\", "                             -regress_stim_files stims.1D", "", "           or without any wildcard, the .HEAD suffix is not needed:", "", "                afni_proc.py -dsets epiRT_r1+orig epiRT_r2+orig epiRT_r3+orig \\", "                             -regress_stim_files stims.1D", "", "     **************************************************************", "     *  New and improved!  Examples that apply to AFNI_data4.     *", "     *  (were quickly OLD and OBSOLETE, as we now use AFNI_data6) *", "     **************************************************************", "", "        The following examples can be run from the AFNI_data4 directory, and", "        are examples of how one might process the data for subject sb23.", "", "        Example 2. Very simple. ~2~", "", "        Use all defaults, except remove 3 TRs and use basis", "        function BLOCK(30,1).  The default basis function is GAM.", "", "                afni_proc.py -subj_id sb23.e2.simple                       \\", "                        -dsets sb23/epi_r??+orig.HEAD                      \\", "                        -tcat_remove_first_trs 3                           \\", "                        -regress_stim_times sb23/stim_files/blk_times.*.1D \\", "                        -regress_basis 'BLOCK(30,1)'", "", "        Example 3. (no longer) The current class example.  ~2~", "", "           Copy the anatomy into the results directory, register EPI data to", "           the last TR, specify stimulus labels, compute blur estimates, and", "           provide GLT options directly to 3dDeconvolve.  The GLTs will be", "           ignored after this, as they take up too many lines.", "", "                afni_proc.py -subj_id sb23.blk                             \\", "                        -dsets sb23/epi_r??+orig.HEAD                      \\", "                        -copy_anat sb23/sb23_mpra+orig                     \\", "                        -tcat_remove_first_trs 3                           \\", "                        -volreg_align_to last                              \\", "                        -regress_stim_times sb23/stim_files/blk_times.*.1D \\", "                        -regress_stim_labels tneg tpos tneu eneg epos      \\", "                                             eneu fneg fpos fneu           \\", "                        -regress_basis 'BLOCK(30,1)'                       \\", "                        -regress_opts_3dD                                  \\", "                            -gltsym 'SYM: +eneg -fneg'                     \\", "                            -glt_label 1 eneg_vs_fneg                      \\", "                            -gltsym 'SYM: 0.5*fneg 0.5*fpos -1.0*fneu'     \\", "                            -glt_label 2 face_contrast                     \\", "                            -gltsym 'SYM: tpos epos fpos -tneg -eneg -fneg'\\", "                            -glt_label 3 pos_vs_neg                        \\", "                        -regress_est_blur_epits                            \\", "                        -regress_est_blur_errts", "", "        Example 4. Similar to 3, but specify the processing blocks. ~2~", "", "           Adding despike and tlrc, and removing tshift.  Note that", "           the tlrc block is to run @auto_tlrc on the anat.  Ignore the GLTs.", "", "                afni_proc.py -subj_id sb23.e4.blocks                       \\", "                        -dsets sb23/epi_r??+orig.HEAD                      \\", "                        -blocks despike volreg blur mask scale regress tlrc\\", "                        -copy_anat sb23/sb23_mpra+orig                     \\", "                        -tcat_remove_first_trs 3                           \\", "                        -regress_stim_times sb23/stim_files/blk_times.*.1D \\", "                        -regress_stim_labels tneg tpos tneu eneg epos      \\", "                                             eneu fneg fpos fneu           \\", "                        -regress_basis 'BLOCK(30,1)'                       \\", "                        -regress_est_blur_epits                            \\", "                        -regress_est_blur_errts", "", "        Example 5a. RETROICOR, resting state data. ~2~", "", "           Assuming the class data is for resting-state and that we have the", "           appropriate slice-based regressors from RetroTS.py, apply the", "           despike and ricor processing blocks.  Note that '-do_block' is used", "           to add non-default blocks into their default positions.  Here the", "           'despike' and 'ricor' processing blocks would come before 'tshift'.", "", "           Remove 3 TRs from the ricor regressors to match the EPI data.  Also,", "           since degrees of freedom are not such a worry, regress the motion", "           parameters per-run (each run gets a separate set of 6 regressors).", "", "           The regression will use 81 basic regressors (all of \"no interest\"),", "           with 13 retroicor regressors being removed during pre-processing:", "", "                 27 baseline  regressors ( 3 per run * 9 runs)", "                 54 motion    regressors ( 6 per run * 9 runs)", "", "           To example #3, add -do_block, -ricor_* and -regress_motion_per_run.", "", "                afni_proc.py -subj_id sb23.e5a.ricor            \\", "                        -dsets sb23/epi_r??+orig.HEAD           \\", "                        -do_block despike ricor                 \\", "                        -tcat_remove_first_trs 3                \\", "                        -ricor_regs_nfirst 3                    \\", "                        -ricor_regs sb23/RICOR/r*.slibase.1D    \\", "                        -regress_motion_per_run", "", "           If tshift, blurring and masking are not desired, consider replacing", "           the -do_block option with an explicit list of blocks:", "", "                -blocks despike ricor volreg regress", "", "        Example 5b. RETROICOR, while running a normal regression. ~2~", "", "           Add the ricor regressors to a normal regression-based processing", "           stream.  Apply the RETROICOR regressors across runs (so using 13", "           concatenated regressors, not 13*9).  Note that concatenation is", "           normally done with the motion regressors too.", "", "           To example #3, add -do_block and three -ricor options.", "", "                afni_proc.py -subj_id sb23.e5b.ricor                       \\", "                        -dsets sb23/epi_r??+orig.HEAD                      \\", "                        -do_block despike ricor                            \\", "                        -copy_anat sb23/sb23_mpra+orig                     \\", "                        -tcat_remove_first_trs 3                           \\", "                        -ricor_regs_nfirst 3                               \\", "                        -ricor_regs sb23/RICOR/r*.slibase.1D               \\", "                        -ricor_regress_method 'across-runs'                \\", "                        -volreg_align_to last                              \\", "                        -regress_stim_times sb23/stim_files/blk_times.*.1D \\", "                        -regress_stim_labels tneg tpos tneu eneg epos      \\", "                                             eneu fneg fpos fneu           \\", "                        -regress_basis 'BLOCK(30,1)'                       \\", "                        -regress_est_blur_epits                            \\", "                        -regress_est_blur_errts", "", "           Also consider adding -regress_bandpass.", "", "        Example 5c. RETROICOR (modern): censor and band pass. ~2~", "", "           This is an example of how we might currently suggest analyzing", "           resting state data.  If no RICOR regressors exist, see example 9", "           (or just remove any ricor options).", "", "           Censoring due to motion has long been considered appropriate in", "           BOLD FMRI analysis, but is less common for those doing bandpass", "           filtering in RS FMRI because the FFT requires one to either break", "           the time axis (evil) or to replace the censored data with something", "           probably inappropriate.", "", "           Instead, it is slow (no FFT, but maybe SFT :) but effective to", "           regress frequencies within the regression model, where censoring", "           is simple.", "", "           Note: band passing in the face of RETROICOR is questionable.  It may", "                 be questionable in general.  To skip bandpassing, remove the", "                 -regress_bandpass option line.", "", "           Also, align EPI to anat and warp to standard space.", "", "                afni_proc.py -subj_id sb23.e5a.ricor            \\", "                        -dsets sb23/epi_r??+orig.HEAD           \\", "                        -blocks despike ricor tshift align tlrc \\", "                                volreg blur mask regress        \\", "                        -copy_anat sb23/sb23_mpra+orig          \\", "                        -tcat_remove_first_trs 3                \\", "                        -ricor_regs_nfirst 3                    \\", "                        -ricor_regs sb23/RICOR/r*.slibase.1D    \\", "                        -volreg_align_e2a                       \\", "                        -volreg_tlrc_warp                       \\", "                        -blur_size 6                            \\", "                        -regress_motion_per_run                 \\", "                        -regress_censor_motion 0.2              \\", "                        -regress_bandpass 0.01 0.1              \\", "                        -regress_apply_mot_types demean deriv   \\", "                        -regress_run_clustsim no                \\", "                        -regress_est_blur_epits                 \\", "                        -regress_est_blur_errts", "", "        Example 6. A modern example.  GOOD TO CONSIDER. ~2~", "", "           Align the EPI to the anatomy.  Also, process in MNI space, using", "           the 2009c non-linear template.", "", "           For alignment in either direction, add the 'align' block, which", "           aligns the anatomy to the EPI.  To then align the EPI to the anat", "           using the lpc+ZZ cost function (instead of just lpc), apply", "           -volreg_align_e2a, where that transform (inverse) is applied along", "           with the motion alignment.", "", "           On top of that, complete the processing in standard space by running", "           @auto_tlrc on the anat (via the 'tlrc' block) and applying the same", "           transformation to the EPI via -volreg_tlrc_warp.  Again, the EPI", "           transformation is applied along with the motion alignment, using", "           the volume with the minimum outlier fraction as the alignment base", "           (option '-volreg_align_to MIN_OUTLIER').", "", "           So use the given -blocks option, plus 2 extra volreg warps to #3 via", "           '-volreg_align_e2a', '-volreg_tlrc_warp'.", "", "           As an added bonus, censor TR pairs where the Euclidean Norm of the", "           motion derivative exceeds 0.3.  Also, regress motion parameters", "           separately for each run.", "", "                afni_proc.py -subj_id sb23.e6.align                        \\", "                        -copy_anat sb23/sb23_mpra+orig                     \\", "                        -dsets sb23/epi_r??+orig.HEAD                      \\", "                        -blocks tshift align tlrc volreg blur mask         \\", "                                scale regress                              \\", "                        -tcat_remove_first_trs 3                           \\", "                        -align_opts_aea -cost lpc+ZZ                       \\", "                        -tlrc_base MNI152_T1_2009c+tlrc                    \\", "                        -volreg_align_to MIN_OUTLIER                       \\", "                        -volreg_align_e2a                                  \\", "                        -volreg_tlrc_warp                                  \\", "                        -regress_stim_times sb23/stim_files/blk_times.*.1D \\", "                        -regress_stim_labels tneg tpos tneu eneg epos      \\", "                                             eneu fneg fpos fneu           \\", "                        -regress_basis 'BLOCK(30,1)'                       \\", "                        -regress_motion_per_run                            \\", "                        -regress_censor_motion 0.3                         \\", "                        -regress_reml_exec                                 \\", "                        -regress_opts_3dD                                  \\", "                            -gltsym 'SYM: +eneg -fneg'                     \\", "                            -glt_label 1 eneg_vs_fneg                      \\", "                        -regress_est_blur_epits                            \\", "                        -regress_est_blur_errts", "", "           To process in orig space, remove -volreg_tlrc_warp.", "           To apply manual tlrc transformation, use -volreg_tlrc_adwarp.", "           To process as anat aligned to EPI, remove -volreg_align_e2a.", "", "         * Also, one can use ANATICOR with task (-regress_anaticor_fast, say)", "           in the case of -reml_exec.", "", "        Example 7. Similar to 6, but get a little more esoteric. ~2~", "", "           a. Register EPI volumes to the one which has the minimum outlier", "              fraction (so hopefully the least motion), still with cost lpc+ZZ.", "", "           b. Blur only within the brain, as far as an automask can tell.  So", "              add -blur_in_automask to blur only within an automatic mask", "              created internally by 3dBlurInMask (akin to 3dAutomask).", "", "           c. Let the basis functions vary.  For some reason, we expect the", "              BOLD responses to the telephone classes to vary across the brain.", "              So we have decided to use TENT functions there.  Since the TR is", "              3.0s and we might expect up to a 45 second BOLD response curve,", "              use 'TENT(0,45,16)' for those first 3 out of 9 basis functions.", "", "              This means using -regress_basis_multi instead of -regress_basis,", "              and specifying all 9 basis functions appropriately.", "", "           d. Use amplitude modulation.", "", "              We expect responses to email stimuli to vary proportionally with", "              the number of punctuation characters used in the message (in", "              certain brain regions).  So we will use those values as auxiliary", "              parameters 3dDeconvolve by marrying the parameters to the stim", "              times (using 1dMarry).", "", "              Use -regress_stim_types to specify that the epos/eneg/eneu stim", "              classes should be passed to 3dDeconvolve using -stim_times_AM2.", "", "           e. Not only censor motion, but censor TRs when more than 10% of the", "              automasked brain are outliers.  So add -regress_censor_outliers.", "", "           f. Include both de-meaned and derivatives of motion parameters in", "              the regression.  So add '-regress_apply_mot_types demean deriv'.", "", "           g. Output baseline parameters so we can see the effect of motion.", "              So add -bout under option -regress_opts_3dD.", "", "           h. Save on RAM by computing the fitts only after 3dDeconvolve.", "              So add -regress_compute_fitts.", "", "           i. Speed things up.  Have 3dDeconvolve use 4 CPUs and skip the", "              single subject 3dClustSim execution.  So add '-jobs 4' to the", "              -regress_opts_3dD option and add '-regress_run_clustsim no'.", "", "                afni_proc.py -subj_id sb23.e7.esoteric                     \\", "                        -dsets sb23/epi_r??+orig.HEAD                      \\", "                        -blocks tshift align tlrc volreg blur mask         \\", "                                scale regress                              \\", "                        -copy_anat sb23/sb23_mpra+orig                     \\", "                        -tcat_remove_first_trs 3                           \\", "                        -align_opts_aea -cost lpc+ZZ                       \\", "                        -volreg_align_to MIN_OUTLIER                       \\", "                        -volreg_align_e2a                                  \\", "                        -volreg_tlrc_warp                                  \\", "                        -blur_in_automask                                  \\", "                        -regress_stim_times sb23/stim_files/blk_times.*.1D \\", "                        -regress_stim_types times times times              \\", "                                            AM2   AM2   AM2                \\", "                                            times times times              \\", "                        -regress_stim_labels tneg tpos tneu                \\", "                                             eneg epos eneu                \\", "                                             fneg fpos fneu                \\", "                        -regress_basis_multi                               \\", "                           'BLOCK(30,1)' 'TENT(0,45,16)' 'BLOCK(30,1)'     \\", "                           'BLOCK(30,1)' 'TENT(0,45,16)' 'BLOCK(30,1)'     \\", "                           'BLOCK(30,1)' 'TENT(0,45,16)' 'BLOCK(30,1)'     \\", "                        -regress_apply_mot_types demean deriv              \\", "                        -regress_motion_per_run                            \\", "                        -regress_censor_motion 0.3                         \\", "                        -regress_censor_outliers 0.1                       \\", "                        -regress_compute_fitts                             \\", "                        -regress_opts_3dD                                  \\", "                            -bout                                          \\", "                            -gltsym 'SYM: +eneg -fneg'                     \\", "                            -glt_label 1 eneg_vs_fneg                      \\", "                            -jobs 4                                        \\", "                        -regress_run_clustsim no                           \\", "                        -regress_est_blur_epits                            \\", "                        -regress_est_blur_errts", "", "        Example 8. Surface-based analysis. ~2~", "", "           This example is intended to be run from AFNI_data6/FT_analysis.", "           It is provided with the class data in file s03.ap.surface.", "", "           Add -surf_spec and -surf_anat to provide the required spec and", "           surface volume datasets.  The surface volume will be aligned to", "           the current anatomy in the processing script.  Two spec files", "           (lh and rh) are provided, one for each hemisphere (via wildcard).", "", "           Also, specify a (resulting) 6 mm FWHM blur via -blur_size.  This", "           does not add a blur, but specifies a resulting blur level.  So", "           6 mm can be given directly for correction for multiple comparisons", "           on the surface.", "", "           Censor per-TR motion above 0.3 mm.", "", "           Note that no -regress_est_blur_errts option is given, since that", "           applies to the volume only (and since the 6 mm blur is a resulting", "           blur level, so the estimates are not needed).", "", "           The -blocks option is provided, but it is the same as the default", "           for surface-based analysis, so is not really needed here.  Note that", "           the 'surf' block is added and the 'mask' block is removed from the", "           volume-based defaults.", "", "           important options:", "", "                -blocks         : includes surf, but no mask", "                                  (default blocks for surf, so not needed)", "                -surf_anat      : volume aligned with surface", "                -surf_spec      : spec file(s) for surface", "", "           Note: one would probably want to use standard mesh surfaces here.", "                 This example will be updated with them in the future.", "", "                afni_proc.py -subj_id FT.surf                            \\", "                    -blocks tshift align volreg surf blur scale regress  \\", "                    -copy_anat FT/FT_anat+orig                           \\", "                    -dsets FT/FT_epi_r?+orig.HEAD                        \\", "                    -surf_anat FT/SUMA/FTmb_SurfVol+orig                 \\", "                    -surf_spec FT/SUMA/FTmb_?h.spec                      \\", "                    -tcat_remove_first_trs 2                             \\", "                    -align_opts_aea -cost lpc+ZZ                         \\", "                    -volreg_align_to third                               \\", "                    -volreg_align_e2a                                    \\", "                    -blur_size 6                                         \\", "                    -regress_stim_times FT/AV1_vis.txt FT/AV2_aud.txt    \\", "                    -regress_stim_labels vis aud                         \\", "                    -regress_basis 'BLOCK(20,1)'                         \\", "                    -regress_motion_per_run                              \\", "                    -regress_censor_motion 0.3                           \\", "                    -regress_opts_3dD                                    \\", "                        -jobs 2                                          \\", "                        -gltsym 'SYM: vis -aud' -glt_label 1 V-A", "", "        Example 9. Resting state analysis (modern): ~2~", "", "           With censoring and bandpass filtering.", "", "           This is our suggested way to do pre-processing for resting state", "           analysis, under the assumption that no cardio/physio recordings", "           were made (see example 5 for cardio files).", "", "           Censoring due to motion has long been considered appropriate in", "           BOLD FMRI analysis, but is less common for those doing bandpass", "           filtering in RS FMRI because the FFT requires one to either break", "           the time axis (evil) or to replace the censored data with something", "           probably inappropriate.", "", "           Instead, it is slow (no FFT, but maybe SFT :) but effective to", "           regress frequencies within the regression model, where censoring", "           is simple.", "", "           inputs: anat, EPI", "           output: errts dataset (to be used for correlation)", "", "           special processing:", "              - despike, as another way to reduce motion effect", "                 (see block despike)", "              - censor motion TRs at the same time as bandpassing data", "                 (see -regress_censor_motion, -regress_bandpass)", "              - regress motion parameters AND derivatives", "                 (see -regress_apply_mot_types)", "", "           Note: for resting state data, a more strict threshold may be a good", "                 idea, since motion artifacts should play a bigger role than in", "                 a task-based analysis.", "", "                 So the typical suggestion of motion censoring at 0.3 for task", "                 based analysis has been changed to 0.2 for this resting state", "                 example, and censoring of outliers has also been added.", "", "                 Outliers are typically due to motion, and may capture motion", "                 in some cases where the motion parameters do not, because", "                 motion is not generally a whole-brain-between-TRs event.", "", "           Note: if regressing out regions of interest, either create the ROI", "                 time series before the blur step, or remove blur from the list", "                 of blocks (and apply any desired blur after the regression).", "", "           Note: it might be reasonable to estimate the blur using epits rather", "                 than errts in the case of bandpassing.  Both options are", "                 included here.", "", "           Note: scaling is optional here.  While scaling has no direct effect", "                 on voxel correlations, it does have an effect on ROI averages", "                 used for correlations.", "", "           Other options to consider: -tlrc_NL_warp, -anat_uniform_method", "", "                afni_proc.py -subj_id subj123                                \\", "                  -dsets epi_run1+orig.HEAD                                  \\", "                  -copy_anat anat+orig                                       \\", "                  -blocks despike tshift align tlrc volreg blur mask regress \\", "                  -tcat_remove_first_trs 3                                   \\", "                  -volreg_align_e2a                                          \\", "                  -volreg_tlrc_warp                                          \\", "                  -regress_censor_motion 0.2                                 \\", "                  -regress_censor_outliers 0.1                               \\", "                  -regress_bandpass 0.01 0.1                                 \\", "                  -regress_apply_mot_types demean deriv                      \\", "                  -regress_est_blur_epits                                    \\", "                  -regress_est_blur_errts", "", "       Example 9b. Resting state analysis with ANATICOR. ~2~", "", "           Like example #9, but also regress out the signal from locally", "           averaged white matter.  The only change is adding the option", "           -regress_anaticor.", "", "           Note that -regress_anaticor implies options -mask_segment_anat and", "           -mask_segment_erode.", "", "                afni_proc.py -subj_id subj123                                \\", "                  -dsets epi_run1+orig.HEAD                                  \\", "                  -copy_anat anat+orig                                       \\", "                  -blocks despike tshift align tlrc volreg blur mask regress \\", "                  -tcat_remove_first_trs 3                                   \\", "                  -volreg_align_e2a                                          \\", "                  -volreg_tlrc_warp                                          \\", "                  -regress_anaticor                                          \\", "                  -regress_censor_motion 0.2                                 \\", "                  -regress_censor_outliers 0.1                               \\", "                  -regress_bandpass 0.01 0.1                                 \\", "                  -regress_apply_mot_types demean deriv                      \\", "                  -regress_est_blur_epits                                    \\", "                  -regress_est_blur_errts", "", "       Example 10. Resting state analysis, with tissue-based regressors. ~2~", "", "           Like example #9, but also regress the eroded white matter averages.", "           The WMe mask come from the Classes dataset, created by 3dSeg via the", "           -mask_segment_anat and -mask_segment_erode options.", "", "        ** While -mask_segment_anat also creates a CSF mask, that mask is ALL", "           CSF, not just restricted to the ventricles, for example.  So it is", "           probably not appropriate for use in tissue-based regression.", "", "           CSFe was previously used as an example of what one could do, but as", "           it is not advised, it has been removed.", "", "           Also, align to minimum outlier volume, and align to the anatomy", "           using cost function lpc+ZZ.", "", "           Note: it might be reasonable to estimate the blur using epits rather", "                 than errts in the case of bandpassing.  Both options are", "                 included here.", "", "                afni_proc.py -subj_id subj123                                \\", "                  -dsets epi_run1+orig.HEAD                                  \\", "                  -copy_anat anat+orig                                       \\", "                  -blocks despike tshift align tlrc volreg blur mask regress \\", "                  -tcat_remove_first_trs 3                                   \\", "                  -align_opts_aea -cost lpc+ZZ                               \\", "                  -volreg_align_to MIN_OUTLIER                               \\", "                  -volreg_align_e2a                                          \\", "                  -volreg_tlrc_warp                                          \\", "                  -mask_segment_anat yes                                     \\", "                  -mask_segment_erode yes                                    \\", "                  -regress_censor_motion 0.2                                 \\", "                  -regress_censor_outliers 0.1                               \\", "                  -regress_bandpass 0.01 0.1                                 \\", "                  -regress_apply_mot_types demean deriv                      \\", "                  -regress_ROI WMe                                           \\", "                  -regress_est_blur_epits                                    \\", "                  -regress_est_blur_errts", "", "       Example 10b. Resting state analysis, as 10a with 3dRSFC. ~2~", "", "            This is for band passing and computation of ALFF, etc.", "", "          * This will soon use a modified 3dRSFC.", "", "            Like example #10, but add -regress_RSFC to bandpass via 3dRSFC.", "            Skip censoring and regression band passing because of the bandpass", "            operation in 3dRSFC.", "", "            To correspond to common tractography, this example stays in orig", "            space (no 'tlrc' block, no -volreg_tlrc_warp option).  Of course,", "            going to standard space is an option.", "", "                afni_proc.py -subj_id subj123                                \\", "                  -dsets epi_run1+orig.HEAD                                  \\", "                  -copy_anat anat+orig                                       \\", "                  -blocks despike tshift align volreg blur mask regress      \\", "                  -tcat_remove_first_trs 3                                   \\", "                  -volreg_align_e2a                                          \\", "                  -blur_size 6.0                                             \\", "                  -mask_apply epi                                            \\", "                  -mask_segment_anat yes                                     \\", "                  -mask_segment_erode yes                                    \\", "                  -regress_bandpass 0.01 0.1                                 \\", "                  -regress_apply_mot_types demean deriv                      \\", "                  -regress_ROI WMe                                           \\", "                  -regress_RSFC                                              \\", "                  -regress_run_clustsim no                                   \\", "                  -regress_est_blur_errts", "", "       Example 11. Resting state analysis (now even more modern :). ~2~", "", "         o Yes, censor (outliers and motion) and despike.", "         o Align the anatomy and EPI using the lpc+ZZ cost function, rather", "           than the default lpc one.", "         o Register EPI volumes to the one which has the minimum outlier", "              fraction (so hopefully the least motion).", "         o Use non-linear registration to MNI template (non-linear 2009c).", "           * This adds a lot of processing time.", "         o No bandpassing.", "         o Use fast ANATICOR method (slightly different from default ANATICOR).", "         o Use FreeSurfer segmentation for:", "             - regression of first 3 principal components of lateral ventricles", "             - ANATICOR white matter mask (for local white matter regression)", "           * For details on how these masks were created, see \"FREESURFER NOTE\"", "             in the help, as it refers to this \"Example 11\".", "         o Input anat is from FreeSurfer (meaning it is aligned with FS masks).", "             - output from FS is usually not quite aligned with input", "         o Erode FS white matter and ventricle masks before application.", "         o Bring along FreeSurfer parcellation datasets:", "             - aaseg : NN interpolated onto the anatomical grid", "             - aeseg : NN interpolated onto the EPI        grid", "           * These 'aseg' follower datasets are just for visualization,", "             they are not actually required for the analysis.", "         o Compute average correlation volumes of the errts against the", "           the gray matter (aeseg) and ventricle (FSVent) masks.", "", "           Note: it might be reasonable to use either set of blur estimates", "                 here (from epits or errts).  The epits (uncleaned) dataset", "                 has all of the noise (though what should be considered noise", "                 in this context is not clear), while the errts is motion", "                 censored.  For consistency in resting state, it would be", "                 reasonable to stick with epits.  They will likely be almost", "                 identical.", "", "", "                afni_proc.py -subj_id FT.11.rest                             \\", "                  -blocks despike tshift align tlrc volreg blur mask regress \\", "                  -copy_anat FT_SurfVol.nii                                  \\", "                  -anat_follower_ROI aaseg anat aparc.a2009s+aseg.nii        \\", "                  -anat_follower_ROI aeseg epi  aparc.a2009s+aseg.nii        \\", "                  -anat_follower_ROI FSvent epi FT_vent.nii                  \\", "                  -anat_follower_ROI FSWe epi FT_white.nii                   \\", "                  -anat_follower_erode FSvent FSWe                           \\", "                  -dsets FT_epi_r?+orig.HEAD                                 \\", "                  -tcat_remove_first_trs 2                                   \\", "                  -align_opts_aea -cost lpc+ZZ                               \\", "                  -tlrc_base MNI152_T1_2009c+tlrc                            \\", "                  -tlrc_NL_warp                                              \\", "                  -volreg_align_to MIN_OUTLIER                               \\", "                  -volreg_align_e2a                                          \\", "                  -volreg_tlrc_warp                                          \\", "                  -regress_motion_per_run                                    \\", "                  -regress_ROI_PC FSvent 3                                   \\", "                  -regress_make_corr_vols aeseg FSvent                       \\", "                  -regress_anaticor_fast                                     \\", "                  -regress_anaticor_label FSWe                               \\", "                  -regress_censor_motion 0.2                                 \\", "                  -regress_censor_outliers 0.1                               \\", "                  -regress_apply_mot_types demean deriv                      \\", "                  -regress_est_blur_epits                                    \\", "                  -regress_est_blur_errts", "", "       Example 11b. Similar to 11, but without FreeSurfer. ~2~", "", "         AFNI currently does not have a good program to extract ventricles.", "         But it can make a CSF mask that includes them.  So without FreeSurfer,", "         one could import a ventricle mask from the template (e.g. for TT space,", "         using TT_desai_dd_mpm+tlrc).  For example, assume Talairach space for", "         the analysis, create a ventricle mask as follows:", "", "                3dcalc -a ~/abin/TT_desai_dd_mpm+tlrc                       \\", "                       -expr 'amongst(a,152,170)' -prefix template_ventricle", "                3dresample -dxyz 2.5 2.5 2.5 -inset template_ventricle+tlrc \\", "                       -prefix template_ventricle_2.5mm", "", "         o Be explicit with 2.5mm, using '-volreg_warp_dxyz 2.5'.", "         o Use template TT_N27+tlrc, to be aligned with the desai atlas.", "         o No -anat_follower options, but use -mask_import to import the", "           template_ventricle_2.5mm dataset (and call it Tvent).", "         o Use -mask_intersect to intersect ventricle mask with the subject's", "           CSFe mask, making a more reliable subject ventricle mask (Svent).", "         o Ventricle principle components are created as per-run regressors.", "         o Make WMe and Svent correlation volumes, which are just for", "           entertainment purposes anyway.", "         o Run the cluster simulation.", "", "                afni_proc.py -subj_id FT.11b.rest                            \\", "                  -blocks despike tshift align tlrc volreg blur mask regress \\", "                  -copy_anat FT_anat+orig                                    \\", "                  -dsets FT_epi_r?+orig.HEAD                                 \\", "                  -tcat_remove_first_trs 2                                   \\", "                  -align_opts_aea -cost lpc+ZZ                               \\", "                  -tlrc_base TT_N27+tlrc                                     \\", "                  -tlrc_NL_warp                                              \\", "                  -volreg_align_to MIN_OUTLIER                               \\", "                  -volreg_align_e2a                                          \\", "                  -volreg_tlrc_warp                                          \\", "                  -volreg_warp_dxyz 2.5                                      \\", "                  -mask_segment_anat yes                                     \\", "                  -mask_segment_erode yes                                    \\", "                  -mask_import Tvent template_ventricle_2.5mm+tlrc           \\", "                  -mask_intersect Svent CSFe Tvent                           \\", "                  -regress_motion_per_run                                    \\", "                  -regress_ROI_PC Svent 3                                    \\", "                  -regress_ROI_PC_per_run Svent                              \\", "                  -regress_make_corr_vols WMe Svent                          \\", "                  -regress_anaticor_fast                                     \\", "                  -regress_censor_motion 0.2                                 \\", "                  -regress_censor_outliers 0.1                               \\", "                  -regress_apply_mot_types demean deriv                      \\", "                  -regress_est_blur_epits                                    \\", "                  -regress_est_blur_errts                                    \\", "                  -regress_run_clustsim yes", "", "       Example 12 background: Multi-echo data processing. ~2~", "", "         Processing multi-echo data should be similar to single echo data,", "         except for perhaps:", "", "            combine         : the addition of a 'combine' block", "            -dsets_me_echo  : specify ME data, per echo", "            -dsets_me_run   : specify ME data, per run (alternative to _echo)", "            -echo_times     : specify echo times (if needed)", "            -combine_method : specify method to combine echoes (if any)", "", "         An afni_proc.py command might be updated to include something like:", "", "            afni_proc.py ...                                     \\", "                -blocks tshift align tlrc volreg mask combine    \\", "                        blur scale regress                       \\", "                -dsets_me_echo epi_run*_echo_01.nii              \\", "                -dsets_me_echo epi_run*_echo_02.nii              \\", "                -dsets_me_echo epi_run*_echo_03.nii              \\", "                -echo_times 15 30.5 41                           \\", "                ...                                              \\", "                -mask_epi_anat yes                               \\", "                -combine_method OC                               \\", "                ...                                              \\", "", "", "       Example 12a. Multi-echo data processing - very simple. ~2~", "", "         Keep it simple and just focus on the basic ME options, plus a few", "         for controlling registration.", "", "         o This example uses 3 echoes of data across just 1 run.", "            - so use a single -dsets_me_run option to input EPI datasets", "         o Echo 2 is used to drive registration for all echoes.", "            - That is the default, but it is good to be explicit.", "         o The echo times are not needed, as the echoes are never combined.", "         o The echo are never combined (in this example), so that there", "           are always 3 echoes, even until the end.", "            - Note that the 'regress' block is not valid for multiple echoes.", "", "                afni_proc.py -subj_id FT.12a.ME                 \\", "                  -blocks tshift align tlrc volreg mask blur    \\", "                  -copy_anat FT_anat+orig                       \\", "                  -dsets_me_run epi_run1_echo*.nii              \\", "                  -reg_echo 2                                   \\", "                  -tcat_remove_first_trs 2                      \\", "                  -volreg_align_to MIN_OUTLIER                  \\", "                  -volreg_align_e2a                             \\", "                  -volreg_tlrc_warp", "", "       Example 12b. Multi-echo data processing - OC resting state. ~2~", "", "         Still keep this simple, mostly focusing on ME options, plus standard", "         ones for resting state.", "", "         o This example uses 3 echoes of data across just 1 run.", "            - so use a single -dsets_me_run option to input EPI datasets", "         o Echo 2 is used to drive registration for all echoes.", "            - That is the default, but it is good to be explicit.", "         o The echoes are combined via the 'combine' block.", "         o So -echo_times is used to provided them.", "", "                afni_proc.py -subj_id FT.12a.ME                 \\", "                  -blocks tshift align tlrc volreg mask combine \\", "                          blur scale regress                    \\", "                  -copy_anat FT_anat+orig                       \\", "                  -dsets_me_run epi_run1_echo*.nii              \\", "                  -echo_times 15 30.5 41                        \\", "                  -reg_echo 2                                   \\", "                  -tcat_remove_first_trs 2                      \\", "                  -align_opts_aea -cost lpc+ZZ                  \\", "                  -tlrc_base MNI152_T1_2009c+tlrc               \\", "                  -tlrc_NL_warp                                 \\", "                  -volreg_align_to MIN_OUTLIER                  \\", "                  -volreg_align_e2a                             \\", "                  -volreg_tlrc_warp                             \\", "                  -mask_epi_anat yes                            \\", "                  -combine_method OC                            \\", "                  -regress_motion_per_run                       \\", "                  -regress_censor_motion 0.2                    \\", "                  -regress_censor_outliers 0.1                  \\", "                  -regress_apply_mot_types demean deriv         \\", "                  -regress_est_blur_epits", "", "       Example 12c. Multi-echo data processing - ME-ICA resting state. ~2~", "", "         As above, but run tedana.py for MEICA denoising.", "", "         o Since tedana.py will mask the data, it may be preferable to", "           blur only within that mask (-blur_in_mask yes).", "         o A task analysis using tedana might look much the same,", "           but with the extra -regress options for the tasks.", "", "                afni_proc.py -subj_id FT.12a.ME                 \\", "                  -blocks tshift align tlrc volreg mask combine \\", "                          blur scale regress                    \\", "                  -copy_anat FT_anat+orig                       \\", "                  -dsets_me_run epi_run1_echo*.nii              \\", "                  -echo_times 15 30.5 41                        \\", "                  -reg_echo 2                                   \\", "                  -tcat_remove_first_trs 2                      \\", "                  -align_opts_aea -cost lpc+ZZ                  \\", "                  -tlrc_base MNI152_T1_2009c+tlrc               \\", "                  -tlrc_NL_warp                                 \\", "                  -volreg_align_to MIN_OUTLIER                  \\", "                  -volreg_align_e2a                             \\", "                  -volreg_tlrc_warp                             \\", "                  -mask_epi_anat yes                            \\", "                  -combine_method tedana                        \\", "                  -blur_in_mask yes                             \\", "                  -regress_motion_per_run                       \\", "                  -regress_censor_motion 0.2                    \\", "                  -regress_censor_outliers 0.1                  \\", "                  -regress_apply_mot_types demean deriv         \\", "                  -regress_est_blur_epits", "", "         Consider an alternative combine method, 'tedana_OC_tedort'.", "", "    --------------------------------------------------", "    -ask_me EXAMPLES:  ** NOTE: -ask_me is antiquated ** ~2~", "", "        a1. Apply -ask_me in the most basic form, with no other options.", "", "                afni_proc.py -ask_me", "", "        a2. Supply input datasets.", "", "                afni_proc.py -ask_me -dsets ED/ED_r*.HEAD", "", "        a3. Same as a2, but supply the datasets in expanded form.", "            No suffix (.HEAD) is needed when wildcards are not used.", "", "                afni_proc.py -ask_me                          \\", "                     -dsets ED/ED_r01+orig ED/ED_r02+orig     \\", "                            ED/ED_r03+orig ED/ED_r04+orig     \\", "                            ED/ED_r05+orig ED/ED_r06+orig     \\", "                            ED/ED_r07+orig ED/ED_r08+orig     \\", "                            ED/ED_r09+orig ED/ED_r10+orig", "", "        a4. Supply datasets, stim_times files and labels.", "", "                afni_proc.py -ask_me                                    \\", "                        -dsets ED/ED_r*.HEAD                            \\", "                        -regress_stim_times misc_files/stim_times.*.1D  \\", "                        -regress_stim_labels ToolMovie HumanMovie       \\", "                                             ToolPoint HumanPoint", "", "", "", "    ==================================================", "    Many NOTE sections: ~1~", "    ==================================================", "", "    --------------------------------------------------", "    GENERAL ANALYSIS NOTE: ~2~", "", "    How might one run a full analysis?  Here are some details to consider.", "", "    0. Expect to re-run the full analysis.  This might be to fix a mistake, to", "       change applied options or to run with current software, to name a few", "       possibilities.  So...", "", "         - keep permanently stored input data separate from computed results", "           (one should be able to easily delete the results to start over)", "         - keep scripts in yet another location", "         - use file naming that is consistent across subjects and groups,", "           making it easy to script with", "", "    1. Script everything.  One should be able to carry out the full analysis", "       just by running the main scripts.", "", "       Learning is best done by typing commands and looking at data, including", "       the input to and output from said commands.  But running an analysis for", "       publication should not rely on typing complicated commands or pressing", "       buttons in a GUI (graphical user interface).", "", "         - it is easy to apply to new subjects", "         - the steps can be clear and unambiguous (no magic or black boxes)", "         - some scripts can be included with publication", "           (e.g. an afni_proc.py command, with the AFNI version)", "", "         - using a GUI relies on consistent button pressing, making it much", "           more difficult to *correctly* repeat, or even understand", "", "    2. Analyze and perform quality control on new subjects promptly.", "", "         - any problems with the acquisition would (hopefully) be caught early", "         - can compare basic quality control measures quickly", "", "    3. LOOK AT YOUR DATA.  Quality control is best done by researchers.", "       Software should not be simply trusted.", "", "         - afni_proc.py processing scripts write guiding @ss_review_driver", "           scripts for *minimal* per-subject quality control (i.e. at a", "           minimum, run that for every subject)", "         - initial subjects should be scrutinized (beyond @ss_review_driver)", "", "         - concatenate anat_final datasets to look for consistency", "         - concatenate final_epi datasets to look for consistency", "         - run gen_ss_review_table.py on the out.ss_review*.txt files", "           (making a spreadsheet to quickly scan for outlier subjects)", "", "         - many issues can be detected by software, buy those usually just come", "           as warnings to the researcher", "         - similarly, some issues will NOT be detected by the software", "         - for QC, software can assist the researcher, not replace them", "", "         NOTE: Data from external sites should be heavily scrutinized,", "               including any from well known public repositories.", "", "    4. Consider regular software updates, even as new subjects are acquired.", "       This ends up requiring a full re-analysis at the end.", "", "       If it will take a while (one year or more?) to collect data, update the", "       software regularly (weekly?  monthly?).  Otherwise, the analysis ends up", "       being done with old software.", "", "          - analysis is run with current, rather than old software", "          - will help detect changes in the software (good ones or bad ones)", "          - at a minimum, more quality control tools tend to show up", "          - keep a copy of the prior software version, in case comparisons are", "            desired (@update.afni.binaries does keep one prior version)", "          - the full analysis should be done with one software version, so once", "            all datasets are collected, back up the current analysis and re-run", "            the entire thing with the current software", "          - keep a snapshot of the software package used for the analysis", "          - report the software version in any publication", "", "    5. Here is a sample (tcsh) script that might run a basic analysis on", "       one or more subjects:", "", "       ======================================================================", "       sample analysis script ~3~", "       ======================================================================", "", "       #!/bin/tcsh", "", "       # --------------------------------------------------", "       # note fixed top-level directories", "       set data_root = /main/location/of/all/data", "", "       set input_root = $data_root/scanner_data", "       set output_root = $data_root/subject_analysis", "", "       # --------------------------------------------------", "       # get a list of subjects, or just use one (consider $argv)", "       cd $input root", "       set subjects = ( subj* )", "       cd -", "", "       # or perhaps just process one subject?", "       set subjects = ( subj_017 )", "", "", "       # --------------------------------------------------", "       # process all subjects", "       foreach subj_id ( $subjects )", "", "          # --------------------------------------------------", "          # note input and output directories", "          set subj_indir = $input_root/$subj_id", "          set subj_outdir = $output_root/$subj_id", "", "          # --------------------------------------------------", "          # if output dir exists, this subject has already been processed", "          if ( -d $subj_outdir ) then", "             echo \"** results dir already exists, skipping subject $subj_id\"", "             continue", "          endif", "", "          # --------------------------------------------------", "          # otherwise create the output directory, write an afni_proc.py", "          # command to it, and fire it up", "", "          mkdir -p $subj_outdir", "          cd $subj_outdir", "", "          # create a run.afni_proc script in this directory", "          cat > run.afni_proc << EOF", "", "          # notes:", "          #   - consider different named inputs (rather than OutBrick)", "          #   - verify how many time points to remove at start (using 5)", "          #   - note which template space is preferable (using MNI)", "          #   - consider non-linear alignment via -tlrc_NL_warp", "          #   - choose blur size (using FWHM = 4 mm)", "          #   - choose basis function (using BLOCK(2,1), for example)", "          #   - assuming 4 CPUs for linear regression", "          #   - afni_proc.py will actually run the proc script (-execute)", "", "", "          afni_proc.py -subj_id $subj_id                          \\", "              -blocks tshift align tlrc volreg blur mask regress  \\", "              -copy_anat $subj_indir/anat+orig                    \\", "              -dsets                                              \\", "                  $subj_indir/epi_r1+orig                         \\", "                  $subj_indir/epi_r2+orig                         \\", "                  $subj_indir/epi_r3+orig                         \\", "              -tcat_remove_first_trs 5                            \\", "              -align_opts_aea -cost lpc+ZZ                        \\", "              -tlrc_base MNI152_T1_2009c+tlrc                     \\", "              -tlrc_NL_warp                                       \\", "              -volreg_align_to MIN_OUTLIER                        \\", "              -volreg_align_e2a                                   \\", "              -volreg_tlrc_warp                                   \\", "              -blur_size 4.0                                      \\", "              -regress_motion_per_run                             \\", "              -regress_censor_motion 0.3                          \\", "              -regress_reml_exec -regress_3dD_stop                \\", "              -regress_stim_times                                 \\", "                  $stim_dir/houses.txt                            \\", "                  $stim_dir/faces.txt                             \\", "                  $stim_dir/doughnuts.txt                         \\", "                  $stim_dir/pizza.txt                             \\", "              -regress_stim_labels                                \\", "                  house face nuts za                              \\", "              -regress_basis 'BLOCK(2,1)'                         \\", "              -regress_opts_3dD                                   \\", "                  -jobs 4                                         \\", "                  -gltsym 'SYM: house -face' -glt_label 1 H-F     \\", "                  -gltsym 'SYM: nuts -za'    -glt_label 2 N-Z     \\", "              -regress_est_blur_errts                             \\", "              -execute", "", "          EOF", "          # EOF denotes the end of the run.afni_proc command", "", "          # now run the analysis (generate proc and execute)", "          tcsh run.afni_proc", "", "       # end loop over subjects", "       end", "", "       ======================================================================", "", "    --------------------------------------------------", "    QUALITY CONTROL NOTE: ~2~", "", "    Look at the data.", "", "    Nothing replaces a living human performing quality control checks by", "    looking at the data.  And the more a person looks at the data, the better", "    they get at spotting anomalies.", "", "    There are 2 types of QC support generated by afni_proc.py, scripts to help", "    someone review the data, and individual text or image files.", "", "        ----------------------------------------------------------------------", "        scripts (the user can run from the results directory):", "", "           @epi_review.FT               - view original (post-SS) EPI data", "           @ss_review_basic             - show basic QC measures, in text", "           @ss_review_driver            - minimum recommended QC review", "           @ss_review_driver_commands   - same, as pure commands", "", "           Notably, the @ss_review_driver script is recommended as the minimum", "           QC to perform on every subject.", "", "        ----------------------------------------------------------------------", "        other files or datasets:   (* shown or reviewed by @ss_review_driver)", "", "        *  3dDeconvolve.err", "", "              This contains any warnings (or errors) from 3dDeconvolve.  This", "              will be created even if 3dREMLfit is run.", "", "        *  anat_final.$subj", "", "              This AFNI dataset should be registered with the final stats", "              (including final_epi_vr_base) and with any applied template.", "              There is also a version with the skull, anat_w_skull_warped.", "", "        *  blur_est.$subj.1D", "", "              This (text) file has the mixed-model ACF (and possibly the FWHM)", "              parameter estimates of the blur.", "", "           Classes", "", "              If 3dSeg is run for anatomical segmentation, this AFNI dataset", "              contains the results, a set of masks per tissue class.  The", "              white matter mask from this might be used for ANATICOR, for", "              example.", "", "           corr_brain", "", "              This AFNI dataset shows the correlation of every voxel with the", "              global signal (brain average time series).", "", "              One can request other corr_* datasets, based on any tissue or ROI", "              mask.  See -regress_make_corr_vols for details.", "", "        *  dfile_rall.1D (and efile.r??.1D)", "", "              This contains the 6 estimated motion parameters across all runs.", "              These parameters are generally used as regressors of no interest,", "              hopefully per run.  They are also used to generate the enorm time", "              series, which is then used for censoring.", "", "           files_ACF", "", "              This directory contains ACF values at different radii per run.", "              One can plot them using something like:", "", "                set af = files_ACF/out.3dFWHMx.ACF.errts.r01.1D", "                1dplot -one -x $af'[0]' $af'[1,2,3]'", "", "        *  final_epi_vr_base", "", "              This dataset is of the EPI volume registration base (used by", "              3dvolreg), warped to the final space.  It should be in alignment", "              with the anat_final dataset (and the template).", "", "           fitts.$subj", "", "              This dataset contains the model fit to the time series data.", "              One can view these time series together in afni using the", "              Dataset #N plugin.", "", "           full_mask.$subj", "", "              This dataset is a brain mask based on the EPI data, generated", "              by 3dAutomask.  Though the default is to apply it as part of the", "              main regression, it is used for computations like ACF and TSNR.", "", "           ideal_*.1D", "", "              These time series text files are the ideal regressors of", "              interest, if appropriate to calculate.", "", "           mat.basewarp.aff12.1D", "", "              This is used to create the final_epi_vr_base dataset.", "", "              Assuming no non-linear registration (including distortion", "              correction), then this matrix holds the combined affine", "              transformation of the EPI to anat and to standard space,", "              as applied to the volume registration base (it does not contain", "              motion correction transformations).", "", "              Time series registration matrices that include motion correction", "              are in mat.r*.warp.aff12.1D (i.e. one file per run).", "", "              In the case of non-linear registration, there is no single file", "              representing the combined transformation, as it is computed just", "              to apply the transformation by 3dNwarpApply.  This command can be", "              found in the proc script or as the last HISTORY entry seen from", "              the output of \"3dinfo final_epi_vr_base\".", "", "        *  motion_${subj}_enorm.1D", "", "              This time series text file is the L2 (Euclidean) norm of the", "              first (backward) differences of the motion parameters.  The", "              values represent time point to time point estimated motion, and", "              they are used for censoring.  Values are zero at the beginning of", "              each run (motion is not computed across runs).", "", "              A high average of these numbers, particularly after the numbers", "              themselves are censored, is justification for dropping a subject.", "              This average is reported by the @ss_review scripts.", "", "           motion_${subj}_censor.1D", "", "              This is a binary 0/1 time series (matching enorm, say), that", "              distinguishes time points which would be censored (0) from those", "              which would not (1).  It is based on the enorm time series and", "              the -regress_censor_motion limit, with a default to censor in", "              pairs of time points.  There may be a combined censor file, if", "              outlier censoring is done (or if a user censor file is input).", "", "           motion_demean.1D", "", "              This is the same as dfile_rall.1D, the motion parameters as", "              estimated by 3dvolreg, except the the mean per run has been", "              removed.", "", "           motion_deriv.1D", "", "              This contains the first (backward) differences from either", "              motion_demean.1D or dfile_rall.1D.  Values are zero at the start", "              of each run.", "", "           out.allcostX.txt", "", "              This holds anat/EPI registration costs for all cost functions.", "              It might be informational to evaluate alignment across subjects", "              and cost functions.", "", "        *  out.cormat_warn.txt", "", "              This contains warnings about a high correlation between any pair", "              of regressors in the main regression matrix, including baseline", "              terms.", "", "        *  out.gcor.1D", "", "              This contains the global correlation, the average correlation", "              between every pair of voxels in the residual time series dataset.", "              This single value is reported by the @ss_review scripts.", "", "           out.mask_ae_dice.txt", "", "              This contains the Dice coefficient, evaluating the overlap", "              between the anatomical and EPI brain masks.", "", "           out.mask_ae_overlap.txt", "", "              This contains general output from 3dOverlap, for evaluating the", "              overlap between the anatomical and EPI brain masks.", "", "        *  out.pre_ss_warn.txt", "", "              This contains warnings about time point #0 in any run where it", "              might be a pre-steady state time point, based on outliers.", "", "        *  out.ss_review.txt", "", "              This is the text output from @ss_review_basic.  Aside from being", "              shown by the @ss_review scripts, it is useful for being compiled", "              across subjects via gen_ss_review_table.py.", "", "        *  outcount_rall.1D (and outcount.r??.1D)", "", "              This is a time series of the fraction of the brain that is an", "              outlier.  It can be used for censoring.", "", "        *  sum_ideal.1D", "", "              As suggested, this time series is the sum of all non-baseline", "              regressors.  It is generated from X.nocensor.xmat.1D if censoring", "              is done, and from X.xmat.1D otherwise.  This might help one find", "              mistakes in stimulus timing, for example.", "", "        *  TSNR_$subj", "", "              This AFNI dataset contains the voxelwise TSNR after regression.", "              The brainwise average is shown in @ss_review_basic.", "", "          X.xmat.1D", "", "              This is the complete regression matrix, created by 3dDeconvolve.", "              One can view it using 1dplot.  It contains all regressors except", "              for any voxelwise ones (e.g. for ANATICOR).", "", "          X.nocensor.xmat.1D", "", "              This is the same as X.xmat.1D, except the nothing is censored,", "              so all time points are present.", "", "        * X.stim.xmat.1D", "", "              This (text) file has the non-baseline regressors (so presumably", "              of interest), created by 3dDeconvolve.", "", "    --------------------------------------------------", "    RESTING STATE NOTE: ~2~", "", "    Resting state data should be processed with physio recordings (for typical", "    single-echo EPI data).  Without such recordings, bandpassing is currently", "    considered as the default.", "", "    Comment on bandpassing:", "", "        Bandpassing is the norm right now.  However most TRs may be too long", "        for this process to be able to remove the desired components of no", "        interest.  On the flip side, if the TRs are short, the vast majority", "        of the degrees of freedom are sacrificed just to do it.  Perhaps", "        bandpassing will eventually go away, but it is the norm right now.", "", "        Also, there is a danger with bandpassing and censoring in that subjects", "        with a lot of motion may run out of degrees of freedom (for baseline,", "        censoring, bandpassing and removal of other signals of no interest).", "        Many papers have been published where a lot of censoring was done,", "        many regressors of no interest were projected out, and there was a", "        separate bandpass operation.  It is likely that many subjects ended up", "        with negative degrees of freedom, making the resulting signals useless", "        (or worse, misleading garbage).  But without keeping track of it,", "        researchers may not even know.", "", "    Bandpassing and degrees of freedom:", "", "        Bandpassing between 0.01 and 0.1 means, from just the lowpass side,", "        throwing away frequencies above 0.1.  So the higher the frequency of", "        collected data (i.e. the smaller the TR), the higher the fraction of", "        DoF will be thrown away.", "", "        For example, if TR = 2s, then the Nyquist frequency (the highest", "        frequency detectable in the data) is 1/(2*2) = 0.25 Hz.  That is to", "        say, one could only detect something going up and down at a cycle rate", "        of once every 4 seconds (twice the TR).", "", "        So for TR = 2s, approximately 40% of the DoF are kept (0.1/0.25) and", "        60% are lost (frequencies from 0.1 to 0.25) due to bandpassing.", "", "        To generalize, Nyquist = 1/(2*TR), so the fraction of DoF kept is", "", "            fraction kept = 0.1/Nyquist = 0.1/(1/(2*TR)) = 0.1*2*TR = 0.2*TR", "", "        For example,", "", "            at TR = 2 s,   0.4  of DoF are kept (60% are lost)", "            at TR = 1 s,   0.2  of DoF are kept (80% are lost)", "            at TR = 0.5 s, 0.1  of DoF are kept (90% are lost)", "            at TR = 0.1 s, 0.02 of DoF are kept (98% are lost)", "", "        Consider also:", "", "            Shirer WR, Jiang H, Price CM, Ng B, Greicius MD", "            Optimization of rs-fMRI pre-processing for enhanced signal-noise", "                separation, test-retest reliability, and group discrimination", "            Neuroimage. 2015 Aug 15;117:67-79.", "", "            Gohel SR, Biswal BB", "            Functional integration between brain regions at rest occurs in", "                multiple-frequency bands", "            Brain connectivity. 2015 Feb 1;5(1):23-34.", "", "            Caballero-Gaudes C, Reynolds RC", "            Methods for cleaning the BOLD fMRI signal", "            Neuroimage. 2017 Jul 1;154:128-49", "", "    Application of bandpassing in afni_proc.py:", "", "        In afni_proc.py, this is all done in a single regression model (removal", "        of noise and baseline signals, bandpassing and censoring).  If some", "        subject were to lose too many TRs due to censoring, this step would", "        fail, as it should.", "", "        There is an additional option of using simulated motion time series", "        in the regression model, which should be more effective than higher", "        order motion parameters, say.  This is done via @simulate_motion.", "", "    There are 3 main steps (generate ricor regs, pre-process, group analysis):", "", "        step 0: If physio recordings were made, generate slice-based regressors", "                using RetroTS.py.  Such regressors can be used by afni_proc.py", "                via the 'ricor' processing block.", "", "                RetroTS.m is Ziad Saad's MATLAB routine to convert the 2 time", "                series into 13 slice-based regressors.  RetroTS.m requires the", "                signal processing toolkit for MATLAB.", "", "                RetroTS.py is a conversion of RetroTS.m to python by J Zosky,", "                which depends on scipy.  See \"RetroTS.py -help\" for details.", "", "        step 1: analyze with afni_proc.py", "", "                Consider these afni_proc.py -help examples:", "                   5b.  case of ricor and no bandpassing", "                   5c.  ricor and bandpassing and full registration", "                   9.   no ricor, but with bandpassing", "                   9b.  with WMeLocal (local white-matter, eroded) - ANATICOR", "                   10.  also with tissue-based regressors", "                   10b. apply bandpassing via 3dRSFC", "                   soon: extra motion regs via motion simulated time series", "                         (either locally or not)", "                   11.  censor, despike, non-linear registration,", "                        no bandpassing, fast ANATICOR regression,", "                        FreeSurfer masks for ventricle/WM regression", "                      * see \"FREESURFER NOTE\" for more details", "", "            processing blocks:", "", "                despike (shrink large spikes in time series)", "                ricor   (if applicable, remove the RetroTS regressors)", "                tshift  (correct for slice timing)", "                align   (figure out alignment between anat and EPI)", "                tlrc    (figure out alignment between anat and template)", "                volreg  (align anat and EPI together, and to standard template)", "                blur    (apply desired FWHM blur to EPI data)", "                scale   (optional, e.g. before seed averaging)", "                regress (polort, motion, mot deriv, bandpass, censor)", "                        (depending on chosen options)", "                        soon: ANATICOR/WMeLocal", "                              extra motion regressors (via motion simulation)", "", "                ==> \"result\" is errts dataset, \"cleaned\" of known noise sources", "", "        step 2: correlation analysis, hopefully with 3dGroupInCorr", "", "            The inputs to this stage are the single subject errts datasets.", "", "            Ignoring 3dGroupInCorr, the basic steps in a correlation analysis", "            (and corresponding programs) are as follows.  This may be helpful", "            for understanding the process, even when using 3dGroupInCorr.", "", "                a. choose a seed voxel (or many) and maybe a seed radius", "", "                for each subject:", "", "                   b. compute time series from seed", "                      (3dmaskave or 3dROIstats)", "                   c. generate correlation map from seed TS", "                      (3dTcorr1D (or 3dDeconvolve or 3dfim+))", "                   d. normalize R->\"Z-score\" via Fisher's z-transform", "                      (3dcalc -expr atanh)", "", "                e. perform group test, maybe with covariates", "                   (3dttest++: 1-sample, 2-sample or paired)", "", "            To play around with a single subject via InstaCorr:", "", "                a. start afni (maybe show images of both anat and EPI)", "                b. start InstaCorr plugin from menu at top right of afni's", "                   Define Overlay panel", "                c. Setup Icorr:", "                    c1. choose errts dataset", "                       (no Start,End; no Blur (already done in pre-processing))", "                    c2. Automask -> No; choose mask dataset: full_mask", "                    c3. turn off Bandpassing (already done, if desired)", "                d. in image window, show correlations", "                    d1. go to seed location, right-click, InstaCorr Set", "                    OR", "                    d1. hold ctrl-shift, hold left mouse button, drag", "                e. have endless fun", "", "            To use 3dGroupInCorr:", "", "                a. run 3dSetupGroupIncorr with mask, labels, subject datasets", "                   (run once per group of subjects), e.g.", "", "                        3dSetupGroupInCorr                \\", "                            -labels subj.ID.list.txt      \\", "                            -prefix sic.GROUP             \\", "                            -mask EPI_mask+tlrc           \\", "                            errts_subj1+tlrc              \\", "                            errts_subj2+tlrc              \\", "                            errts_subj3+tlrc              \\", "                                ...                       \\", "                            errts_subjN+tlrc", "", "                    ==> sic.GROUP.grpincorr.niml (and .grpincorr.data)", "", "                b. run 3dGroupInCorr on 1 or 2 sic.GROUP datasets, e.g.", "", "                   Here are steps for running 3dGroupInCorr via the afni GUI.", "                   To deal with computers that have multiple users, consider", "                   specifying some NIML port block that others are not using.", "                   Here we use port 2 (-npb 2), just to choose one.", "", "                   b1. start afni:", "", "                        afni -niml -npb 2", "", "                   b2. start 3dGroupInCorr", "", "                        3dGroupInCorr -npb 2                    \\", "                            -setA sic.horses.grpincorr.niml     \\", "                            -setB sic.moths.grpincorr.niml      \\", "                            -labelA horses -labelB moths        \\", "                            -covaries my.covariates.txt         \\", "                            -center SAME -donocov -seedrad 5", "", "                   b3. play with right-click -> InstaCorr Set or", "                      hold ctrl-shift/hold left mouse and drag slowly", "", "                   b4. maybe save any useful dataset via", "                      Define Datamode -> SaveAs OLay (and give a useful name)", "", "                b'. alternative, generate result dataset in batch mode, by", "                    adding -batch and some parameters to the 3dGIC command", "", "                    e.g.  -batch XYZAVE GIC.HvsM.PFC 4 55 26", "", "                    In such a case, afni is not needed at all.  The resulting", "                    GIC.HvsM.PFC+tlrc dataset would be written out without any", "                    need to start the afni GUI.  This works well since seed", "                    coordinates for group tests are generally known in advance.", "", "                    See the -batch option under \"3dGroupInCorr -help\" for many", "                    details and options.", "", "                c. threshold/clusterize resulting datasets, just as with a", "                   task analysis", "", "                   (afni GUI, 3dclust, or 3dmerge)", "", "    --------------------------------------------------", "    FREESURFER NOTE: ~2~", "", "    FreeSurfer output can be used for a few things in afni_proc.py:", "", "        - simple skull stripping (i.e. instead of 3dSkullStrip)", "        - running a surface-based analysis", "        - using parcellation datasets for:", "           - tissue-based regression", "           - creating group probability maps", "           - creating group atlases (e.g. maximum probability maps)", "", "    This NOTE mainly refers to using FreeSurfer parcellations for tissue-based", "    regression, as is done in Example 11.", "", "", "    First run FreeSurfer, then import to AFNI using @SUMA_Make_Spec_FS, then", "    make ventricle and white matter masks from the Desikan-Killiany atlas based", "    parcellation dataset, aparc+aseg.nii.", "", "    Note that the aparc.a2009s segmentations are based on the Destrieux atlas,", "    which might be nicer for probability maps, though the Desikan-Killiany", "    aparc+aseg segmentation is currently used for segmenting white matter and", "    ventricles.  I have not studied the differences.", "", "", "    Example 11 brings the aparc.a2009s+aseg segmentation along (for viewing or", "    atlas purposes, aligned with the result), though the white matter and", "    ventricle masks are based instead on aparc+aseg.nii.", "", "        # run (complete) FreeSurfer on FT.nii", "        recon-all -all -subject FT -i FT.nii", "", "        # import to AFNI, in NIFTI format", "        @SUMA_Make_Spec_FS -sid FT -NIFTI", "", "        # create ventricle and white matter masks", "        #", "        # ** warning: it would be good to convert these indices to labels", "        #             in case the output from FreeSurfer is changed", "", "        3dcalc -a aparc+aseg.nii -datum byte -prefix FT_vent.nii \\", "               -expr 'amongst(a,4,43)'", "        3dcalc -a aparc+aseg.nii -datum byte -prefix FT_WM.nii \\", "               -expr 'amongst(a,2,7,41,46,251,252,253,254,255)'", "", "        # note: 16 (brainstem) was incorrectly included from @ANATICOR", "        #       and then in this help through 2016", "", "    After this, FT_SurfVol.nii, FT_vent.nii and FT_WM.nii (along with the", "    basically unused aparc.a2009s+aseg.nii) are passed to afni_proc.py.", "", "", "  * Be aware that the output from FreeSurfer (e.g. FT_SurfVol.nii) will", "    usually not quite align with the input (e.g. FT.nii).  So parcellation", "    datasets will also not quite align with the input (FT.nii).  Therefore,", "    when passing parcellation volumes to afni_proc.py for tissue-based", "    regression, it is important to use the anatomy output from FreeSurfer", "    as the subject anatomy (input to afni_proc.py).  That way, the anatomy", "    and parcellation datasets will be in register, and therefore the EPI", "    will eventually align with the parcellation datasets.", "", "    If it is important to have the FreeSurfer output align with the input,", "    it might help to pass a modified volume to FreeSurfer.  Use 3dresample", "    and then 3dZeropad (if necessary) to make a volume with 1 mm^3 voxels", "    and an even number voxels in each direction.  The @SUMA_Make_Spec_FS", "    help provides some details on this.", "", "    The exact 3dZeropad command depends on the grid output by 3dresample.", "", "        3dresample -inset FT_anat+orig -dxyz 1 1 1 -prefix FT.1 -rmode Cu", "        3dZeropad -L 1 -prefix FT.1.z.nii FT.1+orig", "        recon-all -all -subject FT -i FT.1.z.nii", "        @SUMA_Make_Spec_FS -sid FT -NIFTI", "", "    --------------------------------------------------", "    TIMING FILE NOTE: ~2~", "", "    One issue that the user must be sure of is the timing of the stimulus", "    files (whether -regress_stim_files or -regress_stim_times is used).", "", "    The 'tcat' step will remove the number of pre-steady-state TRs that the", "    user specifies (defaulting to 0).  The stimulus files, provided by the", "    user, must match datasets that have had such TRs removed (i.e. the stim", "    files should start _after_ steady state has been reached).", "", "    --------------------------------------------------", "    MASKING NOTE: ~2~", "", "    The default operation of afni_proc.py has changed (as of 24 Mar, 2009).", "    Prior to that date, the default was to apply the 'epi' mask.  As of", "    17 Jun 2009, only the 'extents' mask is, if appropriate.", "", "    ---", "", "    There may be 4 masks created by default, 3 for user evaluation and all for", "    possible application to the EPI data (though it may not be recommended).", "    The 4th mask (extents) is a special one that will be applied at volreg when", "    appropriate, unless the user specifies otherwise.", "", "    If the user chooses to apply one of the masks to the EPI regression (again,", "    not necessarily recommended), it is done via the option -mask_apply while", "    providing the given mask type (epi, anat, group or extents).", "", "    --> To apply a mask during regression, use -mask_apply.", "", "    Mask descriptions (afni_proc.py name, dataset name, short description):", "", "    1. epi (\"full_mask\") : EPI Automask", "", "       An EPI mask dataset will be created by running '3dAutomask -dilate 1'", "       on the EPI data after blurring.  The 3dAutomask command is executed per", "       run, after which the masks are combined via a union operation.", "", "    2. anat (\"mask_anat.$subj\") : anatomical skull-stripped mask", "", "       If possible, a subject anatomy mask will be created.  This anatomical", "       mask will be created from the appropriate skull-stripped anatomy,", "       resampled to match the EPI (that is output by 3dvolreg) and changed into", "       a binary mask.", "", "       This requires either the 'align' block or a tlrc anatomy (from the", "       'tlrc' block, or just copied via '-copy_anat').  Basically, it requires", "       afni_proc.py to know of a skull-stripped anatomical dataset.", "", "       By default, if both the anat and EPI masks exist, the overlap between", "       them will be computed for evaluation.", "", "    3. group (\"mask_group\") : skull-stripped @auto_tlrc base", "", "       If possible, a group mask will be created.  This requires the 'tlrc'", "       block, from which the @auto_tlrc -base dataset is chosen as the group", "       anatomy.  It also requires '-volreg_warp_epi' so that the EPI is in", "       standard space.  The group anatomy is then resampled to match the EPI", "       and changed into a binary mask.", "", "    4. extents (\"mask_extents\") : mask based on warped EPI extents", "", "       In the case of transforming the EPI volumes to match the anatomical", "       volume (via either -volreg_align_e2a or -volreg_tlrc_warp), an extents", "       mask will be created.  This is to avoid a motion artifact that arises", "       when transforming from a smaller volume (EPI) to a larger one (anat).", "", "    ** Danger Will Robinson! **", "", "       This EPI extents mask is considered necessary because the align/warp", "       transformation that is applied on top of the volreg alignment transform", "       (applied at once), meaning the transformation from the EPI grid to the", "       anatomy grid will vary per TR.", "", "       The effect of this is seen at the edge voxels (extent edge), where a", "       time series could be zero for many of the TRs, but have valid data for", "       the rest of them.  If this timing just happens to correlate with any", "       regressor, the result could be a strong \"activation\" for that regressor,", "       but which would be just a motion based artifact.", "", "       What makes this particularly bad is that if it does happen, it tends to", "       happen for *a cluster* of many voxels at once, possibly an entire slice.", "       Such an effect is compounded by any additional blur.  The result can be", "       an entire cluster of false activation, large enough to survive multiple", "       comparison corrections.", "", "       Thanks to Laura Thomas and Brian Bones for finding this artifact.", "", "   --> To deal with this, a time series of all 1s is created on the original", "       EPI grid space.  Then for each run it is warped with to the same list of", "       transformations that is applied to the EPI data in the volreg step", "       (volreg xform and either alignment to anat or warp to standard space).", "       The result is a time series of extents of each original volume within", "       the new grid.", "", "       These volumes are then intersected over all TRs of all runs.  The final", "       mask is the set of voxels that have valid data at every TR of every run.", "       Yay.", "", "    5. Classes and Classes_resam: GM, WM, CSF class masks from 3dSeg", "", "       By default, unless the user requests otherwise (-mask_segment_anat no),", "       and if anat_final is skull-stripped, then 3dSeg will be used to segment", "       the anatomy into gray matter, white matter and CSF classes.", "", "       A dataset named Classes is the result of running 3dSeg, which is then", "       resampled to match the EPI and named Classes_resam.", "", "       If the user wanted to, this dataset could be used for regression of", "       said tissue classes (or eroded versions).", "", "", "    --- masking, continued...", "", "    Note that it may still not be a good idea to apply any of the masks to the", "    regression, as it might then be necessary to intersect such masks across", "    all subjects, though applying the 'group' mask might be reasonable.", "", " ** Why has the default been changed?", "", "    It seems much better not to mask the regression data in the single-subject", "    analysis at all, send _all_ of the results to group space, and apply an", "    anatomically-based mask there.  That could be computed from the @auto_tlrc", "    reference dataset or from the union of skull-stripped subject anatomies.", "", "    Since subjects have varying degrees of signal dropout in valid brain areas", "    of the EPI data, the resulting EPI intersection mask that would be required", "    in group space may exclude edge regions that are otherwise desirable.", "", "    Also, it is helpful to see if much 'activation' appears outside the brain.", "    This could be due to scanner or interpolation artifacts, and is useful to", "    note, rather than to simply mask out and never see.", "", "    Rather than letting 3dAutomask decide which brain areas should not be", "    considered valid, create a mask based on the anatomy _after_ the results", "    have been warped to a standard group space.  Then perhaps dilate the mask", "    by one voxel.  Example #11 from '3dcalc -help' shows how one might dilate.", "", " ** Note that the EPI data can now be warped to standard space at the volreg", "    step.  In that case, it might be appropriate to mask the EPI data based", "    on the Talairach template, such as what is used for -base in @auto_tlrc.", "    This can be done via '-mask_apply group'.", "", "    ---", "", " ** For those who have processed some of their data with the older method:", "", "    Note that this change should not be harmful to those who have processed", "    data with older versions of afni_proc.py, as it only adds non-zero voxel", "    values to the output datasets.  If some subjects were analyzed with the", "    older version, the processing steps should not need to change.  It is still", "    necessary to apply an intersection mask across subjects in group space.", "", "    It might be okay to create the intersection mask from only those subjects", "    which were masked in the regression, however one might say that biases the", "    voxel choices toward those subjects, though maybe that does not matter.", "    Any voxels used would still be across all subjects.", "", "    ---", "", "    A mask dataset is necessary when computing blur estimates from the epi and", "    errts datasets.  Also, since it is nice to simply see what the mask looks", "    like, its creation has been left in by default.", "", "    The '-regress_no_mask' option is now unnecessary.", "", "    ---", "", "    Note that if no mask were applied in the 'scaling' step, large percent", "    changes could result.  Because large values would be a detriment to the", "    numerical resolution of the scaled short data, the default is to truncate", "    scaled values at 200 (percent), which should not occur in the brain.", "", "    --------------------------------------------------", "    BLIP NOTE: ~2~", "", "    application of reverse-blip (blip-up/blip-down) registration:", "", "       o compute the median of the forward and reverse-blip data", "       o align them using 3dQwarp -plusminus", "          -> the main output warp is the square root of the forward warp", "             to the reverse, i.e. it warps the forward data halfway", "          -> in theory, this warp should make the EPI anatomically accurate", "", "    order of operations:", "", "       o the blip warp is computed after all initial temporal operations", "         (despike, ricor, tshift)", "       o and before all spatial operations (anat/EPI align, tlrc, volreg)", "", "    notes:", "", "       o If no forward blip time series (volume?) is provided by the user,", "         the first time points from the first run will be used (using the", "         same number of time points as in the reverse blip time series).", "       o As usual, all registration transformations are combined.", "", "    differences with unWarpEPI.py (R Cox, D Glen and V Roopchansingh):", "", "                        afni_proc.py            unWarpEPI.py", "                        --------------------    --------------------", "       tshift step:     before unwarp           after unwarp", "                        (option: after unwarp)", "", "       volreg program:  3dvolreg                3dAllineate", "", "       volreg base:     as before               median warped dset", "                        (option: MEDIAN_BLIP)   (same as MEDIAN_BLIP)", "", "       unifize EPI?     no (option: yes)        yes", "       (align w/anat)", "", "    --------------------------------------------------", "    ANAT/EPI ALIGNMENT CASES NOTE: ~2~", "", "    This outlines the effects of alignment options, to help decide what options", "    seem appropriate for various cases.", "", "    1. EPI to EPI alignment (the volreg block)", "", "        Alignment of the EPI data to a single volume is based on the 3 options", "        -volreg_align_to, -volreg_base_dset and -volreg_base_ind, where the", "        first option is by far the most commonly used.", "", "        Note that a good alternative is: '-volreg_align_to MIN_OUTLIER'.", "", "        The logic of EPI alignment in afni_proc.py is:", "", "            a. if -volreg_base_dset is given, align to that", "               (this volume is copied locally as the dataset ext_align_epi)", "            b. otherwise, use the -volreg_align_to or -volreg_base_ind volume", "", "        The typical case is to align the EPI to one of the volumes used in", "        pre-processing (where the dataset is provided by -dsets and where the", "        particular TR is not removed by -tcat_remove_first_trs).  If the base", "        volume is the first or third (TR 0 or 2) from the first run, or is the", "        last TR of the last run, then -volreg_align_to can be used.", "", "        To specify a TR that is not one of the 3 just stated (first, third or", "        last), -volreg_base_ind can be used.", "", "        To specify a volume that is NOT one of those used in pre-processing", "        (such as the first pre-steady state volume, which would be excluded by", "        the option -tcat_remove_first_trs), use -volreg_base_dset.", "", "    2. anat to EPI alignment cases (the align block)", "", "        This is specific to the 'align' processing block, where the anatomy is", "        aligned to the EPI.  The focus is on which EPI volume the anat gets", "        aligned to.  Whether this transformation is inverted in the volreg", "        block (to instead align the EPI to the anat via -volreg_align_e2a) is", "        an independent consideration.", "", "        The logic of which volume the anatomy gets aligned to is as follows:", "            a. if -align_epi_ext_dset is given, use that for anat alignment", "            b. otherwise, if -volreg_base_dset, use that", "            c. otherwise, use the EPI base from the EPI alignment choice", "", "        To restate this: the anatomy gets aligned to the same volume the EPI", "        gets aligned to *unless* -align_epi_ext_dset is given, in which case", "        that volume is used.", "", "        The entire purpose of -align_epi_ext_dset is for the case where the", "        user might want to align the anat to a different volume than what is", "        used for the EPI (e.g. align anat to a pre-steady state TR but the EPI", "        to a steady state one).", "", "        Output:", "", "           The result of the align block is an 'anat_al' dataset.  This will be", "           in alignment with the EPI base (or -align_epi_ext_dset).", "", "           In the default case of anat -> EPI alignment, the aligned anatomy", "           is actually useful going forward, and is so named 'anat_al_keep'.", "", "           Additionally, if the -volreg_align_e2a option is used (thus aligning", "           the EPI to the original anat), then the aligned anat dataset is no", "           longer very useful, and is so named 'anat_al_junk'.  However, unless", "           an anat+tlrc dataset was copied in for use in -volreg_tlrc_adwarp,", "           the skull-striped anat (anat_ss) becomes the current one going", "           forward.  That is identical to the original anat, except that it", "           went through the skull-stripping step in align_epi_anat.py.", "", "           At that point (e2a case) the pb*.volreg.* datasets are aligned with", "           the original anat or the skull-stripped original anat (and possibly", "           in Talairach space, if the -volreg_tlrc_warp or _adwarp option was", "           applied).", "", "         Checking the results:", "", "           The pb*.volreg.* volumes should be aligned with the anat.  If", "           -volreg_align_e2a was used, it will be with the original anat.", "           If not, then it will be with anat_al_keep.", "", "           Note that at the end of the regress block, whichever anatomical", "           dataset is deemed \"in alignment\" with the stats dataset will be", "           copied to anat_final.$subj.", "", "           So compare the volreg EPI with the final anatomical dataset.", "", "    --------------------------------------------------", "    ANAT/EPI ALIGNMENT CORRECTIONS NOTE: ~2~", "", "    Aligning the anatomy and EPI is sometimes difficult, particularly depending", "    on the contrast of the EPI data (between tissue types).  If the alignment", "    fails to do a good job, it may be necessary to run align_epi_anat.py in a", "    separate location, find options that help it to succeed, and then apply", "    those options to re-process the data with afni_proc.py.", "", "    1. If the anat and EPI base do not start off fairly close in alignment,", "       the -giant_move option may be needed for align_epi_anat.py.  Pass this", "       option to AEA.py via the afni_proc.py option -align_opts_aea:", "", "            afni_proc.py ... -align_opts_aea -giant_move", "", "    2. The default cost function used by align_epi_anat.py is lpc (local", "       Pearson correlation).  If this cost function does not work (probably due", "       to poor or unusual EPI contrast), then consider cost functions such as", "       lpa (absolute lpc), lpc+ (lpc plus fractions of other cost functions) or", "       lpc+ZZ (approximate with lpc+, but finish with pure lpc).", "", "       The lpa and lpc+ZZ cost functions are common alternatives.  The", "       -giant_move option may be necessary independently.", "", "       Examples of some helpful options:", "", "         -align_opts_aea -cost lpa", "         -align_opts_aea -giant_move", "         -align_opts_aea -cost lpc+ZZ -giant_move", "         -align_opts_aea -check_flip", "         -align_opts_aea -cost lpc+ZZ -giant_move -resample off", "         -align_opts_aea -skullstrip_opts -blur_fwhm 2", "", "    3. Testing alignment with align_epi_anat.py directly.", "", "       When having alignment problems, it may be more efficient to copy the", "       anat and EPI alignment base to a new directory, figure out a good cost", "       function or other options, and then apply them in a new afni_proc.py", "       command.", "", "       For testing purposes, it helps to test many cost functions at once.", "       Besides the cost specified by -cost, other cost functions can be applied", "       via -multi_cost.  This is efficient, since all of the other processing", "       does not need to be repeated.  For example:", "", "         align_epi_anat.py -anat2epi                    \\", "                -anat subj99_anat+orig                  \\", "                -epi pb01.subj99.r01.tshift+orig        \\", "                -epi_base 0 -volreg off -tshift off     \\", "                -giant_move                             \\", "                -cost lpc -multi_cost lpa lpc+ZZ mi", "", "       That adds -giant_move, and uses the basic lpc cost function along with", "       3 additional cost functions (lpa, lpc+ZZ, mi).  The result is 4 new", "       anatomies aligned to the EPI, 1 per cost function:", "", "               subj99_anat_al+orig         - cost func lpc      (see -cost opt)", "               subj99_anat_al_lpa+orig     - cost func lpa         (additional)", "               subj99_anat_al_lpc+ZZ+orig  - cost func lpc+ZZ      (additional)", "               subj99_anat_al_mi+orig      - cost func mi          (additional)", "", "       Also, if part of the dataset gets clipped in the case of -giant_move,", "       consider the align_epi_anat.py option '-resample off'.", "", "    --------------------------------------------------", "    WARP TO TLRC NOTE: ~2~", "", "    afni_proc.py can now apply a +tlrc transformation to the EPI data as part", "    of the volreg step via the option '-volreg_tlrc_warp'.  Note that it can", "    also align the EPI and anatomy at the volreg step via '-volreg_align_e2a'.", "", "    Manual Talairach transformations can also be applied, but separately, after", "    volreg.  See '-volreg_tlrc_adwarp'.", "", "    This tlrc transformation is recommended for many reasons, though some are", "    not yet implemented.  Advantages include:", "", "        - single interpolation of the EPI data", "", "            Done separately, volume registration, EPI to anat alignment and/or", "            the +tlrc transformation interpolate the EPI data 2 or 3 times.  By", "            combining these transformations into a single one, there is no", "            resampling penalty for the alignment or the warp to standard space.", "", "            Thanks to D Glen for the steps used in align_epi_anat.py.", "", "        - EPI time series become directly comparable across subjects", "", "            Since the volreg output is now in standard space, there is already", "            voxel correspondence across subjects with the EPI data.", "", "        - group masks and/or atlases can be applied to the EPI data without", "          additional warping", "", "            It becomes trivial to extract average time series data over ROIs", "            from standard atlases, say.", "", "            This could even be done automatically with afni_proc.py, as part", "            of the single-subject processing stream (not yet implemented).", "            One would have afni_proc.py extract average time series (or maybe", "            principal components) from all the ROIs in a dataset and apply", "            them as regressors of interest or of no interest.", "", "        - with 3dBlurToFWHM, using an AlphaSim look-up table might be possible", "", "            Since the blur and data grid could both be isotropic and integral,", "            and since the transformation could depend on a known anatomy (such", "            as the N27 Colin brain or icbm_452), it would be easy to create a", "            look-up table of AlphaSim results (so users would not actually need", "            to run it).", "", "            The known numbers would correspond to a cluster size (each for a", "            given, common voxel-wise threshold).  This correction could then", "            be applied automatically.  Again, not yet implemented...", "", "        - no interpolation of statistics", "", "            If the user wishes to include statistics as part of the group", "            analysis (e.g. using 3dMEMA.R), this warping becomes more needed.", "            Warping to standard space *after* statistics are generated is not", "            terribly valid.", "", "    --------------------------------------------------", "    RETROICOR NOTE: ~2~", "", "    ** Cardiac and respiratory regressors must be created from an external", "       source, such as the RetroTS.m matlab program written by Z Saad.  The", "       input to that would be the 2+ signals.  The output would be a single", "       file per run, containing 13 or more regressors for each slice.  That", "       set of output files would be applied here in afni_proc.py.", "", "    Removal of cardiac and respiratory regressors can be done using the 'ricor'", "    processing block.  By default, this would be done after 'despike', but", "    before any other processing block.", "", "    These card/resp signals would be regressed out of the MRI data in the", "    'ricor' block, after which processing would continue normally. In the final", "    'regress' block, regressors for slice 0 would be applied (to correctly", "    account for the degrees of freedom and also to remove residual effects).", "        --> This is now only true when using '-regress_apply_ricor yes'.", "            The default as of 30 Jan 2012 is to not include them in the final", "            regression (since degrees of freedom are really not important for a", "            subsequent correlation analysis).", "", "    Users have the option of removing the signal \"per-run\" or \"across-runs\".", "", "    Example R1: 7 runs of data, 13 card/resp regressors, process \"per-run\"", "", "        Since the 13 regressors are processed per run, the regressors can have", "        different magnitudes each run.  So the 'regress' block will actually", "        get 91 extra regressors (13 regressors times 7 runs each).", "", "    Example R2: process \"across-run\"", "", "        In this case the regressors are catenated across runs when they are", "        removed from the data.  The major difference between this and \"per-run\"", "        is that now only 1 best fit magnitude is applied per regressor (not the", "        best for each run).  So there would be only the 13 catenated regressors", "        for slice 0 added to the 'regress' block.", "", "    Those analyzing resting-state data might prefer the per-run method, as it", "    would remove more variance and degrees of freedom might not be as valuable.", "", "    Those analyzing a normal signal model might prefer doing it across-runs,", "    giving up only 13 degrees of freedom, and helping not to over-model the", "    data.", "", "    ** The minimum options would be specifying the 'ricor' block (preferably", "       after despike), along with -ricor_regs and -ricor_regress_method.", "", "    Example R3: afni_proc.py option usage:", "", "        Provide additional options to afni_proc.py to apply the despike and", "        ricor blocks (which will be the first 2 blocks by default), with each", "        regressor named 'slibase*.1D' going across all runs, and where the", "        first 3 TRs are removed from each run (matching -tcat_remove_first_trs,", "        most likely).", "", "            -do_block despike ricor", "            -ricor_regs slibase*.1D", "            -ricor_regress_method across-runs", "            -ricor_regs_nfirst 3", "", "    --------------------------------------------------", "    RUNS OF DIFFERENT LENGTHS NOTE: ~2~", "", "    In the case that the EPI datasets are not all of the same length, here", "    are some issues that may come up, listed by relevant option:", "", "        -volreg_align_to        OK, as of version 1.49.", "", "        -ricor_regress_method   OK, as of version 3.05.", "", "        -regress_polort         Probably no big deal.", "                                If this option is not used, then the degree of", "                                polynomial used for the baseline will come from", "                                the first run.  Only 1 polort may be applied.", "", "        -regress_est_blur_epits OK, as of version 1.49.", "", "     *  -regress_use_stim_files This may fail, as make_stim_times.py is not", "                                currently prepared to handle runs of different", "                                lengths.", "", "        -regress_censor_motion  OK, as of version 2.14", "", "     * probably will be fixed (please let me know of interest)", "", "    --------------------------------------------------", "    SCRIPT EXECUTION NOTE: ~2~", "", "    The suggested way to run the output processing SCRIPT is via...", "", "        a) if you use tcsh:    tcsh -xef SCRIPT |& tee output.SCRIPT", "", "        b) if you use bash:    tcsh -xef SCRIPT 2>&1 | tee output.SCRIPT", "", "        c) if you use tcsh and the script is executable, maybe use one of:", "", "                            ./SCRIPT |& tee output.SCRIPT", "                            ./SCRIPT 2>&1 | tee output.SCRIPT", "", "    Consider usage 'a' for example:  tcsh -xef SCRIPT |& tee output.SCRIPT", "", "    That command means to invoke a new tcsh with the -xef options (so that", "    commands echo to the screen before they are executed, exit the script", "    upon any error, do not process the ~/.cshrc file) and have it process the", "    SCRIPT file, piping all output to the 'tee' program, which will duplicate", "    output back to the screen, as well as to the given output file.", "", "    parsing the command: tcsh -xef SCRIPT |& tee output.SCRIPT", "", "        a. tcsh", "", "           The script itself is written in tcsh syntax and must be run that way.", "           It does not mean the user must use tcsh.  Note uses 'a' and 'b'.", "           There tcsh is specified by the user.  The usage in 'c' applies tcsh", "           implicitly, because the SCRIPT itself specifies tcsh at the top.", "", "        b. tcsh -xef", "", "           The -xef options are applied to tcsh and have the following effects:", "", "                x : echo commands to screen before executing them", "                e : exit (terminate) the processing on any errors", "                f : do not process user's ~/.cshrc file", "", "           The -x option is very useful so one see not just output from the", "           programs, but the actual commands that produce the output.  It", "           makes following the output much easier.", "", "           The -e option tells the shell to terminate on any error.  This is", "           useful for multiple reasons.  First, it allows the user to easily", "           see the failing command and error message.  Second, it would be", "           confusing and useless to have the script try to continue, without", "           all of the needed data.", "", "           The -f option tells the shell not to process the user's ~/.cshrc", "           (or ~/.tcshrc) file.  The main reason for including this is because", "           of the -x option.  If there were any errors in the user's ~/.cshrc", "           file and -x option were used, they would terminate the shell before", "           the script even started, probably leaving the user confused.", "", "        c. tcsh -xef SCRIPT", "", "           The T-shell is invoked as described above, executing the contents", "           of the specified text file (called 'SCRIPT', for example) as if the", "           user had typed the included commands in their terminal window.", "", "        d. |&", "", "           These symbols are for piping the output of one program to the input", "           of another.  Many people know how to do 'afni_proc.py -help | less'", "           (or maybe '| more').  This script will output a lot of text, and we", "           want to get a copy of that into a text file (see below).", "", "           Piping with '|' captures only stdout (standard output), and would", "           not capture errors and warnings that appear.  Piping with '|&'", "           captures both stdout and stderr (standard error).  The user may not", "           be able to tell any difference between those file streams on the", "           screen, but since programs write to both, we want to capture both.", "", "        e. tee output.SCRIPT", "", "           Where do we want to send this captured stdout and stderr text?  Send", "           it to the 'tee' program.  Like a plumber's tee, the 'tee' program", "           splits the data (not water) stream off into 2 directions.", "", "           Here, one direction that tee sends the output is back to the screen,", "           so the user can still see what is happening.", "", "           The other direction is to the user-specified text file.  In this", "           example it would be 'output.SCRIPT'.  With this use of 'tee', all", "           screen output will be duplicated in that text file.", "", "", "", "    ==================================================", "    OPTIONS:  ~2~", "", "        Informational options, general options, and block options.", "        Block options are ordered by block.", "", "        -----------------------------------------------------------------", "        Informational/terminal options  ~3~", "", "        -help                   : show this help", "        -hist                   : show the module history", "", "        -requires_afni_version  : show AFNI date required by processing script", "", "            Many updates to afni_proc.py are accompanied by corresponding", "            updates to other AFNI programs.  So if the processing script is", "            created on one computer but executed on another (with an older", "            version of AFNI), confusing failures could result.", "", "            The required date is adjusted whenever updates are made that rely", "            on new features of some other program.  If the processing script", "            checks the AFNI version, the AFNI package must be as current as the", "            date output via this option.  Checks are controlled by the option", "            '-check_afni_version'.", "", "            The checking method compares the output of:", "                afni_proc.py -requires_afni_version", "", "            against the most recent date in afni_history:", "                afni_history -past_entries 1", "", "            See also '-requires_afni_hist'.", "", "            See also '-check_afni_version'.", "", "        -requires_afni_hist     : show history of -requires_afni_version", "", "            List the history of '-requires_afni_version' dates and reasons.", "", "        -show_valid_opts        : show all valid options (brief format)", "        -ver                    : show the version number", "", "        -----------------------------------------------------------------", "        General execution and setup options ~3~", "", "        -anat_follower LABEL GRID DSET : specify anat follower dataset", "", "                e.g. -anat_follower GM anat FS_GM_MASK.nii", "", "            Use this option to pass any anatomical follower dataset.  Such a", "            dataset is warped by any transformations that take the original", "            anat to anat_final.", "", "            Anatomical follower datasets are resampled using wsinc5.  The only", "            difference with -anat_follower_ROI is that such ROI datasets are", "            resampled using nearest neighbor interpolation.", "", "               LABEL    : to name and refer to this dataset", "               GRID     : which grid should this be sampled on, anat or epi?", "               DSET     : name of input dataset, changed to copy_af_LABEL", "", "            A default anatomical follower (in the case of skull stripping) is", "            the original anat.  That is to get a warped version that still has", "            a skull, for quality control.", "", "            See also -anat_follower_ROI, anat_follower_erode.", "", "        -anat_follower_erode LABEL LABEL ...: erode masks for given labels", "", "                e.g. -anat_follower_erode WMe", "", "            Perform a single erosion step on the mask dataset for the given", "            label.  This is done on the input ROI (anatomical?) grid.", "", "            The erosion step is applied before any transformation, and uses the", "            18-neighbor approach (6 face and 12 edge neighbors, not 8 corner", "            neighbors) in 3dmask_tool.", "", "            See also -regress_ROI_PC, -regress_ROI.", "            Please see '3dmask_tool -help' for more information on eroding.", "", "        -anat_follower_ROI LABEL GRID DSET : specify anat follower ROI dataset", "", "                e.g. -anat_follower_ROI aaseg anat aparc.a2009s+aseg.nii", "                e.g. -anat_follower_ROI FSvent epi FreeSurfer_ventricles.nii", "", "            Use this option to pass any anatomical follower dataset.  Such a", "            dataset is warped by any transformations that take the original", "            anat to anat_final.", "", "            Similar to -anat_follower, except that these anatomical follower", "            datasets are resampled using nearest neighbor (NN) interpolation,", "            to preserve data values (as opposed to -anat_follower, which uses", "            wsinc5).  That is the only difference between these options.", "", "               LABEL    : to name and refer to this dataset", "               GRID     : which grid should this be sampled on, anat or epi?", "               DSET     : name of input dataset, changed to copy_af_LABEL", "", "            Labels defined via this option may be used in -regress_ROI or _PC.", "", "            See also -anat_follower, anat_follower_erode, -regress_ROI", "            or -regress_ROI_PC.", "", "        -anat_has_skull yes/no  : specify whether the anatomy has a skull", "", "                e.g. -anat_has_skull no", "", "            Use this option to block any skull-stripping operations, likely", "            either in the align or tlrc processing blocks.", "", "        -anat_uniform_method METHOD : specify uniformity correction method", "", "                e.g. -anat_uniform_method unifize", "", "            Specify the method for anatomical intensity uniformity correction.", "", "                none    : do not do uniformity correction at all", "                default : use 3dUnifize at whim of auto_warp.py", "                unifize : apply 3dUnifize early in processing stream", "                          (so it affects more than auto_warp.py)", "", "            Please see '3dUnifize -help' for details.", "            See also -anat_opts_unif.", "", "        -anat_opts_unif OPTS ... : specify extra options for unifize command", "", "                e.g. -anat_opts_unif -Urad 14", "", "            Specify options to be applied to the command used for anatomical", "            intensity uniformity correction, such as 3dUnifize.", "", "            Please see '3dUnifize -help' for details.", "            See also -anat_uniform_method.", "", "        -anat_unif_GM yes/no    : also unifize gray matter (lower intensities)", "                                  the default is 'no'", "", "                e.g. -anat_unif_GM yes", "                default: -anat_unif_GM no", "", "            If this is set to yes, 3dUnifize will not only apply uniformity", "            correction across the brain volume, but also to voxels that look", "            like gray matter.  That is to say the option adds '-GM' to the", "            3dUnifize command.", "", "          * The default was changed from yes to no 2014, May 16.", "", "            Please see '3dUnifize -help' for details.", "            See also -anat_uniform_method, -anat_opts_unif.", "", "        -ask_me                 : ask the user about the basic options to apply", "", "            When this option is used, the program will ask the user how they", "            wish to set the basic options.  The intention is to give the user", "            a feel for what options to apply (without using -ask_me).", "", "        -bash                   : show example execution command in bash form", "", "            After the script file is created, this program suggests how to run", "            it (piping stdout/stderr through 'tee').  If the user is running", "            the bash shell, this option will suggest the 'bash' form of a", "            command to execute the newly created script.", "", "            example of tcsh form for execution:", "", "                tcsh -x proc.ED.8.glt |& tee output.proc.ED.8.glt", "", "            example of bash form for execution:", "", "                tcsh -x proc.ED.8.glt 2>&1 | tee output.proc.ED.8.glt", "", "            Please see \"man bash\" or \"man tee\" for more information.", "", "        -blocks BLOCK1 ...      : specify the processing blocks to apply", "", "                e.g. -blocks volreg blur scale regress", "                e.g. -blocks despike tshift align volreg blur scale regress", "                default: tshift volreg blur mask scale regress", "", "            The user may apply this option to specify which processing blocks", "            are to be included in the output script.  The order of the blocks", "            may be varied, and blocks may be skipped.", "", "            See also '-do_block' (e.g. '-do_block despike').", "", "        -check_afni_version yes/no : check that AFNI is current enough", "", "                e.g. -check_afni_version no", "                default: yes", "", "            Check that the version of AFNI is recent enough for processing of", "            the afni_proc.py script.", "", "            For the version check, the output of:", "                afni_proc.py -requires_afni_version", "", "            is tested against the most recent date in afni_history:", "                afni_history -past_entries 1", "", "            In the case that newer features in other programs might not be", "            needed by the given afni_proc.py script (depending on the options),", "            the user is left with this option to ignore the AFNI version check.", "", "            Please see 'afni_history -help' or 'afni -ver' for more information.", "            See also '-requires_afni_version'.", "", "        -check_results_dir yes/no : check whether dir exists before proceeding", "", "                e.g. -check_results_dir no", "                default: yes", "", "            By default, if the results directory already exists, the script", "            will terminate before doing any processing.  Set this option to", "            'no' to remove that check.", "", "        -check_setup_errors yes/no : terminate on setup errors", "", "                e.g. -check_setup_errors yes", "                default: no", "", "            Have the script check $status after each command in the setup", "            processing block.  It is preferable to run the script using the", "            -e option to tcsh (as suggested), but maybe the user does not wish", "            to do so.", "", "        -copy_anat ANAT         : copy the ANAT dataset to the results dir", "", "                e.g. -copy_anat Elvis/mprage+orig", "", "            This will apply 3dcopy to copy the anatomical dataset(s) to the", "            results directory.  Note that if a +view is not given, 3dcopy will", "            attempt to copy +acpc and +tlrc datasets, also.", "", "            See also '3dcopy -help'.", "", "        -copy_files file1 ...   : copy file1, etc. into the results directory", "", "                e.g. -copy_files glt_AvsB.txt glt_BvsC.1D glt_eat_cheese.txt", "                e.g. -copy_files contrasts/glt_*.txt", "", "            This option allows the user to copy some list of files into the", "            results directory.  This would happen before the tcat block, so", "            such files may be used for other commands in the script (such as", "            contrast files in 3dDeconvolve, via -regress_opts_3dD).", "", "        -do_block BLOCK_NAME ...: add extra blocks in their default positions", "", "                e.g. -do_block despike ricor", "                e.g. -do_block align", "", "            With this option, any 'optional block' can be applied in its", "            default position.  This includes the following blocks, along with", "            their default positions:", "", "                despike : first (between tcat and tshift)", "                ricor   : just after despike (else first)", "                align   : before tlrc, before volreg", "                tlrc    : after align, before volreg", "                empty   : NO DEFAULT, cannot be applied via -do_block", "", "            Any block not included in -blocks can be added via this option", "            (except for 'empty').", "", "            See also '-blocks', as well as the \"PROCESSING BLOCKS\" section of", "            the -help output.", "", "        -dsets dset1 dset2 ...  : (REQUIRED) specify EPI run datasets", "", "                e.g. -dsets Elvis_run1+orig Elvis_run2+orig Elvis_run3+orig", "                e.g. -dsets Elvis_run*.HEAD", "", "            The user must specify the list of EPI run datasets to analyze.", "            When the runs are processed, they will be written to start with", "            run 1, regardless of whether the input runs were just 6, 7 and 21.", "", "            Note that when using a wildcard it is essential for the EPI", "            datasets to be alphabetical, as that is how the shell will list", "            them on the command line.  For instance, epi_run1+orig through", "            epi_run11+orig is not alphabetical.  If they were specified via", "            wildcard their order would end up as run1 run10 run11 run2 ...", "", "            Note also that when using a wildcard it is essential to specify", "            the datasets suffix, so that the shell doesn't put both the .BRIK", "            and .HEAD filenames on the command line (which would make it twice", "            as many runs of data).", "", "        -dsets_me_echo dset1 dset2 ...  : specify ME datasets for one echo", "                                          (all runs with each option)", "", "           These examples might correspond to 3 echoes across 4 runs.", "", "                e.g. -dsets_me_echo epi_run*.echo_1+orig.HEAD", "                     -dsets_me_echo epi_run*.echo_2+orig.HEAD", "                     -dsets_me_echo epi_run*.echo_3+orig.HEAD", "", "                e.g. -dsets_me_echo r?.e1.nii", "                     -dsets_me_echo r?.e2.nii", "                     -dsets_me_echo r?.e3.nii", "", "                e.g. -dsets_me_echo r1.e1.nii r2.e1.nii r3.e1.nii r4.e1.nii", "                     -dsets_me_echo r1.e2.nii r2.e2.nii r3.e2.nii r4.e2.nii", "                     -dsets_me_echo r1.e3.nii r2.e3.nii r3.e3.nii r4.e3.nii", "", "            This option is convenient when there are more runs than echoes.", "", "            When providing multi-echo data to afni_proc.py, doing all echoes", "            of all runs at once seems messy and error prone.  So one must", "            provide either one echo at a time (easier if there are more runs)", "            or one run at a time (easier if there are fewer runs).", "", "            With this option:", "", "               - use one option per echo (as opposed to per run, below)", "               - each option use should list all run datasets for that echo", "", "            For example, if there are 7 runs and 3 echoes, use 3 options, one", "            per echo, and pass the 7 runs of data for that echo in each.", "", "            See also -dsets_me_run.", "            See also -echo_times and -reg_echo.", "", "        -dsets_me_run dset1 dset2 ...   : specify ME datasets for one run", "                                          (all echoes with each option)", "", "           These examples might correspond to 4 echoes across 2 runs.", "", "                e.g. -dsets_me_run epi_run1.echo_*+orig.HEAD", "                     -dsets_me_run epi_run2.echo_*+orig.HEAD", "", "                e.g. -dsets_me_run r1.e*.nii", "                     -dsets_me_run r2.e*.nii", "", "                e.g. -dsets_me_run r1.e1.nii r1.e2.nii r1.e3.nii r1.e4.nii", "                     -dsets_me_run r2.e1.nii r2.e2.nii r2.e3.nii r2.e4.nii", "", "            This option is convenient when there are more echoes than runs.", "", "            When providing multi-echo data to afni_proc.py, doing all echoes", "            of all runs at once seems messy and error prone.  So one must", "            provide either one echo at a time (easier if there are more runs)", "            or one run at a time (easier if there are fewer runs).", "", "            With this option:", "", "               - use one option per run (as opposed to per echo, above)", "               - each option use should list all echo datasets for that run", "", "            For example, if there are 2 runs and 4 echoes, use 2 options, one", "            per run, and pass the 4 echoes of data for that run in each.", "", "            See also -dsets_me_echo.", "            See also -echo_times and -reg_echo.", "", "        -echo_times TE1 TE2 TE3 ... : specify echo-times for ME data processing", "", "                e.g. -echo_times 20 30.5 41.2", "", "            Use this option to specify echo times, if they are needed for the", "            'combine' processing block (OC/ME-ICA/tedana).", "", "            See also -combine_method.", "", "        -execute                : execute the created processing script", "", "            If this option is applied, not only will the processing script be", "            created, but it will then be executed in the \"suggested\" manner,", "            such as via:", "", "                tcsh -xef proc.sb23 |& tee output.proc.sb23", "", "            Note that it will actually use the bash format of the command,", "            since the system command (C and therefore python) uses /bin/sh.", "", "                tcsh -xef proc.sb23 2>&1 | tee output.proc.sb23", "", "        -gen_epi_review SCRIPT_NAME : specify script for EPI review", "", "                e.g. -gen_epi_review review_orig_EPI.txt", "", "            By default, the proc script calls gen_epi_review.py on the original", "            EPI data (from the tcat step, so only missing pre-SS TRs).  This", "            creates a \"drive afni\" script that the user can run to quickly scan", "            that EPI data for apparent issues.", "", "            Without this option, the script will be called @epi_review.$subj,", "            where $subj is the subject ID.", "", "            The script starts afni, loads the first EPI run and starts scanning", "            through time (effectively hitting 'v' in the graph window).  The", "            user can press <enter> in the prompting terminal window to go to", "            each successive run.", "", "            Note that the user has full control over afni, aside from a new run", "            being loaded whey they hit <enter>.  Recall that the <space> key", "            (applied in the graph window) can terminate the 'v' (video mode).", "", "            See 'gen_epi_review.py -help' for details.", "            See also 'no_epi_review', to disable this feature.", "", "        -no_epi_review", "", "            This option is used to prevent writing a gen_epi_review.py command", "            in the processing script (i.e. do not create a script to review the", "            EPI data).", "", "            The only clear reason to want this option is if gen_epi_review.py", "            fails for some reason.  It should not hurt to create that little", "            text file (@epi_review.$subj, by default).", "", "            See also '-gen_epi_review'.", "", "        -keep_rm_files          : do not have script delete rm.* files at end", "", "                e.g. -keep_rm_files", "", "            The output script may generate temporary files in a block, which", "            would be given names with prefix 'rm.'.  By default, those files", "            are deleted at the end of the script.  This option blocks that", "            deletion.", "", "        -move_preproc_files     : move preprocessing files to preproc.data dir", "", "            At the end of the output script, create a 'preproc.data' directory,", "            and move most of the files there (dfile, outcount, pb*, rm*).", "", "            See also -remove_preproc_files.", "", "        -no_proc_command        : do not print afni_proc.py command in script", "", "                e.g. -no_proc_command", "", "            If this option is applied, the command used to generate the output", "            script will be stored at the end of the script.", "", "        -out_dir DIR            : specify the output directory for the script", "", "                e.g. -out_dir ED_results", "                default: SUBJ.results", "", "            The AFNI processing script will create this directory and perform", "            all processing in it.", "", "        -outlier_count yes/no   : should we count outliers with 3dToutcount?", "", "                e.g. -outlier_count no", "                default: yes", "", "            By default, outlier fractions are computed per TR with 3dToutcount.", "            To disable outlier counting, apply this option with parameter 'no'.", "            This is a yes/no option, meaning those are the only valid inputs.", "", "            Note that -outlier_count must be 'yes' in order to censor outliers", "            with -regress_censor_outliers.", "", "            See \"3dToutcount -help\" for more details.", "            See also -regress_censor_outliers.", "", "        -outlier_legendre yes/no : use Legendre polynomials in 3dToutcount?", "", "                e.g. -outlier_legendre no", "                default: yes", "", "            By default the -legendre option is passed to 3dToutcount.  Along", "            with using better behaved polynomials, it also allows them to be", "            higher than 3rd order (if desired).", "", "            See \"3dToutcount -help\" for more details.", "", "        -outlier_polort POLORT  : specify polynomial baseline for 3dToutcount", "", "                e.g. -outlier_polort 3", "                default: same degree that 3dDeconvolve would use:", "                         1 + floor(run_length/150)", "", "            Outlier counts come after detrending the data, where the degree", "            of the polynomial trend defaults to the same that 3dDeconvolve", "            would use.  This option will override the default.", "", "            See \"3dToutcount -help\" for more details.", "            See \"3dDeconvolve -help\" for more details.", "            See also '-regress_polort' and '-outlier_legendre'.", "", "        -radial_correlate yes/no : correlate each voxel with local radius", "", "                e.g. -radial_correlate yes", "                default: no", "", "            With this option set, @radial_correlate will be run on the", "            initial EPI time series datasets.  That creates a 'corr_test'", "            directory that one can review, plus potential warnings (in text)", "            if large clusters of high correlations are found.", "", "            (very abbreviated) method for @radial_correlate:", "                for each voxel", "                   compute average time series within 20 mm radius sphere", "                   correlate central voxel time series with spherical average", "                look for clusters of high correlations", "", "            This is a useful quality control (QC) dataset that helps one find", "            scanner artifacts, particularly including coils going bad.", "", "            To visually check the results, the program text output suggests:", "", "                run command: afni corr_test.results.postdata", "                then set:    Underlay  = epi.SOMETHING", "                             Overlay   = res.SOMETHING.corr", "                             maybe threshold = 0.9, maybe clusterize", "", "            See \"@radial_correlate -help\" for details and a list of options.", "", "        -reg_echo ECHO_NUM  : specify 1-based echo for registration", "", "                e.g. -reg_echo 3", "                default: 2", "", "            Multi-echo data is registered based on a single echo, with the", "            resulting transformations being applied to all echoes.  Use this", "            option to specify the 1-based echo used to drive registration.", "", "            Note that the echo used for driving registration should have", "            reasonable tissue contrast.", "", "        -remove_preproc_files   : delete pre-processed data", "", "            At the end of the output script, delete the intermediate data (to", "            save disk space).  Delete dfile*, outcount*, pb* and rm*.", "", "            See also -move_preproc_files.", "", "        -script SCRIPT_NAME     : specify the name of the resulting script", "", "                e.g. -script ED.process.script", "                default: proc_subj", "", "            The output of this program is a script file.  This option can be", "            used to specify the name of that file.", "", "            See also -scr_overwrite, -subj_id.", "", "        -scr_overwrite          : overwrite any existing script", "", "                e.g. -scr_overwrite", "", "            If the output script file already exists, it will be overwritten", "            only if the user applies this option.", "", "            See also -script.", "", "        -sep_char CHAR          : apply as separation character in filenames", "", "                e.g. -sep_char _", "                default: .", "", "            The separation character is used in many output filenames, such as", "            the default '.' in:", "", "                pb04.Nancy.r07.scale+orig.BRIK", "", "            If (for some crazy reason) an underscore (_) character would be", "            preferable, the result would be:", "", "                pb04_Nancy_r07_scale+orig.BRIK", "", "            If \"-sep_char _\" is applied, so is -subj_curly.", "", "            See also -subj_curly.", "", "        -subj_curly             : apply $subj as ${subj}", "", "            The subject ID is used in dataset names is typically used without", "            curly brackets (i.e. $subj).  If something is done where this would", "            result in errors (e.g. \"-sep_char _\"), the curly brackets might be", "            useful to delimit the variable (i.e. ${subj}).", "", "            Note that this option is automatically applied in the case of", "            \"-sep_char _\".", "", "            See also -sep_char.", "", "        -subj_id SUBJECT_ID     : specify the subject ID for the script", "", "                e.g. -subj_id elvis", "                default: SUBJ", "", "            The subject ID is used in dataset names and in the output directory", "            name (unless -out_dir is used).  This option allows the user to", "            apply an appropriate naming convention.", "", "        -test_for_dsets yes/no  : test for existence of input datasets", "", "                e.g. -test_for_dsets no", "                default: yes", "", "            This options controls whether afni_proc.py check for the existence", "            of input datasets.  In general, they must exist when afni_proc.py", "            is run, in order to get run information (TR, #TRs, #runs, etc).", "", "        -test_stim_files yes/no : evaluate stim_files for appropriateness?", "", "                e.g. -test_stim_files no", "                default: yes", "", "            This options controls whether afni_proc.py evaluates the stim_files", "            for validity.  By default, the program will do so.", "", "            Input files are one of local stim_times, global stim_times or 1D", "            formats.  Options -regress_stim_files and -regress_extra_stim_files", "            imply 1D format for input files.  Otherwise, -regress_stim_times is", "            assumed to imply local stim_times format (-regress_global_times", "            implies global stim_times format).", "", "            Checks include:", "", "                1D              : # rows equals total reps", "                local times     : # rows equal # runs", "                                : times must be >= 0.0", "                                : times per run (per row) are unique", "                                : times cannot exceed run time", "                global times    : file must be either 1 row or 1 column", "                                : times must be >= 0.0", "                                : times must be unique", "                                : times cannot exceed total duration of all runs", "", "            This option provides the ability to disable this test.", "", "            See \"1d_tool.py -help\" for details on '-look_like_*' options.", "            See also -regress_stim_files, -regress_extra_stim_files,", "            -regress_stim_times, -regress_local_times, -regress_global_times.", "", "        -verb LEVEL             : specify the verbosity of this script", "", "                e.g. -verb 2", "                default: 1", "", "            Print out extra information during execution.", "", "        -write_3dD_prefix PREFIX : specify prefix for outputs from 3dd_script", "", "                e.g. -write_3dD_prefix basis.tent.", "                default: test.", "", "            If a separate 3dDeconvolve command script is generated via the", "            option -write_3dD_script, then the given PREFIX will be used for", "            relevant output files. in the script.", "", "            See also -write_3dD_script.", "", "        -write_3dD_script SCRIPT : specify SCRIPT only for 3dDeconvolve command", "", "                e.g. -write_3dD_script run.3dd.tent", "", "            This option is intended to be used with the EXACT same afni_proc.py", "            command (aside from any -write_3dD_* options).  The purpose is to", "            generate a corresponding 3dDeconvolve command script which could", "            be run in the same results directory.", "", "            Alternatively, little things could be changed that would only", "            affect the 3dDeconvolve command in the new script, such as the", "            basis function(s).", "", "            The new script should include a prefix to distinguish output files", "            from those created by the original proc script.", "", "          * This option implies '-test_stim_files no'.", "", "            See also -write_3dD_prefix, -test_stim_files.", "", "        -write_ppi_3dD_scripts  : flag: write 3dD scripts for PPI analysis", "", "                e.g. -write_ppi_3dD_scripts                        \\", "                     -regress_ppi_stim_files PPI_*.1D some_seed.1D \\", "                     -regress_ppi_stim_labels PPI_A PPI_B PPI_C seed", "", "            Request 3dDeconvolve scripts for pre-PPI filtering (do regression", "            without censoring) and post-PPI filtering (include PPI regressors", "            and seed).", "", "            This is a convenience method for creating extra 3dDeconvolve", "            command scripts without having to run afni_proc.py multiple times", "            with different options.", "", "            Using this option, afni_proc.py will create the main proc script,", "            plus :", "", "               A. (if censoring was done) an uncensored 3dDeconvolve command", "                  pre-PPI filter script, to create an uncensored errts time", "                  series.", "", "                  This script is akin to using -write_3dD_* to output a", "                  regression script, along with adding -regress_skip_censor.", "                  The regression command should be identical to the original", "                  one, except for inclusion of 3dDeconvolve's -censor option.", "", "               B. a 3dDeconvolve post-PPI filter script to include the PPI", "                  and seed regressors.", "", "                  This script is akin to using -write_3dD_* to output a", "                  regression script, along with passing the PPI and seed", "                  regressors via -regress_extra_stim_files and _labels.", "", "            Use -regress_ppi_stim_files and -regress_ppi_stim_labels to", "            specify the PPI (and seed) regressors and their labels.  These", "            options are currently required.", "", "            See also -regress_ppi_stim_files, -regress_ppi_stim_labels.", "", "        -----------------------------------------------------------------", "        Block options (in default block order) ~3~", "", "        These options pertain to individual processing blocks.  Each option", "        starts with the block name.", "", "        -tcat_preSS_warn_limit LIMIT : TR #0 outlier limit to warn of pre-SS", "", "                e.g. -tcat_preSS_warn_limit 0.7", "                default: 0.4", "", "            Outlier fractions are computed across TRs in the tcat processing", "            block.  If TR #0 has a large fraction, it might suggest that pre-", "            steady state TRs have been included in the analysis.  If the", "            detected fraction exceeds this limit, a warning will be stored", "            (and output by the @ss_review_basic script).", "", "            The special case of limit = 0.0 implies no check will be done.", "", "        -tcat_remove_first_trs NUM : specify how many TRs to remove from runs", "", "                e.g. -tcat_remove_first_trs 3", "                e.g. -tcat_remove_first_trs 3 1 0 0 3", "                default: 0", "", "            Since it takes several seconds for the magnetization to reach a", "            steady state (at the beginning of each run), the initial TRs of", "            each run may have values that are significantly greater than the", "            later ones.  This option is used to specify how many TRs to", "            remove from the beginning of every run.", "", "            If the number needs to vary across runs, then one number should", "            be specified per run.", "", "        -tcat_remove_last_trs NUM : specify TRs to remove from run ends", "", "                e.g. -tcat_remove_last_trs 10", "                default: 0", "", "            For when the user wants a simple way to shorten each run.", "", "            See also -ricor_regs_rm_nlast.", "", "        -despike_mask           : allow Automasking in 3dDespike", "", "            By default, -nomask is applied to 3dDespike.  Since anatomical", "            masks will probably not be contained within the Automask operation", "            of 3dDespike (which uses methods akin to '3dAutomask -dilate 4'),", "            it is left up to the user to speed up this operation via masking.", "", "            Note that the only case in which this should be done is when", "            applying the EPI mask to the regression.", "", "            Please see '3dDespike -help' and '3dAutomask -help' for more", "            information.", "", "        -despike_new yes/no     : set whether to use new version of 3dDespike", "", "                e.g. -despike_new no", "                default: yes", "", "            There is a '-NEW' option/method in 3dDespike which runs a faster", "            method than the previous L1-norm method (Nov 2013).  The results", "            are similar but not identical (different fits).  The difference in", "            speed is more dramatic for long time series (> 500 time points).", "", "            Use this option to control whether to use the new version.", "", "            Sep 2016: in 3dDespike, -NEW is now the default if the input is", "                      longer than 500 time points.  In such a case -despike_new", "                      has no effect.", "", "            See also env var AFNI_3dDespike_NEW and '3dDespike -help' for more", "            information.", "", "        -despike_opts_3dDes OPTS... : specify additional options for 3dDespike", "", "                e.g. -despike_opts_3dDes -nomask -ignore 2", "", "            By default, 3dDespike is used with only -prefix and -nomask", "            (unless -despike_mask is applied).  Any other options must be", "            applied via -despike_opts_3dDes.", "", "            Note that the despike block is not applied by default.  To apply", "            despike in the processing script, use either '-do_block despike'", "            or '-blocks ... despike ...'.", "", "            Please see '3dDespike -help' for more information.", "            See also '-do_blocks', '-blocks', '-despike_mask'.", "", "        -ricor_datum DATUM      : specify output data type from ricor block", "", "                e.g. -ricor_datum float", "", "            By default, if the input is unscaled shorts, the output will be", "            unscaled shorts.  Otherwise the output will be floats.", "", "            The user may override this default with the -ricor_datum option.", "            Currently only 'short' and 'float' are valid parameters.", "", "            Note that 3dREMLfit only outputs floats at the moment.  Recall", "            that the down-side of float data is that it takes twice the disk", "            space, compared with shorts (scaled or unscaled).", "", "            Please see '3dREMLfit -help' for more information.", "", "        -ricor_polort POLORT    : set the polynomial degree for 3dREMLfit", "", "                e.g. -ricor_polort 4", "                default: 1 + floor(run_length / 75.0)", "", "            The default polynomial degree to apply during the 'ricor' block is", "            similar to that of the 'regress' block, but is based on twice the", "            run length (and so should be almost twice as large).  This is to", "            account for motion, since volreg has typically not happened yet.", "", "            Use -ricor_polort to override the default.", "", "        -ricor_regress_method METHOD    : process per-run or across-runs", "", "                e.g. -ricor_regress_method across-runs", "                default: NONE: this option is required for a 'ricor' block", "", "            * valid METHOD parameters: per-run, across-runs", "", "            The cardiac and respiratory signals can be regressed out of each", "            run separately, or out of all runs at once.  The user must choose", "            the method, there is no default.", "", "            See \"RETROICOR NOTE\" for more details about the methods.", "", "        -ricor_regress_solver METHOD    : regress using OLSQ or REML", "", "                e.g. -ricor_regress_solver REML", "                default: OLSQ", "", "            * valid METHOD parameters: OLSQ, REML", "", "            Use this option to specify the regression method for removing the", "            cardiac and respiratory signals.  The default method is ordinary", "            least squares, removing the \"best fit\" of the card/resp signals", "            from the data (also subject to the polort baseline).", "", "            To apply the REML (REstricted Maximum Likelihood) method, use this", "            option.", "", "            Note that 3dREMLfit is used for the regression in either case,", "            particularly since the regressors are slice-based (they are", "            different for each slice).", "", "            Please see '3dREMLfit -help' for more information.", "", "        -ricor_regs REG1 REG2 ...       : specify ricor regressors (1 per run)", "", "                e.g. -ricor_regs slibase*.1D", "", "            This option is required with a 'ricor' processing block.", "", "            The expected format of the regressor files for RETROICOR processing", "            is one file per run, where each file contains a set of regressors", "            per slice.  If there are 5 runs and 27 slices, and if there are 13", "            regressors per slice, then there should be 5 files input, each with", "            351 (=27*13) columns.", "", "            This format is based on the output of RetroTS.m, included in the", "            AFNI distribution (as part of the matlab package), by Z Saad.", "", "        -ricor_regs_nfirst NFIRST       : ignore the first regressor timepoints", "", "                e.g. -ricor_regs_nfirst 2", "                default: 0", "", "            This option is similar to -tcat_remove_first_trs.  It is used to", "            remove the first few TRs from the -ricor_regs regressor files.", "", "            Since it is likely that the number of TRs in the ricor regressor", "            files matches the number of TRs in the original input dataset (via", "            the -dsets option), it is likely that -ricor_regs_nfirst should", "            match -tcat_remove_first_trs.", "", "            See also '-tcat_remove_first_trs', '-ricor_regs', '-dsets'.", "", "        -ricor_regs_rm_nlast NUM : remove the last NUM TRs from each regressor", "", "                e.g. -ricor_regs_rm_nlast 10", "                default: 0", "", "            For when the user wants a simple way to shorten each run.", "", "            See also -tcat_remove_last_trs.", "", "        -tshift_align_to TSHIFT OP : specify 3dTshift alignment option", "", "                e.g. -tshift_align_to -slice 14", "                default: -tzero 0", "", "            By default, each time series is aligned to the beginning of the", "            TR.  This option allows the users to change the alignment, and", "            applies the option parameters directly to the 3dTshift command", "            in the output script.", "", "            It is likely that the user will use either '-slice SLICE_NUM' or", "            '-tzero ZERO_TIME'.", "", "            Note that when aligning to an offset other than the beginning of", "            the TR, and when applying the -regress_stim_files option, then it", "            may be necessary to also apply -regress_stim_times_offset, to", "            offset timing for stimuli to later within each TR.", "", "            Please see '3dTshift -help' for more information.", "            See also '-regress_stim_times_offset'.", "", "        -tshift_interp METHOD   : specify the interpolation method for tshift", "", "                e.g. -tshift_interp -Fourier", "                e.g. -tshift_interp -cubic", "                default -quintic", "", "            Please see '3dTshift -help' for more information.", "", "        -tshift_opts_ts OPTS ... : specify extra options for 3dTshift", "", "                e.g. -tshift_opts_ts -tpattern alt+z", "", "            This option allows the user to add extra options to the 3dTshift", "            command.  Note that only one -tshift_opts_ts should be applied,", "            which may be used for multiple 3dTshift options.", "", "            Please see '3dTshift -help' for more information.", "", "        -blip_forward_dset      : specify a forward blip dataset", "", "                e.g. -blip_forward_dset epi_forward_blip+orig'[0..9]'", "", "            Without this option, the first TRs of the first input EPI time", "            series would be used as the forward blip dataset.", "", "            See also -blip_revers_dset.", "", "            Please see '3dQwarp -help' for more information, and the -plusminus", "            option in particular.", "", "        -blip_reverse_dset      : specify a reverse blip dataset", "", "                e.g. -blip_reverse_dset epi_reverse_blip+orig", "                e.g. -blip_reverse_dset epi_reverse_blip+orig'[0..9]'", "", "            EPI distortion correction can be applied via blip up/blip down", "            acquisitions.  Unless specified otherwise, the first TRs of the", "            first run of typical EPI data specified via -dsets is considered", "            to be the forward direction (blip up, say).  So only the reverse", "            direction data needs separate input.", "", "            Please see '3dQwarp -help' for more information, and the -plusminus", "            option in particular.", "", "        -blip_opts_qw OPTS ...  : specify extra options for 3dQwarp", "", "                e.g. -blip_opts_qw -noXdis -noZdis", "", "            This option allows the user to add extra options to the 3dQwarp", "            command specific to the 'blip' processing block.", "", "            There are many options (e.g. for blurring) applied in the 3dQwarp", "            command by afni_proc.py by default, so review the resulting script.", "", "            Please see '3dQwarp -help' for more information.", "", "        -tlrc_anat              : run @auto_tlrc on '-copy_anat' dataset", "", "                e.g. -tlrc_anat", "", "            Run @auto_tlrc on the anatomical dataset provided by '-copy_anat'.", "            By default, warp the anat to align with TT_N27+tlrc, unless the", "            '-tlrc_base' option is given.", "", "            The -copy_anat option specifies which anatomy to transform.", "", "         ** Note, use of this option has the same effect as application of the", "            'tlrc' block.", "", "            Please see '@auto_tlrc -help' for more information.", "            See also -copy_anat, -tlrc_base, -tlrc_no_ss and the 'tlrc' block.", "", "        -tlrc_base BASE_DSET    : run \"@auto_tlrc -base BASE_DSET\"", "", "                e.g. -tlrc_base TT_icbm452+tlrc", "                default: -tlrc_base TT_N27+tlrc", "", "            This option is used to supply an alternate -base dataset for", "            @auto_tlrc (or auto_warp.py).  Otherwise, TT_N27+tlrc will be used.", "", "            Note that the default operation of @auto_tlrc is to \"skull strip\"", "            the input dataset.  If this is not appropriate, consider also the", "            '-tlrc_no_ss' option.", "", "            Please see '@auto_tlrc -help' for more information.", "            See also -tlrc_anat, -tlrc_no_ss.", "", "        -tlrc_NL_warp           : use non-linear for template alignment", "", "                e.g. -tlrc_NL_warp", "", "            If this option is applied, then auto_warp.py is applied for the", "            transformation to standard space, rather than @auto_tlrc, which in", "            turn applies 3dQwarp (rather than 3dWarpDrive in @auto_tlrc).", "", "            The output datasets from this operation are:", "", "                INPUT_ANAT+tlrc         : standard space version of anat", "                anat.un.aff.Xat.1D      : affine xform to standard space", "                anat.un.aff.qw_WARP.nii : non-linear xform to standard space", "                                          (displacement vectors across volume)", "", "            The resulting ANAT dataset is copied out of the awpy directory", "            back into AFNI format, and with the original name but new view,", "            while the 2 transformation files (one text file of 12 numbers, one", "            3-volume dataset vectors) are moved out with the original names.", "", "            If -volreg_tlrc_warp is given, then the non-linear transformation", "            will also be applied to the EPI data, sending the 'volreg' output", "            directly to standard space.  As usual, all transformations are", "            combined so that the EPI is only resampled one time.", "", "            Options can be added to auto_warp.py via -tlrc_opts_at.", "", "            Consider use of -anat_uniform_method along with this option.", "", "            Please see 'auto_warp.py -help' for more information.", "            See also -tlrc_opts_at, -anat_uniform_method.", "", "        -tlrc_NL_warped_dsets ANAT WARP.1D NL_WARP: import auto_warp.py output", "", "                e.g. -tlrc_NL_warped_dsets anat.nii           \\", "                                           anat.un.aff.Xat.1D \\", "                                           anat.un.aff.qw_WARP.nii", "", "            If the user has already run auto_warp.py on the subject anatomy", "            to transform (non-linear) to standard space, those datasets can", "            be input to save re-processing time.", "", "            They are the same 3 files that would be otherwise created by", "            running auto_warp_py from the proc script.", "", "            When using this option, the 'tlrc' block will be empty of actions.", "", "        -tlrc_NL_awpy_rm Y/N    : specify whether to remove awpy directory", "", "                e.g.     -tlrc_NL_awpy_rm no", "                default: -tlrc_NL_awpy_rm yes", "", "            The auto_warp.py program does all its work in an sub-directory", "            called 'awpy', which is removed by default.  Use this option with", "            'no' to save the awpy directory.", "", "        -tlrc_no_ss             : add the -no_ss option to @auto_tlrc", "", "                e.g. -tlrc_no_ss", "", "            This option is used to tell @auto_tlrc not to perform the skull", "            strip operation.", "", "            Please see '@auto_tlrc -help' for more information.", "", "        -tlrc_opts_at OPTS ...   : add additional options to @auto_tlrc", "", "                e.g. -tlrc_opts_at -OK_maxite", "", "            This option is used to add user-specified options to @auto_tlrc,", "            specifically those afni_proc.py is not otherwise set to handle.", "", "            In the case of -tlrc_NL_warp, the options will be passed to", "            auto_warp.py, instead.", "", "            Please see '@auto_tlrc -help' for more information.", "            Please see 'auto_warp.py -help' for more information.", "", "        -tlrc_rmode RMODE       : apply RMODE resampling in @auto_tlrc", "", "                e.g. -tlrc_rmode NN", "", "            This option is used to apply '-rmode RMODE' in @auto_tlrc.", "", "            Please see '@auto_tlrc -help' for more information.", "", "        -tlrc_suffix SUFFIX     : apply SUFFIX to result of @auto_tlrc", "", "                e.g. -tlrc_suffix auto_tlrc", "", "            This option is used to apply '-suffix SUFFIX' in @auto_tlrc.", "", "            Please see '@auto_tlrc -help' for more information.", "", "        -align_epi_ext_dset DSET : specify dset/brick for align_epi_anat EPI", "", "                e.g. -align_epi_ext_dset subj10/epi_r01+orig'[0]'", "", "            This option allows the user to specify an external volume for the", "            EPI base used in align_epi_anat.py in the align block.  The user", "            should apply sub-brick selection if the dataset has more than one", "            volume.  This volume would be used for both the -epi and the", "            -epi_base options in align_epi_anat.py.", "", "            The user might want to align to an EPI volume that is not in the", "            processing stream in the case where there is not sufficient EPI", "            contrast left after the magnetization has reached a steady state.", "            Perhaps volume 0 has sufficient contrast for alignment, but is not", "            appropriate for analysis.  In such a case, the user may elect to", "            align to volume 0, while excluding it from the analysis as part of", "            the first volumes removed in -tcat_remove_first_trs.", "", "            e.g. -dsets subj10/epi_r*_orig.HEAD", "                 -tcat_remove_first_trs 3", "                 -align_epi_ext_dset subj10/epi_r01+orig'[0]'", "                 -volreg_align_to first", "", "            Note that even if the anatomy were acquired after the EPI, the user", "            might still want to align the anat to the beginning of some run,", "            and align all the EPIs to a time point close to that.  Since the", "            anat and EPI are being forcibly aligned, it does not make such a", "            big difference whether the EPI base is close in time to the anat", "            acquisition.", "", "            Note that this option does not affect the EPI registration base.", "", "            Note that without this option, the volreg base dataset (whether", "            one of the processed TRs or not) will be applied for anatomical", "            alignment, assuming the align block is applied.", "", "            See also -volreg_base_dset.", "            Please see \"align_epi_anat.py -help\" for more information.", "", "        -align_opts_aea OPTS ... : specify extra options for align_epi_anat.py", "", "                e.g. -align_opts_aea -cost lpc+ZZ", "                e.g. -align_opts_aea -cost lpc+ZZ -check_flip", "                e.g. -align_opts_aea -Allineate_opts -source_automask+4", "                e.g. -align_opts_aea -giant_move -AddEdge -epi_strip 3dAutomask", "                e.g. -align_opts_aea -skullstrip_opts -blur_fwhm 2", "", "            This option allows the user to add extra options to the alignment", "            command, align_epi_anat.py.", "", "            Note that only one -align_opts_aea option should be given, with", "            possibly many parameters to be passed on to align_epi_anat.py.", "", "            Note the second example.  In order to pass '-source_automask+4' to", "            3dAllineate, one must pass '-Allineate_opts -source_automask+4' to", "            align_epi_anat.py.", "", "            Similarly, the fourth example passes '-blur_fwhm 2' down through", "            align_epi_anat.py to 3dSkullStrip.", "", "          * The -check_flip option to align_epi_anat.py is good for evaluating", "            data from external sources.  Aside from performing the typical", "            registration, it will compare the final registration cost to that", "            of a left/right flipped version.  If the flipped version is lower,", "            one should investigate whether the axes are correctly labeled, or", "            even labeled at all.", "", "            Please see \"align_epi_anat.py -help\" for more information.", "            Please see \"3dAllineate -help\" for more information.", "", "        -align_epi_strip_method METHOD : specify EPI skull strip method in AEA", "", "                e.g. -align_epi_strip_method 3dSkullStrip", "                default: 3dAutomask (changed from 3dSkullStrip, 20 Aug, 2013)", "", "            When align_epi_anat.py is used to align the EPI and anatomy, it", "            uses 3dSkullStrip to remove non-brain tissue from the EPI dataset.", "            However afni_proc.py changes that to 3dAutomask by default (as of", "            August 20, 2013).  This option can be used to specify which method", "            to use, one of 3dSkullStrip, 3dAutomask or None.", "", "            This option assumes the 'align' processing block is used.", "", "            Please see \"align_epi_anat.py -help\" for more information.", "            Please see \"3dSkullStrip -help\" for more information.", "            Please see \"3dAutomask -help\" for more information.", "", "        -align_unifize_epi yes/no: run uniformity correction on EPI base volume", "", "                e.g. -align_unifize_epi yes", "                default: no", "", "            Use this option to run \"3dUnifize -T2\" on the vr_base dataset", "            for the purpose of alignment to the anat.", "", "            The uniformity corrected volume is only used for anatomical", "            alignment.", "", "        -volreg_align_e2a       : align EPI to anatomy at volreg step", "", "            This option is used to align the EPI data to match the anatomy.", "            It is done by applying the inverse of the anatomy to EPI alignment", "            matrix to the EPI data at the volreg step.  The 'align' processing", "            block is required.", "", "            At the 'align' block, the anatomy is aligned to the EPI data.", "            When applying the '-volreg_align_e2a' option, the inverse of that", "            a2e transformation (so now e2a) is instead applied to the EPI data.", "", "            Note that this e2a transformation is catenated with the volume", "            registration transformations, so that the EPI data is still only", "            resampled the one time.  If the user requests -volreg_tlrc_warp,", "            the +tlrc transformation will also be applied at that step in a", "            single transformation.", "", "            See also the 'align' block and '-volreg_tlrc_warp'.", "", "        -volreg_align_to POSN   : specify the base position for volume reg", "", "                e.g. -volreg_align_to last", "                e.g. -volreg_align_to MIN_OUTLIER", "                default: third", "", "            This option takes 'first', 'third', 'last' or 'MIN_OUTLIER' as a", "            parameter.  It specifies whether the EPI volumes are registered to", "            the first or third volume (of the first run), the last volume (of", "            the last run), or the volume that is consider a minimum outlier.", "            The choice of 'first' or 'third' might correspond with when the", "            anatomy was acquired before the EPI data.  The choice of 'last'", "            might correspond to when the anatomy was acquired after the EPI", "            data.", "", "            The default of 'third' was chosen to go a little farther into the", "            steady state data.", "", "            Note that this is done after removing any volumes in the initial", "            tcat operation.", "", "          * A special case is if POSN is the string MIN_OUTLIER, in which", "            case the volume with the minimum outlier fraction would be used.", "", "            Since anat and EPI alignment tends to work very well, the choice", "            of alignment base could even be independent of when the anatomy", "            was acquired, making MIN_OUTLIER a good choice.", "", "            Please see '3dvolreg -help' for more information.", "            See also -tcat_remove_first_trs, -volreg_base_ind and", "            -volreg_base_dset.", "", "        -volreg_base_dset DSET  : specify dset/sub-brick for volreg base", "", "                e.g. -volreg_base_dset subj10/vreg_base+orig'[0]'", "                e.g. -volreg_base_dset MIN_OUTLIER", "", "            This option allows the user to specify an external dataset for the", "            volreg base.  The user should apply sub-brick selection if the", "            dataset has more than one volume.", "", "            For example, one might align to a pre-magnetic steady state volume.", "", "            Note that unless -align_epi_ext_dset is also applied, this volume", "            will be used for anatomical to EPI alignment (assuming that is", "            being done at all).", "", "          * A special case is if DSET is the string MIN_OUTLIER, in which", "            case the volume with the minimum outlier fraction would be used.", "", "            See also -align_epi_ext_dset, -volreg_align_to and -volreg_base_ind.", "", "        -volreg_base_ind RUN SUB : specify run/sub-brick indices for base", "", "                e.g. -volreg_base_ind 10 123", "                default: 0 0", "", "            This option allows the user to specify exactly which dataset and", "            sub-brick to use as the base registration image.  Note that the", "            SUB index applies AFTER the removal of pre-steady state images.", "", "          * The RUN number is 1-based, matching the run list in the output", "            shell script.  The SUB index is 0-based, matching the sub-brick of", "            EPI time series #RUN.  Yes, one is 1-based, the other is 0-based.", "            Life is hard.", "", "            The user can apply only one of the -volreg_align_to and", "            -volreg_base_ind options.", "", "            See also -volreg_align_to, -tcat_remove_first_trs and", "            -volreg_base_dset.", "", "        -volreg_get_allcostX yes/no : compute all anat/EPI costs", "", "                e.g. -volreg_get_allcostX no", "                default: yes", "", "            By default, given the final anatomical dataset (anat_final) and", "            the the final EPI volreg base (final_epi), this option can be used", "            to compute alignment costs between the two volumes across all cost", "            functions from 3dAllineate.  Effectively, it will add the following", "            to the proc script:", "", "                3dAllineate -base FINAL_EPI -input FINAL_ANAT -allcostX", "", "             The text output is stored in the file out.allcostX.txt.", "", "             This operation is informational only, to help evaluate alignment", "             costs across subjects.", "", "             Please see '3dAllineate -help' for more details.", "", "        -volreg_compute_tsnr yes/no : compute TSNR datasets from volreg output", "", "                e.g. -volreg_compute_tsnr yes", "                default: no", "", "            Use this option to compute a temporal signal to noise (TSNR)", "            dataset at the end of the volreg block.  Both the signal and noise", "            datasets are from the run 1 output, where the \"signal\" is the mean", "            and the \"noise\" is the detrended time series.", "", "            TSNR = average(signal) / stdev(noise)", "", "            See also -regress_compute_tsnr.", "", "        -volreg_interp METHOD   : specify the interpolation method for volreg", "", "                e.g. -volreg_interp -quintic", "                e.g. -volreg_interp -Fourier", "                default: -cubic", "", "            Please see '3dvolreg -help' for more information.", "", "        -volreg_motsim          : generate motion simulated time series", "", "            Use of this option will result in a 'motsim' (motion simulation)", "            time series dataset that is akin to an EPI dataset altered only", "            by motion and registration (no BOLD, no signal drift, etc).", "", "            This dataset can be used to generate regressors of no interest to", "            be used in the regression block.", "", "            rcr - note relevant options once they are in", "", "            Please see '@simulate_motion -help' for more information.", "", "        -volreg_opts_ms OPTS ... : specify extra options for @simulate_motion", "", "                e.g. -volreg_opts_ms -save_workdir", "", "            This option can be used to pass extra options directly to the", "            @simulate_motion command.", "", "            See also -volreg_motsim.", "            Please see '@simulate_motion -help' for more information.", "", "        -volreg_opts_vr OPTS ... : specify extra options for 3dvolreg", "", "                e.g. -volreg_opts_vr -twopass", "                e.g. -volreg_opts_vr -noclip -nomaxdisp", "", "            This option allows the user to add extra options to the 3dvolreg", "            command.  Note that only one -volreg_opts_vr should be applied,", "            which may be used for multiple 3dvolreg options.", "", "            Please see '3dvolreg -help' for more information.", "", "        -volreg_no_extent_mask  : do not create and apply extents mask", "", "                default: apply extents mask", "", "            This option says not to create or apply the extents mask.", "", "            The extents mask:", "", "            When EPI data is transformed to the anatomical grid in either orig", "            or tlrc space (i.e. if -volreg_align_e2a or -volreg_tlrc_warp is", "            applied), then the complete EPI volume will only cover part of the", "            resulting volume space.  Worse than that, the coverage will vary", "            over time, as motion will alter the final transformation (remember", "            that volreg, EPI->anat and ->tlrc transformations are all combined,", "            to prevent multiple resampling steps).  The result is that edge", "            voxels will sometimes have valid data and sometimes not.", "", "            The extents mask is made from an all-1 dataset that is warped with", "            the same per-TR transformations as the EPI data.  The intersection", "            of the result is the extents mask, so that every voxel in the", "            extents mask has data at every time point.  Voxels that are not", "            are missing data from some or all TRs.", "", "            It is called the extents mask because it defines the 'bounding box'", "            of valid EPI data.  It is not quite a tiled box though, as motion", "            changes the location slightly, per TR.", "", "            See also -volreg_align_e2a, -volreg_tlrc_warp.", "            See also the 'extents' mask, in the \"MASKING NOTE\" section above.", "", "        -volreg_regress_per_run : regress motion parameters from each run", "", "            === This option has been replaced by -regress_motion_per_run. ===", "", "        -volreg_tlrc_adwarp     : warp EPI to +tlrc space at end of volreg step", "", "                default: stay in +orig space", "", "            With this option, the EPI data will be warped to standard space", "            (via adwarp) at the end of the volreg processing block.  Further", "            processing through regression will be done in standard space.", "", "            This option is useful for applying a manual Talairach transform,", "            which does not work with -volreg_tlrc_warp.  To apply one from", "            @auto_tlrc, -volreg_tlrc_warp is recommended.", "", "            The resulting voxel grid is the minimum dimension, truncated to 3", "            significant bits.  See -volreg_warp_dxyz for details.", "", "            Note: this step requires a transformed anatomy, which can come from", "            the -tlrc_anat option or from -copy_anat importing an existing one.", "", "            Please see 'WARP TO TLRC NOTE' above, for additional details.", "            See also -volreg_tlrc_warp, -volreg_warp_dxyz, -tlrc_anat,", "            -copy_anat.", "", "        -volreg_tlrc_warp       : warp EPI to +tlrc space at volreg step", "", "                default: stay in +orig space", "", "            With this option, the EPI data will be warped to standard space", "            in the volreg processing block.  All further processing through", "            regression will be done in standard space.", "", "            Warping is done with volreg to apply both the volreg and tlrc", "            transformations in a single step (so a single interpolation of the", "            EPI data).  The volreg transformations (for each volume) are stored", "            and multiplied by the +tlrc transformation, while the volume", "            registered EPI data is promptly ignored.", "", "            The volreg/tlrc (affine or non-linear) transformation is then", "            applied as a single concatenated warp to the unregistered data.", "", "            Note that the transformation concatenation is not possible when", "            using the 12-piece manual transformation (see -volreg_tlrc_adwarp", "            for details).", "", "            The resulting voxel grid is the minimum dimension, truncated to 3", "            significant bits.  See -volreg_warp_dxyz for details.", "", "            Note: this step requires a transformed anatomy, which can come from", "            the -tlrc_anat option or from -copy_anat importing an existing one.", "", "            Please see 'WARP TO TLRC NOTE' above, for additional details.", "            See also -volreg_tlrc_adwarp, -volreg_warp_dxyz, -tlrc_anat,", "            -copy_anat.", "", "        -volreg_warp_dxyz DXYZ  : grid dimensions for _align_e2a or _tlrc_warp", "", "                e.g. -volreg_warp_dxyz 3.5", "                default: min dim truncated to 3 significant bits", "                         (see description, below)", "", "            This option allows the user to specify the grid size for output", "            datasets from the -volreg_tlrc_warp and -volreg_align_e2a options.", "            In either case, the output grid will be isotropic voxels (cubes).", "", "            By default, DXYZ is the minimum input dimension, truncated to", "            3 significant bits (for integers, starts affecting them at 9, as", "            9 requires 4 bits to represent).", "", "            Some examples:", "                ----------------------------  (integer range, so >= 4)", "                8.00   ...  9.99   --> 8.0", "                ...", "                4.00   ...  4.99   --> 4.0", "                ----------------------------  (3 significant bits)", "                2.50   ...  2.99   --> 2.5", "                2.00   ...  2.49   --> 2.0", "                1.75   ...  1.99   --> 1.75", "                1.50   ...  1.74   --> 1.5", "                1.25   ...  1.49   --> 1.25", "                1.00   ...  1.24   --> 1.0", "                0.875  ...  0.99   --> 0.875", "                0.75   ...  0.874  --> 0.75", "                0.625  ...  0.74   --> 0.625", "                0.50   ...  0.624  --> 0.50", "                0.4375 ...  0.49   --> 0.4375", "                0.375  ...  0.4374 --> 0.375", "                ...", "", "        -volreg_zpad N_SLICES   : specify number of slices for -zpad", "", "                e.g. -volreg_zpad 4", "                default: -volreg_zpad 1", "", "            This option allows the user to specify the number of slices applied", "            via the -zpad option to 3dvolreg.", "", "        -surf_anat ANAT_DSET    : specify surface volume dataset", "", "                e.g. -surf_anat SUMA/sb23_surf_SurfVol+orig", "", "            This option is required in order to do surface-based analysis.", "", "            This volumetric dataset should be the one used for generation of", "            the surface (and therefore should be in perfect alignment).  It may", "            be output by the surface generation software.", "", "            Unless specified by the user, the processing script will register", "            this anatomy with the current anatomy.", "", "            Use -surf_anat_aligned if the surf_anat is already aligned with the", "            current experiment.", "", "            Use '-surf_anat_has_skull no' if the surf_anat has already been", "            skull stripped.", "", "            Please see '@SUMA_AlignToExperiment -help' for more details.", "            See also -surf_anat_aligned, -surf_anat_has_skull.", "            See example #8 for typical usage.", "", "        -surf_spec spec1 [spec2]: specify surface specificatin file(s)", "", "                e.g. -surf_spec SUMA/sb23_?h_141_std.spec", "", "            Use this option to provide either 1 or 2 spec files for surface", "            analysis.  Each file must have lh or rh in the name (to encode", "            the hemisphere), and that can be their only difference.  So if", "            the files do not have such a naming pattern, they should probably", "            be copied to new files that do.  For example, consider the spec", "            files included with the AFNI_data4 sample data:", "", "                SUMA/sb23_lh_141_std.spec", "                SUMA/sb23_rh_141_std.spec", "", "        -surf_A surface_A       : specify first surface for mapping", "", "                e.g. -surf_A smoothwm", "                default: -surf_A smoothwm", "", "            This option allows the user to specify the first (usually inner)", "            surface for use when mapping from the volume and for blurring.", "            If the option is not given, the smoothwm surface will be assumed.", "", "        -surf_B surface_B       : specify second surface for mapping", "", "                e.g. -surf_B pial", "                default: -surf_B pial", "", "            This option allows the user to specify the second (usually outer)", "            surface for use when mapping from the volume (not for blurring).", "            If the option is not given, the pial surface will be assumed.", "", "        -surf_blur_fwhm FWHM    :  NO LONGER VALID", "", "            Please use -blur_size, instead.", "", "        -blur_filter FILTER     : specify 3dmerge filter option", "", "                e.g. -blur_filter -1blur_rms", "                default: -1blur_fwhm", "", "            This option allows the user to specify the filter option from", "            3dmerge.  Note that only the filter option is set here, not the", "            filter size.  The two parts were separated so that users might", "            generally worry only about the filter size.", "", "            Please see '3dmerge -help' for more information.", "            See also -blur_size.", "", "        -blur_in_automask       : apply 3dBlurInMask -automask", "", "            This option forces use of 3dBlurInMask -automask, regardless of", "            whether other masks exist and are being applied.", "", "            Note that one would not want to apply -automask via -blur_opts_BIM,", "            as that might result in failure because of multiple -mask options.", "", "            Note that -blur_in_automask implies '-blur_in_mask yes'.", "", "            Please see '3dBlurInMask -help' for more information.", "            See also -blur_in_mask, -blur_opts_BIM.", "", "        -blur_in_mask yes/no    : specify whether to restrict blur to a mask", "", "                e.g. -blur_in_mask yes", "                default: no", "", "            This option allows the user to specify whether to use 3dBlurInMask", "            instead of 3dmerge for blurring.", "", "            Note that the algorithms are a little different, and 3dmerge comes", "            out a little more blurred.", "", "            Note that 3dBlurInMask uses only FWHM kernel size units, so the", "            -blur_filter should be either -1blur_fwhm or -FWHM.", "", "            Please see '3dBlurInMask -help' for more information.", "            Please see '3dmerge -help' for more information.", "            See also -blur_filter.", "", "        -blur_opts_BIM OPTS ...  : specify extra options for 3dBlurInMask", "", "                e.g. -blur_opts_BIM -automask", "", "            This option allows the user to add extra options to the 3dBlurInMask", "            command.  Only one -blur_opts_BIM should be applied, which may be", "            used for multiple 3dBlurInMask options.", "", "            This option is only useful when '-blur_in_mask yes' is applied.", "", "            Please see '3dBlurInMask -help' for more information.", "            See also -blur_in_mask.", "", "        -blur_opts_merge OPTS ... : specify extra options for 3dmerge", "", "                e.g. -blur_opts_merge -2clip -20 50", "", "            This option allows the user to add extra options to the 3dmerge", "            command.  Note that only one -blur_opts_merge should be applied,", "            which may be used for multiple 3dmerge options.", "", "            Please see '3dmerge -help' for more information.", "", "        -blur_size SIZE_MM      : specify the size, in millimeters", "", "                e.g. -blur_size 6.0", "                default: 4", "", "            This option allows the user to specify the size of the blur used", "            by 3dmerge (or another applied smoothing program).  It is applied", "            as the 'bmm' parameter in the filter option (such as -1blur_fwhm)", "            in 3dmerge.", "", "            Note the relationship between blur sizes, as used in 3dmerge:", "", "                sigma = 0.57735027 * rms = 0.42466090 * fwhm", "                (implying fwhm = 1.359556 * rms)", "", "            Programs 3dmerge and 3dBlurInMask apply -blur_size as an additional", "            gaussian blur.  Therefore smoothing estimates should be computed", "            per subject for the correction for multiple comparisons.", "", "            Programs 3dBlurToFWHM and SurfSmooth apply -blur_size as the", "            resulting blur, and so do not requre blur estimation.", "", "            Please see '3dmerge -help'      for more information.", "            Please see '3dBlurInMask -help' for more information.", "            Please see '3dBlurToFWHM -help' for more information.", "            Please see 'SurfSmooth -help'   for more information.", "            See also -blur_filter.", "", "        -blur_to_fwhm           : blur TO the blur size (not add a blur size)", "", "            This option changes the program used to blur the data.  Instead of", "            using 3dmerge, this applies 3dBlurToFWHM.  So instead of adding a", "            blur of size -blur_size (with 3dmerge), the data is blurred TO the", "            FWHM of the -blur_size.", "", "            Note that 3dBlurToFWHM should be run with a mask.  So either:", "                o  put the 'mask' block before the 'blur' block, or", "                o  use -blur_in_automask", "            It is not appropriate to include non-brain in the blur estimate.", "", "            Note that extra options can be added via -blur_opts_B2FW.", "", "            Please see '3dBlurToFWHM -help' for more information.", "            See also -blur_size, -blur_in_automask, -blur_opts_B2FW.", "", "        -blur_opts_B2FW OPTS ... : specify extra options for 3dBlurToFWHM", "", "                e.g. -blur_opts_B2FW -rate 0.2 -temper", "", "            This allows the user to add extra options to the 3dBlurToFWHM", "            command.  Note that only one -blur_opts_B2FW should be applied,", "            which may be used for multiple 3dBlurToFWHM options.", "", "            Please see '3dBlurToFWHM -help' for more information.", "", "        -mask_apply TYPE        : specify which mask to apply in regression", "", "                e.g. -mask_apply group", "", "            If possible, masks will be made for the EPI data, the subject", "            anatomy, the group anatomy and EPI warp extents.  This option is", "            used to specify which of those masks to apply to the regression.", "", "            Valid choices: epi, anat, group, extents.", "", "            A subject 'anat' mask will be created if the EPI anat anatomy are", "            aligned, or if the EPI data is warped to standard space via the", "            anat transformation.  In any case, a skull-stripped anat will exist.", "", "            A 'group' anat mask will be created if the 'tlrc' block is used", "            (via the -blocks or -tlrc_anat options).  In such a case, the anat", "            template will be made into a binary mask.", "", "            This option makes -regress_apply_mask obsolete.", "", "            See \"MASKING NOTE\" and \"DEFAULTS\" for details.", "            See also -blocks.", "", "        -mask_dilate NUM_VOXELS : specify the automask dilation", "", "                e.g. -mask_dilate 3", "                default: 1", "", "            By default, the masks generated from the EPI data are dilated by", "            1 step (voxel), via the -dilate option in 3dAutomask.  With this", "            option, the user may specify the dilation.  Valid integers must", "            be at least zero.", "", "            Note that 3dAutomask dilation is a little different from the", "            natural voxel-neighbor dilation.", "", "            Please see '3dAutomask -help' for more information.", "            See also -mask_type.", "", "        -mask_epi_anat yes/no : apply epi_anat mask in place of EPI mask", "", "                e.g. -mask_epi_anat yes", "", "            An EPI mask might be applied to the data either for simple", "            computations (e.g. global brain correlation, GCOR), or actually", "            applied to the EPI data.  The EPI mask $full_mask is used for most", "            such computations, by default.", "", "            The mask_epi_anat dataset is an intersection of full_mask and", "            mask_anat, and might be better suited to such computations.", "", "            Use this option to apply mask_epi_anat in place of full_mask.", "", "        -mask_import LABEL MSET : import a final grid mask with the given label", "", "                e.g. -mask_import Tvent template_ventricle_3mm+tlrc", "", "            Use this option to import a mask that is aligned with the final", "            EPI data _and_ is on the final grid.", "", "                o  this might be based on the group template", "                o  this should already be resampled appropriately", "                o  no warping or resampling will be done to this dataset", "", "            This mask can be applied via LABEL as other masks, using options", "            like: -regress_ROI, -regress_ROI_PC, -regress_make_corr_vols,", "                  -regress_anaticor_label, -mask_intersect, -mask_union.", "", "            For example, one might import a ventricle mask from the template,", "            intersect it with the subject specific CSFe (eroded CSF) mask,", "            and possibly take the union with WMe (eroded white matter), before", "            using the result for principle component regression, as in:", "", "                -mask_import Tvent template_ventricle_3mm+tlrc \\", "                -mask_intersect Svent CSFe Tvent               \\", "                -mask_union WM_vent Svent WMe                  \\", "                -regress_ROI_PC WM_vent 3                      \\", "", "            See also -regress_ROI, -regress_ROI_PC, -regress_make_corr_vols,", "                     -regress_anaticor_label, -mask_intersect, -mask_union.", "", "        -mask_intersect NEW_LABEL MASK_A MASK_B : intersect 2 masks", "", "                e.g. -mask_intersect Svent CSFe Tvent", "", "            Use this option to intersect 2 known masks to create a new mask.", "            NEW_LABEL will be the label of the result, while MASK_A and MASK_B", "            should be labels for existing masks.", "", "            One could use this to intersect a template ventricle mask with each", "            subject's specific CSFe (eroded CSF) mask from 3dSeg, for example.", "", "            See -mask_import for more details.", "", "        -mask_union NEW_LABEL MASK_A MASK_B : take union of 2 masks", "", "                e.g. -mask_union WM_vent Svent WMe", "", "            Use this option to take the union of 2 known masks to create a new", "            mask.  NEW_LABEL will be the label of the result, while MASK_A and", "            MASK_B should be labels for existing masks.", "", "            One could use this to create union of CSFe and WMe for principle", "            component regression, for example.", "", "            See -mask_import for more details.", "", "        -mask_rm_segsy Y/N  : choose whether to delete the Segsy directory", "", "                e.g. -mask_rm_segsy no", "                default: yes", "", "            This option is a companion to -mask_segment_anat.", "", "            In the case of running 3dSeg to segment the anatomy, a resulting", "            Segsy directory is created.  Since the main result is a Classes", "            dataset, and to save disk space, the Segsy directory is removed", "            by default.  Use this option to preserve it.", "", "            See also -mask_segment_anat.", "", "        -mask_segment_anat Y/N  : choose whether to segment anatomy", "", "                e.g. -mask_segment_anat yes", "                default: no (if anat_final is skull-stripped)", "", "            This option controls whether 3dSeg is run to segment the anatomical", "            dataset.  Such a segmentation would then be resampled to match the", "            grid of the EPI data.", "", "            When this is run, 3dSeg creates the Classes dataset, which is a", "            composition mask of the GM/WM/CSF (gray matter, white matter and", "            cerebral spinal fluid) regions.  Then 3dresample is used to create", "            Classes_resam, the same mask but at the resolution of the EPI.", "", "            Such a dataset might have multiple uses, such as tissue-based", "            regression.  Note that for such a use, the ROI time series should", "            come from the volreg data, before any blur.", "", "          * Mask labels created by -mask_segment_anat and -mask_segment_erode", "            can be applied with -regress_ROI and -regress_ROI_PC.", "", "          * The CSF mask is of ALL CSF (not just in the ventricles), and is", "            therefore not very appropriate to use with tissue-based regression.", "", "            Consider use of -anat_uniform_method along with this option.", "", "            Please see '3dSeg -help' for more information.", "            Please see '3dUnifize -help' for more information.", "            See also -mask_rm_segsy, -anat_uniform_method -mask_segment_erode,", "             and -regress_ROI, -regress_ROI_PC.", "", "        -mask_segment_erode Y/N", "", "                e.g. -mask_segment_erode Yes", "                default: yes (if -regress_ROI or -regress_anaticor)", "", "            This option is a companion to -mask_segment_anat.", "", "            Anatomical segmentation is used to create GM (gray matter), WM", "            (white matter) and CSF masks.  When the _erode option is applied,", "            eroded versions of those masks are created via 3dmask_tool.", "", "            See also -mask_segment_anat, -regress_anaticor.", "            Please see '3dmask_tool -help' for more information.", "", "        -mask_test_overlap Y/N  : choose whether to test anat/EPI mask overlap", "", "                e.g. -mask_test_overlap No", "                default: Yes", "", "            If the subject anatomy and EPI masks are computed, then the default", "            operation is to run 3dABoverlap to evaluate the overlap between the", "            two masks.  Output is saved in a text file.", "", "            This option allows one to disable such functionality.", "", "            Please see '3dABoverlap -help' for more information.", "", "        -mask_type TYPE         : specify 'union' or 'intersection' mask type", "", "                e.g. -mask_type intersection", "                default: union", "", "            This option is used to specify whether the mask applied to the", "            analysis is the union of masks from each run, or the intersection.", "            The only valid values for TYPE are 'union' and 'intersection'.", "", "            This is not how to specify whether a mask is created, that is", "            done via the 'mask' block with the '-blocks' option.", "", "            Please see '3dAutomask -help', '3dMean -help' or '3dcalc -help'.", "            See also -mask_dilate, -blocks.", "", "        -combine_method METHOD  : specify method for combining echoes", "", "                e.g. -combine_method OC", "                default: OC", "", "            When using the 'combine' block to combine echoes (for each run),", "            this option can be used to specify the method used.   Methods:", "", "                mean             : simple mean of echoes", "                OC               : optimally combined (via @compute_OC_weights)", "                                   (current default is OC_A)", "                OC_A             : original log(mean()) regression method", "                OC_B             : newer log() time series regression method", "                                   (there is little difference between OC_A", "                                   and OC_B)", "                OC_tedort        : OC, and pass tedana orts to regression", "                tedana           : run tedana.py, using output dn_ts_OC.nii", "                tedana_OC        : run tedana.py, using output ts_OC.nii", "                                   (i.e. use tedana.py for optimally combined)", "                tedana_OC_tedort : tedana_OC, and include tedana orts", "", "            The OC/OC_A combine method is from Posse et. al., 1999, and then", "            applied by Kundu et. al., 2011 and presented by Javier in a 2017", "            summer course.", "", "            The 'tedort' methods are applied using @extract_meica_ortvec,", "            which projects the 'good' MEICA components out of the 'bad' ones,", "            and saves those as regressors to be applied later.  Otherwise, some", "            of the 'good' components are removed with the 'bad.  The tedort", "            method can be applied with either AFNI OC or tedana OC (meaning", "            the respective OC method would be applied to combine the echoes,", "            and the tedort components will be passed on to the regress block).", "", "            Please see '@compute_OC_weights -help' for more information.", "            Please see '@extract_meica_ortvec -help' for more information.", "            See also -combine_tedana_path.", "", "        -combine_opts_tedana OPT OPT ... : specify extra options for tedana.py", "", "                e.g. -combine_opts_tedana --sourceTEs=-1 --kdaw=10 --rdaw=1", "", "            Use this option to pass extra options through to tedana.py.", "            This applies to any tedana-based -combine_method.", "", "            See also -combine_method.", "", "        -combine_opts_tedwrap OPT OPT ... : pass options to tedana_wrapper.py", "", "                e.g. -combine_opts_tedwrap -tedana_is_exec", "", "            Use this option to pass extra options to tedana_wrapper.py.", "            This applies to any tedana-based -combine_method.", "", "        -combine_tedana_path PATH : specify path to tedana.py", "", "                e.g. -combine_tedana_path ~/testbin/meica.libs/tedana.py", "                default: from under afni binaries directory", "", "            If one wishes to use a version of tedana.py other than what comes", "            with AFNI, this option allows one to specify that file.", "", "            This applies to any tedana-based -combine_method.", "", "            See also -combine_method.", "", "        -scale_max_val MAX      : specify the maximum value for scaled data", "", "                e.g. -scale_max_val 1000", "                default 200", "", "            The scale step multiples the time series for each voxel by a", "            scalar so that the mean for that particular run is 100 (allowing", "            interpretation of EPI values as a percentage of the mean).", "", "            Values of 200 represent a 100% change above the mean, and so can", "            probably be considered garbage (or the voxel can be considered", "            non-brain).  The output values are limited so as not to sacrifice", "            the precision of the values of short datasets.  Note that in a", "            short (2-byte integer) dataset, a large range of values means", "            bits of accuracy are lost for the representation.", "", "            No max will be applied if MAX is <= 100.", "", "            Please see 'DATASET TYPES' in the output of '3dcalc -help'.", "            See also -scale_no_max.", "", "        -scale_no_max           : do not apply a limit to the scaled values", "", "            The default limit for scaled data is 200.  Use of this option will", "            remove any limit from being applied.", "", "            A limit on the scaled data is highly encouraged when working with", "            'short' integer data, especially when not applying a mask.", "", "            See also -scale_max_val.", "", "        -regress_3dD_stop       : 3dDeconvolve should stop after X-matrix gen", "", "            Use this option to tell 3dDeconvolve to stop after generating the", "            X-matrix (via -x1D_stop).  This is useful if the user only wishes", "            to run the regression through 3dREMLfit.", "", "            See also -regress_reml_exec.", "", "        -regress_anaticor       : generate errts using ANATICOR method", "", "            Apply the ANATICOR method of HJ Jo, regressing out the WMeLocal", "            time series, which varies across voxels.", "", "            WMeLocal is the average time series from all voxels within 45 mm", "            which are in the eroded white matter mask.", "", "            The script will run the standard regression via 3dDeconvolve (or", "            stop after setting up the X-matrix, if the user says to), and use", "            that X-matrix, possibly censored, in 3dTproject.  The WMeLocal time", "            series is applied along with the X-matrix to get the result.", "", "            Note that other 4-D time series might be regressed out via the", "            3dTproject step, as well.", "", "            In the case of task-based ANATICOR, -regress_reml_exec is required,", "            which uses 3dREMLfit to regress the voxel-wise ANATICOR regressors.", "", "            This option implies -mask_segment_anat and -mask_segment_erode.", "", "          * Consider use of -regress_anaticor_fast, instead.", "", "            Please see \"@ANATICOR -help\" for more detail, including the paper", "            reference for the method.", "            See also -mask_segment_anat, -mask_segment_erode, -regress_3dD_stop.", "            See also -regress_reml_exec.", "", "        -regress_anaticor_label LABEL : specify LABEL for ANATICOR ROI", "", "            To go with either -regress_anaticor or -regress_anaticor_fast,", "            this option is used the specifiy an alternate label of an ROI", "            mask to be used in the ANATICOR step.  The default LABEL is WMe", "            (eroded white matter from 3dSeg).", "", "            When this option is included, it is up to the user to make sure", "            afni_proc.py has such a label, either by including options:", "                -mask_segment_anat (and possibly -mask_segment_erode),", "                -regress_ROI_PC, -regress_ROI, or -anat_follower_ROI.", "", "            Any known label made via those options may be used.", "", "            See also -mask_segment_anat, -mask_segment_erode, -regress_ROI_PC,", "                -anat_follower_ROI.", "", "        -regress_anaticor_radius RADIUS : specify RADIUS for 3dLocalstat", "", "            To go with -regress_anaticor, use this option to specify the radius", "            of spheres within which local white matter is averaged.  A small", "            radius means the white matter is more local.  It is also faster.", "", "            If no white matter is found within the specified distance of some", "            voxel, the effect is that ANATICOR will simply not happen at that", "            voxel.  That is a reasonable \"failure\" case, in that it says there", "            is simply no white matter close enough to regress out (again, at", "            the given voxel).", "", "            See also -regress_anaticor.", "", "        -regress_anaticor_fast  : generate errts using fast ANATICOR method", "", "            This applies basically the same method as with -regress_anaticor,", "            above.  While -regress_anaticor creates WMeLocal dataset by", "            getting the average white matter voxel within a fixed radius, the", "            'fast' method computes it by instead integrating the white matter", "            over a gaussian curve.", "", "            There some basic effects of using the 'fast' method:", "", "                1. Using a Gaussian curve to compute each voxel-wise regressor", "                   gives more weight to the white matter that is closest to", "                   each given voxel.  The FWHM of this 3D kernel is specified", "                   by -regress_anaticor_fwhm, with a default of 30 mm.", "", "                2. If there is no close white matter (e.g. due to a poor", "                   segmentation), the Gaussian curve will likely find white", "                   matter far away, instead of creating an empty regressor.", "", "                3. This is quite a bit faster, because it is done by creating", "                   a time series of all desired white matter voxels, blurring", "                   it, and then just regressing out that dataset.  The blur", "                   operation is much faster than a localstat one.", "", "            Please see \"@ANATICOR -help\" for more detail, including the paper", "            reference for the method.", "            See also -regress_anaticor_fwhm/", "            See also -mask_segment_anat, -mask_segment_erode, -regress_3dD_stop.", "            See also -regress_anaticor.", "", "        -regress_anaticor_fwhm FWHM  : specify FWHM for 'fast' ANATICOR, in mm", "", "                e.g.     -regress_anaticor_fwhm 20", "                default: -regress_anaticor_fwhm 30", "", "            This option applies to -regress_anaticor_fast.", "", "            The 'fast' ANATICOR method blurs the time series of desired white", "            matter voxels using a Gaussian kernel with the given FWHM (full", "            width at half maximum).", "", "            To understand the FWHM, note that it is essentially the diameter of", "            a sphere where the contribution from points at that distance", "            (FWHM/2) contribute half as much as the center point.  For example,", "            if FWHM=10mm, then any voxel at a distance of 5 mm would contribute", "            half as much as a voxel at the center of the kernel.", "", "            See also -regress_anaticor_fast.", "", "        -regress_apply_mask     : apply the mask during scaling and regression", "", "            By default, any created union mask is not applied to the analysis.", "            Use this option to apply it.", "", "         ** This option is essentially obsolete.  Please consider -mask_apply", "            as a preferable option to choose which mask to apply.", "", "            See \"MASKING NOTE\" and \"DEFAULTS\" for details.", "            See also -blocks, -mask_apply.", "", "        -regress_apply_mot_types TYPE1 ... : specify motion regressors", "", "                e.g. -regress_apply_mot_types basic", "                e.g. -regress_apply_mot_types deriv", "                e.g. -regress_apply_mot_types demean deriv", "                default: demean", "", "            By default, the motion parameters from 3dvolreg are applied in the", "            regression, but after first removing the mean, per run.  This is", "            the application of the 'demean' regressors.", "", "            This option gives the ability to choose a combination of:", "", "                basic:  dfile_rall.1D - the parameters straight from 3dvolreg", "                        (or an external motion file, see -regress_motion_file)", "                demean: 'basic' params with the mean removed, per run", "                deriv:  per-run derivative of 'basic' params (de-meaned)", "", "         ** Note that basic and demean cannot both be used, as they would cause", "            multi-collinearity with the constant drift parameters.", "", "         ** Note also that basic and demean will give the same results, except", "            for the betas of the constant drift parameters (and subject to", "            computational precision).", "", "         ** A small side effect of de-meaning motion parameters is that the", "            constant drift terms should evaluate to the mean baseline.", "", "            See also -regress_motion_file, -regress_no_motion_demean,", "            -regress_no_motion_deriv, -regress_no_motion.", "", "        -regress_apply_ricor yes/no : apply ricor regs in final regression", "", "                e.g.     -regress_apply_ricor yes", "                default: no", "", "            This is from a change in the default behavior 30 Jan 2012.  Prior", "            to then, the 13 (?) ricor regressors from slice 0 would be applied", "            in the final regression (mostly accounting for degrees of freedom).", "            But since resting state analysis relies on a subsequent correlation", "            analysis, it seems cleaner not to regress them (a second time).", "", "        -regress_bandpass lowf highf : bandpass the frequency range", "", "                e.g.  -regress_bandpass 0.01 0.1", "", "            This option is intended for use in resting state analysis.", "", "            Use this option to perform bandpass filtering during the linear", "            regression.  While such an operation is slow (much slower than the", "            FFT using 3dBandpass), doing it during the regression allows one to", "            perform (e.g. motion) censoring at the same time.", "", "            This option has a similar effect to running 3dBandpass, e.g. the", "            example of '-regress_bandpass 0.01 0.1' is akin to running:", "", "                3dBandpass -ort motion.1D -band 0.01 0.1", "", "            except that it is done in 3dDeconvolve using linear regression.", "            And censoring is easy in the context of regression.", "", "            Note that the Nyquist frequency is 0.5/TR.  That means that if the", "            TR were >= 5 seconds, there would be no frequencies within the band", "            range of 0.01 to 0.1 to filter.  So there is no point to such an", "            operation.", "", "            On the flip side, if the TR is 1.0 second or shorter, the range of", "            0.01 to 0.1 would remove about 80% of the degrees of freedom (since", "            everything above 0.1 is filtered/removed, up through 0.5).  This", "            might result in a model that is overfit, where there are almost as", "            many (or worse, more) regressors than time points to fit.", "", "            So a 0.01 to 0.1 bandpass filter might make the most sense for a", "            TR in [2.0, 3.0], or so.", "", "            A different filter range would affect this, of course.", "", "            See also -regress_censor_motion.", "", "        -regress_basis BASIS    : specify the regression basis function", "", "                e.g. -regress_basis 'BLOCK(4,1)'", "                e.g. -regress_basis 'BLOCK(5)'", "                e.g. -regress_basis 'TENT(0,14,8)'", "                default: GAM", "", "            This option is used to set the basis function used by 3dDeconvolve", "            in the regression step.  This basis function will be applied to", "            all user-supplied regressors (please let me know if there is need", "            to apply different basis functions to different regressors).", "", "         ** Note that use of dmBLOCK requires -stim_times_AM1 (or AM2).  So", "            consider option -regress_stim_types.", "", "         ** If using -regress_stim_types 'file' for a particular regressor,", "            the basis function will be ignored.  In such a case, it is safest", "            to use 'NONE' for the corresponding basis function.", "", "            Please see '3dDeconvolve -help' for more information, or the link:", "                https://afni.nimh.nih.gov/afni/doc/misc/3dDeconvolveSummer2004", "            See also -regress_basis_normall, -regress_stim_times,", "                     -regress_stim_types, -regress_basis_multi.", "", "        -regress_basis_multi BASIS BASIS .. : specify multiple basis functions", "", "                e.g. -regress_basis_multi 'BLOCK(30,1)' 'TENT(0,45,16)' \\", "                                          'BLOCK(30,1)' dmUBLOCK", "", "            In the case that basis functions vary across stim classes, use", "            this option to list a basis function for each class.  The given", "            basis functions should correspond to the listed -regress_stim_times", "            files, just as the -regress_stim_labels entries do.", "", "            See also -regress_basis.", "", "        -regress_basis_normall NORM : specify the magnitude of basis functions", "", "                e.g. -regress_basis_normall 1.0", "", "            This option is used to set the '-basis_normall' parameter in", "            3dDeconvolve.  It specifies the height of each basis function.", "", "            For the example basis functions, -basis_normall is not recommended.", "", "            Please see '3dDeconvolve -help' for more information.", "            See also -regress_basis.", "", "        -regress_censor_extern CENSOR.1D : supply an external censor file", "", "                e.g. -regress_censor_extern censor_bad_trs.1D", "", "            This option is used to provide an initial censor file, if there", "            is some censoring that is desired beyond the automated motion and", "            outlier censoring.", "", "            Any additional censoring (motion or outliers) will be combined.", "", "             See also -regress_censor_motion, -regress_censor_outliers.", "", "        -regress_censor_motion LIMIT : censor TRs with excessive motion", "", "                e.g. -regress_censor_motion 0.3", "", "            This option is used to censor TRs where the subject moved too much.", "            \"Too much\" is decided by taking the derivative of the motion", "            parameters (ignoring shifts between runs) and the sqrt(sum squares)", "            per TR.  If this Euclidean Norm exceeds the given LIMIT, the TR", "            will be censored.", "", "            This option will result in the creation of 3 censor files:", "", "                motion_$subj_censor.1D", "                motion_$subj_CENSORTR.txt", "                motion_$subj_enorm.1D", "", "            motion_$subj_censor.1D is a 0/1 columnar file to be applied to", "            3dDeconvolve via -censor.  A row with a 1 means to include that TR,", "            while a 0 means to exclude (censor) it.", "", "            motion_$subj_CENSORTR.txt is a short text file listing censored", "            TRs, suitable for use with the -CENSORTR option in 3dDeconvolve.", "            The -censor option is the one applied however, so this file is not", "            used, but may be preferable for users to have a quick peek at.", "", "            motion_$subj_enorm.1D is the time series that the LIMIT is applied", "            to in deciding which TRs to censor.  It is the Euclidean norm of", "            the derivatives of the motion parameters.  Plotting this will give", "            users a visual indication of why TRs were censored.", "", "            By default, the TR prior to the large motion derivative will also", "            be censored.  To turn off that behavior, use -regress_censor_prev", "            with parameter 'no'.", "", "            If censoring the first few TRs from each run is also necessary,", "            use -regress_censor_first_trs.", "", "            Please see '1d_tool.py -help' for information on censoring motion.", "            See also -regress_censor_prev and -regress_censor_first_trs.", "", "        -regress_censor_first_trs N  : censor the first N TRs in each run", "", "                e.g.     -regress_censor_first_trs 3", "                default: N = 0", "", "            If, for example, censoring the first 3 TRs per run is desired, a", "            user might add \"-CENSORTR '*:0-2'\" to the -regress_opts_3dD option.", "            However, when using -regress_censor_motion, these censoring options", "            must be combined into one for 3dDeconvolve.", "", "            The -regress_censor_first_trs censors those TRs along with any with", "            large motion.", "", "            See '-censor_first_trs' under '1d_tool.py -help' for details.", "            See also '-regress_censor_motion'.", "", "        -regress_censor_prev yes/no  : censor TRs preceding large motion", "", "                default: -regress_censor_prev yes", "", "            Since motion spans two TRs, the derivative is not quite enough", "            information to decide whether it is more appropriate to censor", "            the earlier or later TR.  To error on the safe side, many users", "            choose to censor both.", "", "            Use this option to specify whether to include the previous TR", "            when censoring.", "", "            By default this option is applied as 'yes'.  Users may elect not", "            not to censor the previous TRs by setting this to 'no'.", "", "            See also -regress_censor_motion.", "", "        -regress_censor_outliers LIMIT : censor TRs with excessive outliers", "", "                e.g. -regress_censor_outliers 0.15", "", "            This option is used to censor TRs where too many voxels are flagged", "            as outliers by 3dToutcount.  LIMIT should be in [0.0, 1.0], as it", "            is a limit on the fraction of masked voxels.", "", "            '3dToutcount -automask -fraction' is used to output the fraction of", "            (auto)masked voxels that are considered outliers at each TR.  If", "            the fraction of outlier voxels is greater than LIMIT for some TR,", "            that TR is censored out.", "", "            Depending on the scanner settings, early TRs might have somewhat", "            higher intensities.  This could lead to the first few TRs of each", "            run being censored.  To avoid censoring the first few TRs of each", "            run, apply the -regress_skip_first_outliers option.", "", "            Note that if motion is also being censored, the multiple censor", "            files will be combined (multiplied) before 3dDeconvolve.", "", "            See '3dToutcount -help' for more details.", "            See also -regress_skip_first_outliers, -regress_censor_motion.", "", "        -regress_compute_gcor yes/no : compute GCOR from unit errts", "", "                e.g. -regress_compute_gcor no", "                default: yes", "", "            By default, the global correlation (GCOR) is computed from the", "            masked residual time series (errts).", "", "            GCOR can be thought of as the result of:", "                A1. compute the correlations of each voxel with every other", "                    --> can be viewed as an NMASK x NMASK correlation matrix", "                A2. compute GCOR: the average of the NMASK^2 values", "", "            Since step A1 would take a lot of time and disk space, a more", "            efficient computation is desirable:", "                B0. compute USET: scale each voxel time series to unit length", "                B1. compute GMU: the global mean of this unit dataset", "                B2. compute a correlation volume (of each time series with GMU)", "                B3. compute the average of this volume", "", "            The actual computation is simplified even further, as steps B2 and", "            B3 combine as the L2 norm of GMU.  The result is:", "                B2'. length(GMU)^2  (or the sum of squares of GMU)", "", "            The steps B0, B1 and B2' are performed in the proc script.", "", "            Note: This measure of global correlation is a single number in the", "                  range [0, 1] (not in [-1, 1] as some might expect).", "", "            Note: computation of GCOR requires a residual dataset, an EPI mask,", "                  and a volume analysis (no surface at the moment).", "", "        -regress_compute_tsnr yes/no : compute TSNR datasets from errts", "", "                e.g. -regress_compute_tsnr no", "                default: yes", "", "            By default, a temporal signal to noise (TSNR) dataset is created at", "            the end of the regress block.  The \"signal\" is the all_runs dataset", "            (input to 3dDeconvolve), and the \"noise\" is the errts dataset (the", "            residuals from 3dDeconvolve).  TSNR is computed (per voxel) as the", "            mean signal divided by the standard deviation of the noise.", "", "               TSNR = average(signal) / stdev(noise)", "", "            The main difference between the TSNR datasets from the volreg and", "            regress blocks is that the data in the regress block has been", "            smoothed and \"completely\" detrended (detrended according to the", "            regression model: including polort, motion and stim responses).", "", "            Use this option to prevent the TSNR dataset computation in the", "            'regress' block.", "", "            See also -volreg_compute_tsnr.", "", "        -regress_fout yes/no         : output F-stat sub-bricks", "", "                e.g. -regress_fout no", "                default: yes", "", "            This option controls whether to apply -fout in 3dDeconvolve.  The", "            default is yes.", "", "        -regress_make_cbucket yes/no : add a -cbucket option to 3dDeconvolve", "", "                default: 'no'", "", "            Recall that the -bucket dataset (no 'c') contains beta weights and", "            various statistics, but generally not including baseline terms", "            (polort and motion).", "", "            The -cbucket dataset (with a 'c') is a little different in that it", "            contains:", "                - ONLY betas (no t-stats, no F-stats, no contrasts)", "                - ALL betas (including baseline terms)", "            So it has one volume (beta) per regressor in the X-matrix.", "", "            The use is generally for 3dSynthesize, to recreate time series", "            datasets akin to the fitts, but where the user can request any set", "            of parameters to be included (for example, the polort and the main", "            2 regressors of interest).", "", "            Setting this to 'yes' will result in the -cbucket option being", "            added to the 3dDeconvolve command.", "", "            Please see '3dDeconvolve -help' for more details.", "", "        -regress_make_corr_vols LABEL1 ... : create correlation volume dsets", "", "                e.g. -regress_make_corr_vols aeseg FSvent", "                default: one is made against full_mask", "", "            This option is used to specify extra correlation volumes to compute", "            based on the residuals (so generally for resting state analysis).", "", "            What is a such a correlation volume?", "", "               Given: errts     : the residuals from the linear regression", "                      a mask    : to correlate over, e.g. full_mask", "", "               Compute: for each voxel (in the errts, say), compute the average", "                  correlation over all voxels within the given mask.  In some", "                  sense, this is a measure of self correlation over a specified", "                  region.", "", "               This is a mean correlation rather than a correlation with the", "               mean.", "", "            The labels specified can be from any ROI mask, such as those coming", "            via -anat_follower_ROI, -regress_ROI_PC, or from the automatic", "            masks from -mask_segment_anat.", "", "            See also -anat_follower_ROI, -regress_ROI_PC, -mask_segment_anat.", "", "        -regress_mot_as_ort yes/no : regress motion parameters using -ortvec", "", "                default: no", "", "            By default, motion parameters are applied to 3dvolreg using", "            -stim_file and -stim_base.  Use this option to apply them using", "            -ortvec, instead.", "", "            One difference is in having a \"cleaner\" 3dDeconvolve command,", "            without the many extra -stim_file options.  Another is a change in", "            the labels associated with the individual parameters.  Otherwise,", "            all results should be the same.", "", "        -regress_motion_per_run : regress motion parameters from each run", "", "                default: regress motion parameters catenated across runs", "", "            By default, motion parameters from the volreg block are catenated", "            across all runs, providing 6 (assuming 3dvolreg) regressors of no", "            interest in the regression block.", "", "            With -regress_motion_per_run, the motion parameters from each run", "            are used as separate regressors, providing a total of (6 * nruns)", "            regressors.", "", "            This allows for the magnitudes of the regressors to vary over each", "            run, rather than using a single (best) magnitude over all runs.", "            So more motion-correlated variance can be accounted for, at the", "            cost of the extra degrees of freedom (6*(nruns-1)).", "", "            This option will apply to all motion regressors, including", "            derivatives (if requested).", "", "            ** This option was previously called -volreg_regress_per_run. **", "", "        -regress_skip_first_outliers NSKIP : ignore the first NSKIP TRs", "", "                e.g. -regress_skip_first_outliers 4", "                default: 0", "", "            When using -regress_censor_outliers, any TR with too high of an", "            outlier fraction will be censored.  But depending on the scanner", "            settings, early TRs might have somewhat higher intensities, leading", "            to them possibly being inappropriately censored.", "", "            To avoid censoring any the first few TRs of each run, apply the", "            -regress_skip_first_outliers option.", "", "            See also -regress_censor_outliers.", "", "        -regress_compute_fitts       : compute fitts via 3dcalc, not 3dDecon", "", "            This option is to save memory during 3dDeconvolve, in the case", "            where the user has requested both the fitts and errts datasets.", "", "            Normally 3dDeconvolve is used to compute both the fitts and errts", "            time series.  But if memory gets tight, it is worth noting that", "            these datasets are redundant, one can be computed from the other", "            (given the all_runs dataset).", "", "                all_runs = fitts + errts", "", "            Using -regress_compute_fitts, -fitts is no longer applied in 3dD", "            (though -errts is).  Instead, note that an all_runs dataset is", "            created just after 3dDeconvolve.  After that step, the script will", "            create fitts as (all_runs-errts) using 3dcalc.", "", "            Note that computation of both errts and fitts datasets is required", "            for this option to be applied.", "", "            See also -regress_est_blur_errts, -regress_errts_prefix,", "            -regress_fitts_prefix and -regress_no_fitts.", "", "        -regress_cormat_warnings Y/N : specify whether to get cormat warnings", "", "                e.g. -mask_cormat_warnings No", "                default: Yes", "", "            By default, '1d_tool.py -show_cormat_warnings' is run on the", "            regression matrix.  Any large, pairwise correlations are shown", "            in text output (which is also saved to a text file).", "", "            This option allows one to disable such functionality.", "", "            Please see '1d_tool.py -help' for more details.", "", "        -regress_est_blur_epits      : estimate the smoothness of the EPI data", "", "            This option specifies to run 3dFWHMx on each of the EPI datasets", "            used for regression, the results of which are averaged.  These blur", "            values are saved to the file blur_est.$subj.1D, along with any", "            similar output from errts.", "", "            These blur estimates may be input to AlphaSim, for any multiple", "            testing correction done for this subject.  If AlphaSim is run at", "            the group level, it is reasonable to average these estimates", "            across all subjects (assuming they were scanned with the same", "            protocol and at the same scanner).", "", "            The mask block is required for this operation (without which the", "            estimates are not reliable).", "", "            Please see '3dFWHMx -help' for more information.", "            See also -regress_est_blur_errts.", "", "        -regress_est_blur_errts      : estimate the smoothness of the errts", "", "            This option specifies to run 3dFWHMx on the errts dataset, output", "            from the regression (by 3dDeconvolve).", "", "            These blur estimates may be input to AlphaSim, for any multiple", "            testing correction done for this subject.  If AlphaSim is run at", "            the group level, it is reasonable to average these estimates", "            across all subjects (assuming they were scanned with the same", "            protocol and at the same scanner).", "", "            Note that the errts blur estimates should be not only slightly", "            more accurate than the epits blur estimates, but they should be", "            slightly smaller, too (which is beneficial).", "", "            The mask block is required for this operation (without which the", "            estimates are not reliable).", "", "            Please see '3dFWHMx -help' for more information.", "            See also -regress_est_blur_epits.", "", "        -regress_errts_prefix PREFIX : specify a prefix for the -errts option", "", "                e.g. -regress_fitts_prefix errts", "", "            This option is used to add a -errts option to 3dDeconvolve.  As", "            with -regress_fitts_prefix, only the PREFIX is specified, to which", "            the subject ID will be added.", "", "            Please see '3dDeconvolve -help' for more information.", "            See also -regress_fitts_prefix.", "", "        -regress_fitts_prefix PREFIX : specify a prefix for the -fitts option", "", "                e.g. -regress_fitts_prefix model_fit", "                default: fitts", "", "            By default, the 3dDeconvolve command in the script will be given", "            a '-fitts fitts' option.  This option allows the user to change", "            the prefix applied in the output script.", "", "            The -regress_no_fitts option can be used to eliminate use of -fitts.", "", "            Please see '3dDeconvolve -help' for more information.", "            See also -regress_no_fitts.", "", "        -regress_global_times        : specify -stim_times as global times", "", "                default: 3dDeconvolve figures it out, if it can", "", "            By default, the 3dDeconvolve determines whether -stim_times files", "            are local or global times by the first line of the file.  If it", "            contains at least 2 times (which include '*' characters), it is", "            considered as local_times, otherwise as global_times.", "", "            The -regress_global_times option is mostly added to be symmetric", "            with -regress_local_times, as the only case where it would be", "            needed is when there are other times in the first row, but the", "            should still be viewed as global.", "", "            See also -regress_local_times.", "", "        -regress_local_times         : specify -stim_times as local times", "", "                default: 3dDeconvolve figures it out, if it can", "", "            By default, the 3dDeconvolve determines whether -stim_times files", "            are local or global times by the first line of the file.  If it", "            contains at least 2 times (which include '*' characters), it is", "            considered as local_times, otherwise as global_times.", "", "            In the case where the first run has only 1 stimulus (maybe even", "            every run), the user would need to put an extra '*' after the", "            first stimulus time.  If the first run has no stimuli, then two", "            would be needed ('* *'), but only for the first run.", "", "            Since this may get confusing, being explicit by adding this option", "            is a reasonable thing to do.", "", "            See also -regress_global_times.", "", "        -regress_iresp_prefix PREFIX : specify a prefix for the -iresp option", "", "                e.g. -regress_iresp_prefix model_fit", "                default: iresp", "", "            This option allows the user to change the -iresp prefix applied in", "            the 3dDeconvolve command of the output script.", "", "            By default, the 3dDeconvolve command in the script will be given a", "            set of '-iresp iresp' options, one per stimulus type, unless the", "            regression basis function is GAM.  In the case of GAM, the response", "            form is assumed to be known, so there is no need for -iresp.", "", "            The stimulus label will be appended to this prefix so that a sample", "            3dDeconvolve option might look one of these 2 examples:", "", "                -iresp 7 iresp_stim07", "                -iresp 7 model_fit_donuts", "", "            The -regress_no_iresp option can be used to eliminate use of -iresp.", "", "            Please see '3dDeconvolve -help' for more information.", "            See also -regress_no_iresp, -regress_basis.", "", "        -regress_make_ideal_sum IDEAL.1D : create IDEAL.1D file from regressors", "", "                e.g. -regress_make_ideal_sum ideal_all.1D", "", "            By default, afni_proc.py will compute a 'sum_ideal.1D' file that", "            is the sum of non-polort and non-motion regressors from the", "            X-matrix.  This -regress_make_ideal_sum option is used to specify", "            the output file for that sum (if sum_idea.1D is not desired).", "", "            Note that if there is nothing in the X-matrix except for polort and", "            motion regressors, or if 1d_tool.py cannot tell what is in there", "            (if there is no header information), then all columns will be used.", "", "            Computing the sum means adding a 1d_tool.py command to figure out", "            which columns should be used in the sum (since mixing GAM, TENT,", "            etc., makes it harder to tell up front), and a 3dTstat command to", "            actually sum those columns of the 1D X-matrix (the X-matrix is", "            output by 3dDeconvolve).", "", "            Please see '3dDeconvolve -help', '1d_tool.py -help' and", "            '3dTstat -help'.", "            See also -regress_basis, -regress_no_ideal_sum.", "", "        -regress_motion_file FILE.1D  : use FILE.1D for motion parameters", "", "                e.g. -regress_motion_file motion.1D", "", "            Particularly if the user performs motion correction outside of", "            afni_proc.py, they may wish to specify a motion parameter file", "            other than dfile_rall.1D (the default generated in the volreg", "            block).", "", "            Note: such files no longer need to be copied via -copy_files.", "", "            If the motion file is in a remote directory, include the path,", "            e.g. -regress_motion_file ../subject17/data/motion.1D .", "", "        -regress_no_fitts       : do not supply -fitts to 3dDeconvolve", "", "                e.g. -regress_no_fitts", "", "            This option prevents the program from adding a -fitts option to", "            the 3dDeconvolve command in the output script.", "", "            See also -regress_fitts_prefix.", "", "        -regress_no_ideal_sum      : do not create sum_ideal.1D from regressors", "", "            By default, afni_proc.py will compute a 'sum_ideal.1D' file that", "            is the sum of non-polort and non-motion regressors from the", "            X-matrix.  This option prevents that step.", "", "            See also -regress_make_ideal_sum.", "", "        -regress_no_ideals      : do not generate ideal response curves", "", "                e.g. -regress_no_ideals", "", "            By default, if the GAM or BLOCK basis function is used, ideal", "            response curve files are generated for each stimulus type (from", "            the output X matrix using '3dDeconvolve -x1D').  The names of the", "            ideal response function files look like 'ideal_LABEL.1D', for each", "            stimulus label, LABEL.", "", "            This option is used to suppress generation of those files.", "", "            See also -regress_basis, -regress_stim_labels.", "", "        -regress_no_iresp       : do not supply -iresp to 3dDeconvolve", "", "                e.g. -regress_no_iresp", "", "            This option prevents the program from adding a set of -iresp", "            options to the 3dDeconvolve command in the output script.", "", "            By default -iresp will be used unless the basis function is GAM.", "", "            See also -regress_iresp_prefix, -regress_basis.", "", "        -regress_no_mask        : do not apply the mask in regression", "", "            ** This is now the default, making the option unnecessary.", "", "            This option prevents the program from applying the mask dataset", "            in the scaling or regression steps.", "", "            If the user does not want to apply a mask in the regression", "            analysis, but wants the full_mask dataset for other reasons", "            (such as computing blur estimates), this option can be used.", "", "            See also -regress_est_blur_epits, -regress_est_blur_errts.", "", "        -regress_no_motion      : do not apply motion params in 3dDeconvolve", "", "                e.g. -regress_no_motion", "", "            This option prevents the program from adding the registration", "            parameters (from volreg) to the 3dDeconvolve command.", "", "        -regress_no_motion_demean : do not compute de-meaned motion parameters", "", "                default: do compute them", "", "            Even if they are not applied in the regression, the default is to", "            compute de-meaned motion parameters.  These may give the user a", "            better idea of motion regressors, since their scale will not be", "            affected by jumps across run breaks or multi-run drift.", "", "            This option prevents the program from even computing such motion", "            parameters.  The only real reason to not do it is if there is some", "            problem with the command.", "", "        -regress_no_motion_deriv  : do not compute motion parameter derivatives", "", "                default: do compute them", "", "            Even if they are not applied in the regression, the default is to", "            compute motion parameter derivatives (and de-mean them).  These can", "            give the user a different idea about motion regressors, since the", "            derivatives are a better indication of per-TR motion.  Note that", "            the 'enorm' file that is created (and optionally used for motion", "            censoring) is basically made by collapsing (via the Euclidean Norm", "            - the square root of the sum of the squares) these 6 derivative", "            columns into one.", "", "            This option prevents the program from even computing such motion", "            parameters.  The only real reason to not do it is if there is some", "            problem with the command.", "", "                See also -regress_censor_motion.", "", "        -regress_opts_3dD OPTS ...   : specify extra options for 3dDeconvolve", "", "                e.g. -regress_opts_3dD -gltsym ../contr/contrast1.txt  \\", "                                       -glt_label 1 FACEvsDONUT        \\", "                                       -jobs 6                         \\", "                                       -GOFORIT 8", "", "            This option allows the user to add extra options to the 3dDeconvolve", "            command.  Note that only one -regress_opts_3dD should be applied,", "            which may be used for multiple 3dDeconvolve options.", "", "            Please see '3dDeconvolve -help' for more information, or the link:", "                https://afni.nimh.nih.gov/afni/doc/misc/3dDeconvolveSummer2004", "", "        -regress_opts_reml OPTS ...  : specify extra options for 3dREMLfit", "", "                e.g. -regress_opts_reml                                 \\", "                        -gltsym ../contr/contrast1.txt FACEvsDONUT      \\", "                        -MAXa 0.92", "", "            This option allows the user to add extra options to the 3dREMLfit", "            command.  Note that only one -regress_opts_reml should be applied,", "            which may be used for multiple 3dREMLfit options.", "", "            Please see '3dREMLfit -help' for more information.", "", "        -regress_ppi_stim_files FILE FILE ... : specify PPI (and seed) files", "", "                e.g. -regress_ppi_stim_files PPI.1.A.1D PPI.2.B.1D PPI.3.seed.1D", "", "            Use this option to pass PPI stimulus files for inclusion in", "            3dDeconvolve command.  This list is essentially appended to", "            (and could be replaced by) -regress_extra_stim_files.", "", "          * These are not timing files, but direct regressors.", "", "            Use -regress_ppi_stim_labels to specify the corresponding labels.", "", "            See also -write_ppi_3dD_scripts, -regress_ppi_stim_labels.", "", "        -regress_ppi_stim_labels LAB1 LAB2 ... : specify PPI (and seed) labels", "", "                e.g. -regress_ppi_stim_files PPI.taskA PPI.taskB PPI.seed", "", "            Use this option to specify labels for the PPI stimulus files", "            specified via -regress_ppi_stim_files.  This list is essentially", "            appended to (and could be replaced by) -regress_extra_stim_labels.", "", "            Use -regress_ppi_stim_labels to specify the corresponding labels.", "", "            See also -write_ppi_3dD_scripts, -regress_ppi_stim_labels.", "", "        -regress_polort DEGREE  : specify the polynomial degree of baseline", "", "                e.g. -regress_polort 2", "                default: 1 + floor(run_length / 150.0)", "", "            3dDeconvolve models the baseline for each run separately, using", "            Legendre polynomials (by default).  This option specifies the", "            degree of polynomial.  Note that this will create DEGREE * NRUNS", "            regressors.", "", "            The default is computed from the length of a run, in seconds, as", "            shown above.  For example, if each run were 320 seconds, then the", "            default polort would be 3 (cubic).", "", "            Please see '3dDeconvolve -help' for more information.", "", "        -regress_reml_exec      : execute 3dREMLfit, matching 3dDeconvolve cmd", "", "            3dDeconvolve automatically creates a 3dREMLfit command script to", "            match the regression model of 3dDeconvolve.  Via this option, the", "            user can have that command executed.", "", "            Note that the X-matrix used in 3dREMLfit is actually generated by", "            3dDeconvolve.  The 3dDeconvolve command generates both the X-matrix", "            and the 3dREMLfit command script, and so it must be run regardless", "            of whether it actually performs the regression.", "", "            To terminate 3dDeconvolve after creation of the X-matrix and", "            3dREMLfit command script, apply -regress_3dD_stop.", "", "            See also -regress_3dD_stop.", "", "        -regress_ROI R1 R2 ... : specify a list of mask averages to regress out", "", "                e.g. -regress_ROI WMe", "                e.g. -regress_ROI brain WMe CSF", "                e.g. -regress_ROI FSvent FSwhite", "", "            Use this option to regress out one more more known ROI averages.", "            ROIs that can be generated from -mask_segment_anat/_erode include:", "", "                name    description     source dataset    creation program", "                -----   --------------  --------------    ----------------", "                brain   EPI brain mask  full_mask         3dAutomask", "                CSF     CSF             mask_CSF_resam    3dSeg -> Classes", "                CSFe    CSF (eroded)    mask_CSFe_resam   3dSeg -> Classes", "                GM      gray matter     mask_GM_resam     3dSeg -> Classes", "                GMe     gray (eroded)   mask_GMe_resam    3dSeg -> Classes", "                WM      white matter    mask_WM_resam     3dSeg -> Classes", "                WMe     white (eroded)  mask_WMe_resam    3dSeg -> Classes", "", "            Other ROI labels can come from -anat_follower_ROI options, i.e.", "            imported masks.", "", "          * Use of this option requires either -mask_segment_anat or labels", "            defined via -anat_follower_ROI options.", "", "            See also -mask_segment_anat/_erode, -anat_follower_ROI.", "            Please see '3dSeg -help' for more information on the masks.", "", "        -regress_ROI_PC LABEL NUM_PC    : regress out PCs within mask", "", "                e.g. -regress_ROI_PC vent 3", "                     -regress_ROI_PC WMe 3", "", "            Add the top principal components (PCs) over an anatomical mask as", "            regressors of no interest.", "", "              - LABEL   : the class label given to this set of regressors", "              - NUM_PC  : the number of principal components to include", "", "            The LABEL can apply to something defined via -mask_segment_anat", "            maybe with -mask_segment_erode, or from -anat_follower_ROI", "            (assuming 'epi' grid), or 'brain' (full_mask).  The -mask_segment*", "            options define ROI labels implicitly (see above), while the user", "            defines ROI labels in any -anat_follower_ROI options.", "", "            Method (including 'follower' steps):", "", "              If -anat_follower_ROI is used to define the label, then the", "              follower ROI steps would first be applied to that dataset.", "", "              If ROIs are created 'automatically' via 3dSeg (-mask_segment_anat)", "              then the follower steps do not apply.", "", "              F1. if requested (-anat_follower_erode) erode the ROI mask", "              F2. apply all anatomical transformations to the ROI mask", "                  a. catenate all anatomical transformations", "                     i.   anat to EPI?", "                     ii.  affine xform of anat to template?", "                     iii. subsequent non-linear xform of anat to template?", "                  b. sample the transformed mask on the EPI grid", "                  c. use nearest neighbor interpolation, NN", "", "           Method (post-mask alignment):", "", "              P1. extract the top NUM_PC principal components from the volume", "                  registered EPI data, over the mask", "                  a. detrend the volume registered EPI data at the polort level", "                     to be used in the regression, per run", "                  b. catenate the detrended volreg data across runs", "                  c. compute the top PCs from the (censored?) time series", "                  d. if censoring, zero-fill the time series with volumes of", "                     zeros at the censored TRs, to maintain TR correspondence", "              P2. include those PCs as regressors of no interest", "                  a. apply with: 3dDeconvolve -ortvec PCs LABEL", "", "            Typical usage might start with the FreeSurfer parcellation of the", "            subject's anatomical dataset, followed by ROI extraction using", "            3dcalc (to make a new dataset of just the desired regions).  Then", "            choose the number of components to extract and a label.", "", "            That ROI dataset, PC count and label are then applied with this", "            option.", "", "          * The given MASK must be in register with the anatomical dataset,", "            though it does not necessarily need to be on the anatomical grid.", "", "          * Multiple -regress_ROI_PC options can be used.", "", "            See also -anat_follower, -anat_follower_ROI, -regress_ROI_erode,", "            and -regress_ROI.", "", "        -regress_ROI_per_run LABEL ... : regress these ROIs per run", "", "                e.g. -regress_ROI_per_run vent", "                e.g. -regress_ROI_per_run vent WMe", "", "            Use this option to create the given ROI regressors per run.", "            Instead of creating one regressor spanning all runs, this option", "            leads to creating one regressor per run, akin to splitting the", "            long regressor across runs, and zero-padding to be the same length.", "", "            See also -regress_ROI_PC, -regress_ROI_PC_per_run.", "", "        -regress_ROI_PC_per_run LABEL ... : regress these PCs per run", "", "                e.g. -regress_ROI_PC_per_run vent", "                e.g. -regress_ROI_PC_per_run vent WMe", "", "            Use this option to create the given PC regressors per run.  So", "            if there are 4 runs and 3 'vent' PCs were requested with the", "            option \"-regress_ROI_PC vent 3\", then applying this option with", "            the 'vent' label results in not 3 regressors (one per PC), but", "            12 regressors (one per PC per run).", "", "            Note that unlike the -regress_ROI_per_run case, this is not merely", "            splitting one signal across runs.  In this case the principle", "            components are be computed per run, almost certainly resulting in", "            different components than those computed across all runs at once.", "", "            See also -regress_ROI_PC, -regress_ROI_per_run.", "", "        -regress_RSFC           : perform bandpassing via 3dRSFC", "", "            Use this option flag to run 3dRSFC after the linear regression", "            step (presumably to clean resting state data).  Along with the", "            bandpassed data, 3dRSFC will produce connectivity parameters,", "            saved in the RSFC directory by the proc script.", "", "            The -regress_bandpass option is required, and those bands will be", "            passed directly to 3dRSFC.  Since bandpassing will be done only", "            after the linear regression, censoring is not advisable.", "", "            See also -regress_bandpass, -regress_censor_motion.", "            Please see '3dRSFC -help' for more information.", "", "        -regress_RONI IND1 ...  : specify a list of regressors of no interest", "", "                e.g. -regress_RONI 1 17 22", "", "            Use this option flag regressors as ones of no interest, meaning", "            they are applied to the baseline (for full-F) and the corresponding", "            beta weights are not output (by default at least).", "", "            The indices in the list should match those given to 3dDeconvolve.", "            They start at 1 first with the main regressors, and then with any", "            extra regressors (given via -regress_extra_stim_files).  Note that", "            these do not apply to motion regressors.", "", "            The user is encouraged to check the 3dDeconvolve command in the", "            processing script, to be sure they are applied correctly.", "", "        -regress_stim_labels LAB1 ...   : specify labels for stimulus classes", "", "                e.g. -regress_stim_labels houses faces donuts", "                default: stim01 stim02 stim03 ...", "", "            This option is used to apply a label to each stimulus type.  The", "            number of labels should equal the number of files used in the", "            -regress_stim_times option, or the total number of columns in the", "            files used in the -regress_stim_files option.", "", "            These labels will be applied as '-stim_label' in 3dDeconvolve.", "", "            Please see '3dDeconvolve -help' for more information.", "            See also -regress_stim_times, -regress_stim_labels.", "", "        -regress_stim_times FILE1 ... : specify files used for -stim_times", "", "                e.g. -regress_stim_times ED_stim_times*.1D", "                e.g. -regress_stim_times times_A.1D times_B.1D times_C.1D", "", "            3dDeconvolve will be run using '-stim_times'.  This option is", "            used to specify the stimulus timing files to be applied, one", "            file per stimulus type.  The order of the files given on the", "            command line will be the order given to 3dDeconvolve.  Each of", "            these timing files will be given along with the basis function", "            specified by '-regress_basis'.", "", "            The user must specify either -regress_stim_times or", "            -regress_stim_files if regression is performed, but not both.", "            Note the form of the files is one row per run.  If there is at", "            most one stimulus per run, please add a trailing '*'.", "", "            Labels may be specified using the -regress_stim_labels option.", "", "            These two examples of such files are for a 3-run experiment.  In", "            the second example, there is only 1 stimulus at all, occurring in", "            run #2.", "", "                e.g.            0  12.4  27.3  29", "                                *", "                                30 40 50", "", "                e.g.            *", "                                20 *", "                                *", "", "            Please see '3dDeconvolve -help' for more information, or the link:", "                https://afni.nimh.nih.gov/afni/doc/misc/3dDeconvolveSummer2004", "            See also -regress_stim_files, -regress_stim_labels, -regress_basis,", "                     -regress_basis_normall, -regress_polort.", "", "        -regress_stim_files FILE1 ... : specify TR-locked stim files", "", "                e.g. -regress_stim_files ED_stim_file*.1D", "                e.g. -regress_stim_files stim_A.1D stim_B.1D stim_C.1D", "", "            Without the -regress_use_stim_files option, 3dDeconvolve will be", "            run using '-stim_times', not '-stim_file'.  The user can still", "            specify the 3dDeconvolve -stim_file files here, but they would", "            then be converted to -stim_times files using the script,", "            make_stim_times.py .", "", "            It might be more educational for the user to run make_stim_times.py", "            outside afni_proc.py (such as was done before example 2, above), or", "            to create the timing files directly.", "", "            Each given file can be for multiple stimulus classes, where one", "            column is for one stim class, and each row represents a TR.  So", "            each file should have NUM_RUNS * NUM_TRS rows.", "", "            The stim_times files will be labeled stim_times.NN.1D, where NN", "            is the stimulus index.", "", "            Note that if the stimuli were presented at a fixed time after", "            the beginning of a TR, the user should consider the option,", "            -regress_stim_times_offset, to apply that offset.", "", "            ---", "", "            If the -regress_use_stim_files option is provided, 3dDeconvolve", "            will be run using each stim_file as a regressor.  The order of the", "            regressors should match the order of any labels, provided via the", "            -regress_stim_labels option.", "", "            Alternately, this can be done via -regress_stim_times, along", "            with -regress_stim_types 'file'.", "", "            Please see '3dDeconvolve -help' for more information, or the link:", "                https://afni.nimh.nih.gov/afni/doc/misc/3dDeconvolveSummer2004", "            See also -regress_stim_times, -regress_stim_labels, -regress_basis,", "                     -regress_basis_normall, -regress_polort,", "                     -regress_stim_times_offset, -regress_use_stim_files.", "", "        -regress_extra_stim_files FILE1 ... : specify extra stim files", "", "                e.g. -regress_extra_stim_files resp.1D cardiac.1D", "                e.g. -regress_extra_stim_files regs_of_no_int_*.1D", "", "            Use this option to specify extra files to be applied with the", "            -stim_file option in 3dDeconvolve (as opposed to the more usual", "            option, -stim_times).", "", "            These files will not be converted to stim_times format.", "", "            Corresponding labels can be given with -regress_extra_stim_labels.", "", "            See also -regress_extra_stim_labels, -regress_ROI, -regress_RONI.", "", "        -regress_extra_stim_labels LAB1 ... : specify extra stim file labels", "", "                e.g. -regress_extra_stim_labels resp cardiac", "", "            If -regress_extra_stim_files is given, the user may want to specify", "            labels for those extra stimulus files.  This option provides that", "            mechanism.  If this option is not given, default labels will be", "            assigned (like stim17, for example).", "", "            Note that the number of entries in this list should match the", "            number of extra stim files.", "", "            See also -regress_extra_stim_files.", "", "        -regress_stim_times_offset OFFSET : add OFFSET to -stim_times files", "", "                e.g. -regress_stim_times_offset 1.25", "                e.g. -regress_stim_times_offset -9.2", "                default: 0", "", "            With -regress_stim_times:", "", "               If the -regress_stim_times option is uses, and if ALL stim files", "               are timing files, then timing_tool.py will be used to add the", "               time offset to each -regress_stim_times file as it is copied into", "               the stimuli directory (near the beginning of the script).", "", "            With -regress_stim_files:", "", "               If the -regress_stim_files option is used (so the script would", "               convert -stim_files to -stim_times before 3dDeconvolve), the", "               user may want to add an offset to the times in the resulting", "               timing files.", "", "               For example, if -tshift_align_to is applied and the user chooses", "               to align volumes to the middle of the TR, it might be appropriate", "               to add TR/2 to the times of the stim_times files.", "", "               This OFFSET will be applied to the make_stim_times.py command in", "               the output script.", "", "            Please see 'make_stim_times.py -help' for more information.", "            See also -regress_stim_files, -regress_use_stim_files,", "                     -regress_stim_times and -tshift_align_to.", "", "        -regress_stim_types TYPE1 TYPE2 ... : specify list of stim types", "", "                e.g. -regress_stim_types times times AM2 AM2 times AM1 file", "                e.g. -regress_stim_types AM2", "                default: times", "", "            If amplitude, duration or individual modulation is desired with", "            any of the stimulus timing files provided via -regress_stim_files,", "            then this option should be used to specify one (if all of the types", "            are the same) or a list of stimulus timing types.  One can also use", "            the type 'file' for the case of -stim_file, where the input is a 1D", "            regressor instead of stimulus times.", "", "            The types should be (possibly repeated) elements of the set:", "            {times, AM1, AM2, IM}, where they indicate:", "", "                times:  a standard stimulus timing file (not married)", "                        ==> use -stim_times in 3dDeconvolve command", "", "                AM1:    have one or more married parameters", "                        ==> use -stim_times_AM1 in 3dDeconvolve command", "", "                AM2:    have one or more married parameters", "                        ==> use -stim_times_AM2 in 3dDeconvolve command", "", "                IM:     NO married parameters, but get beta for each stim", "                        ==> use -stim_times_IM in 3dDeconvolve command", "", "                file:   a 1D regressor, not a stimulus timing file", "                        ==> use -stim_file in 3dDeconvolve command", "", "            Please see '3dDeconvolve -help' for more information.", "            See also -regress_stim_times.", "            See also example 7 (esoteric options).", "", "        -regress_use_stim_files : use -stim_file in regression, not -stim_times", "", "            The default operation of afni_proc.py is to convert TR-locked files", "            for the 3dDeconvolve -stim_file option to timing files for the", "            3dDeconvolve -stim_times option.", "", "            If the -regress_use_stim_times option is provided, then no such", "            conversion will take place.  This assumes the -regress_stim_files", "            option is applied to provide such -stim_file files.", "", "            This option has been renamed from '-regress_no_stim_times'.", "", "            Please see '3dDeconvolve -help' for more information.", "            See also -regress_stim_files, -regress_stim_times,", "                     -regress_stim_labels.", "", "        -----------------------------------------------------------------", "        3dClustSim options ~3~", "", "        -regress_run_clustsim yes/no : add 3dClustSim attrs to stats dset", "", "                e.g. -regress_run_clustsim no", "                default: yes", "", "            This option controls whether 3dClustSim will be executed after the", "            regression analysis.  Since the default is 'yes', the effective use", "            of this option would be to turn off the operation.", "", "            3dClustSim is a more advanced version of AlphaSim, and generates a", "            table of cluster sizes/alpha values that can be then stored in the", "            stats dataset for a simple multiple comparison correction in the", "            cluster interface of the afni GUI.", "", "            The blur estimates and mask dataset are required, and so the", "            option is only relevant in the context of blur estimation.", "", "            Please see '3dClustSim -help' for more information.", "            See also -regress_est_blur_epits, -regress_est_blur_epits and", "                     -regress_opts_CS.", "", "        -regress_CS_NN LEVELS   : specify NN levels for 3dClustSim command", "", "                e.g.     -regress_CS_NN 1", "                default: -regress_CS_NN 123", "", "            This option allows the user to specify which nearest neighbors to", "            consider when clustering.  Cluster results will be generated for", "            each included NN level.  Using multiple levels means being able to", "            choose between those same levels when looking at the statistical", "            results using the afni GUI.", "", "            The LEVELS should be chosen from the set {1,2,3}, where the", "            respective levels mean \"shares a face\", \"shares an edge\" and", "            \"shares a corner\", respectively.  Any non-empty subset can be used.", "            They should be specified as is with 3dClustSim.", "", "            So there are 7 valid subsets: 1, 2, 3, 12, 13, 23, and 123.", "", "            Please see '3dClustSim -help' for details on its '-NN' option.", "", "        -regress_opts_CS OPTS ...    : specify extra options for 3dClustSim", "", "                e.g. -regress_opts_CS -athr 0.05 0.01 0.005 0.001", "", "            This option allows the user to add extra options to the 3dClustSim", "            command.  Only 1 such option should be applied, though multiple", "            options to 3dClustSim can be included.", "", "            Please see '3dClustSim -help' for more information.", "            See also -regress_run_clustsim.", "", "", "    - R Reynolds  Dec, 2006                             thanks to Z Saad", "    ===========================================================================", ""], "params": [{"param": "-regress_stim_files", "line_start": 188, "length": 5, "param_range": [9049, 9068], "help": "                             -regress_stim_files stims.1D\n\n           or without any wildcard, the .HEAD suffix is not needed:\n\n                afni_proc.py -dsets epiRT_r1+orig epiRT_r2+orig epiRT_r3+orig \\", "help_range": [9020, 9227]}, {"param": "-regress_stim_files", "line_start": 193, "length": 16, "param_range": [9257, 9276], "help": "                             -regress_stim_files stims.1D\n\n     **************************************************************\n     *  New and improved!  Examples that apply to AFNI_data4.     *\n     *  (were quickly OLD and OBSOLETE, as we now use AFNI_data6) *\n     **************************************************************\n\n        The following examples can be run from the AFNI_data4 directory, and\n        are examples of how one might process the data for subject sb23.\n\n        Example 2. Very simple. ~2~\n\n        Use all defaults, except remove 3 TRs and use basis\n        function BLOCK(30,1).  The default basis function is GAM.\n\n                afni_proc.py -subj_id sb23.e2.simple                       \\", "help_range": [9228, 9951]}, {"param": "-dsets", "line_start": 209, "length": 2, "param_range": [9976, 9982], "help": "                        -dsets sb23/epi_r??+orig.HEAD                      \\\n                        -tcat_remove_first_trs 3                           \\", "help_range": [9952, 10105]}, {"param": "-regress_stim_times", "line_start": 211, "length": 11, "param_range": [10130, 10149], "help": "                        -regress_stim_times sb23/stim_files/blk_times.*.1D \\\n                        -regress_basis 'BLOCK(30,1)'\n\n        Example 3. (no longer) The current class example.  ~2~\n\n           Copy the anatomy into the results directory, register EPI data to\n           the last TR, specify stimulus labels, compute blur estimates, and\n           provide GLT options directly to 3dDeconvolve.  The GLTs will be\n           ignored after this, as they take up too many lines.\n\n                afni_proc.py -subj_id sb23.blk                             \\", "help_range": [10106, 10670]}, {"param": "-dsets", "line_start": 222, "length": 4, "param_range": [10695, 10701], "help": "                        -dsets sb23/epi_r??+orig.HEAD                      \\\n                        -copy_anat sb23/sb23_mpra+orig                     \\\n                        -tcat_remove_first_trs 3                           \\\n                        -volreg_align_to last                              \\", "help_range": [10671, 10978]}, {"param": "-regress_stim_times", "line_start": 226, "length": 1, "param_range": [11003, 11022], "help": "                        -regress_stim_times sb23/stim_files/blk_times.*.1D \\", "help_range": [10106, 10182]}, {"param": "-regress_stim_labels", "line_start": 227, "length": 3, "param_range": [11080, 11100], "help": "                        -regress_stim_labels tneg tpos tneu eneg epos      \\\n                                             eneu fneg fpos fneu           \\\n                        -regress_basis 'BLOCK(30,1)'                       \\", "help_range": [11056, 11286]}, {"param": "-regress_opts_3dD", "line_start": 230, "length": 16, "param_range": [11311, 11328], "help": "                        -regress_opts_3dD                                  \\\n                            -gltsym 'SYM: +eneg -fneg'                     \\\n                            -glt_label 1 eneg_vs_fneg                      \\\n                            -gltsym 'SYM: 0.5*fneg 0.5*fpos -1.0*fneu'     \\\n                            -glt_label 2 face_contrast                     \\\n                            -gltsym 'SYM: tpos epos fpos -tneg -eneg -fneg'\\\n                            -glt_label 3 pos_vs_neg                        \\\n                        -regress_est_blur_epits                            \\\n                        -regress_est_blur_errts\n\n        Example 4. Similar to 3, but specify the processing blocks. ~2~\n\n           Adding despike and tlrc, and removing tshift.  Note that\n           the tlrc block is to run @auto_tlrc on the anat.  Ignore the GLTs.\n\n                afni_proc.py -subj_id sb23.e4.blocks                       \\", "help_range": [11287, 12248]}, {"param": "-dsets", "line_start": 246, "length": 4, "param_range": [12273, 12279], "help": "                        -dsets sb23/epi_r??+orig.HEAD                      \\\n                        -blocks despike volreg blur mask scale regress tlrc\\\n                        -copy_anat sb23/sb23_mpra+orig                     \\\n                        -tcat_remove_first_trs 3                           \\", "help_range": [12249, 12556]}, {"param": "-regress_stim_times", "line_start": 250, "length": 1, "param_range": [12581, 12600], "help": "                        -regress_stim_times sb23/stim_files/blk_times.*.1D \\", "help_range": [10106, 10182]}, {"param": "-regress_stim_labels", "line_start": 251, "length": 27, "param_range": [12658, 12678], "help": "                        -regress_stim_labels tneg tpos tneu eneg epos      \\\n                                             eneu fneg fpos fneu           \\\n                        -regress_basis 'BLOCK(30,1)'                       \\\n                        -regress_est_blur_epits                            \\\n                        -regress_est_blur_errts\n\n        Example 5a. RETROICOR, resting state data. ~2~\n\n           Assuming the class data is for resting-state and that we have the\n           appropriate slice-based regressors from RetroTS.py, apply the\n           despike and ricor processing blocks.  Note that '-do_block' is used\n           to add non-default blocks into their default positions.  Here the\n           'despike' and 'ricor' processing blocks would come before 'tshift'.\n\n           Remove 3 TRs from the ricor regressors to match the EPI data.  Also,\n           since degrees of freedom are not such a worry, regress the motion\n           parameters per-run (each run gets a separate set of 6 regressors).\n\n           The regression will use 81 basic regressors (all of \"no interest\"),\n           with 13 retroicor regressors being removed during pre-processing:\n\n                 27 baseline  regressors ( 3 per run * 9 runs)\n                 54 motion    regressors ( 6 per run * 9 runs)\n\n           To example #3, add -do_block, -ricor_* and -regress_motion_per_run.\n\n                afni_proc.py -subj_id sb23.e5a.ricor            \\", "help_range": [12634, 14098]}, {"param": "-dsets", "line_start": 278, "length": 1, "param_range": [14123, 14129], "help": "                        -dsets sb23/epi_r??+orig.HEAD           \\", "help_range": [14099, 14164]}, {"param": "-do_block", "line_start": 279, "length": 2, "param_range": [14189, 14198], "help": "                        -do_block despike ricor                 \\\n                        -tcat_remove_first_trs 3                \\", "help_range": [14165, 14296]}, {"param": "-ricor_regs", "line_start": 281, "length": 1, "param_range": [14321, 14332], "help": "                        -ricor_regs_nfirst 3                    \\", "help_range": [14297, 14362]}, {"param": "-ricor_regs", "line_start": 282, "length": 18, "param_range": [14387, 14398], "help": "                        -ricor_regs sb23/RICOR/r*.slibase.1D    \\\n                        -regress_motion_per_run\n\n           If tshift, blurring and masking are not desired, consider replacing\n           the -do_block option with an explicit list of blocks:\n\n                -blocks despike ricor volreg regress\n\n        Example 5b. RETROICOR, while running a normal regression. ~2~\n\n           Add the ricor regressors to a normal regression-based processing\n           stream.  Apply the RETROICOR regressors across runs (so using 13\n           concatenated regressors, not 13*9).  Note that concatenation is\n           normally done with the motion regressors too.\n\n           To example #3, add -do_block and three -ricor options.\n\n                afni_proc.py -subj_id sb23.e5b.ricor                       \\", "help_range": [14363, 15176]}, {"param": "-dsets", "line_start": 300, "length": 1, "param_range": [15201, 15207], "help": "                        -dsets sb23/epi_r??+orig.HEAD                      \\", "help_range": [9952, 10028]}, {"param": "-do_block", "line_start": 301, "length": 3, "param_range": [15278, 15287], "help": "                        -do_block despike ricor                            \\\n                        -copy_anat sb23/sb23_mpra+orig                     \\\n                        -tcat_remove_first_trs 3                           \\", "help_range": [15254, 15484]}, {"param": "-ricor_regs", "line_start": 304, "length": 1, "param_range": [15509, 15520], "help": "                        -ricor_regs_nfirst 3                               \\", "help_range": [15485, 15561]}, {"param": "-ricor_regs", "line_start": 305, "length": 3, "param_range": [15586, 15597], "help": "                        -ricor_regs sb23/RICOR/r*.slibase.1D               \\\n                        -ricor_regress_method 'across-runs'                \\\n                        -volreg_align_to last                              \\", "help_range": [15562, 15792]}, {"param": "-regress_stim_times", "line_start": 308, "length": 1, "param_range": [15817, 15836], "help": "                        -regress_stim_times sb23/stim_files/blk_times.*.1D \\", "help_range": [10106, 10182]}, {"param": "-regress_stim_labels", "line_start": 309, "length": 31, "param_range": [15894, 15914], "help": "                        -regress_stim_labels tneg tpos tneu eneg epos      \\\n                                             eneu fneg fpos fneu           \\\n                        -regress_basis 'BLOCK(30,1)'                       \\\n                        -regress_est_blur_epits                            \\\n                        -regress_est_blur_errts\n\n           Also consider adding -regress_bandpass.\n\n        Example 5c. RETROICOR (modern): censor and band pass. ~2~\n\n           This is an example of how we might currently suggest analyzing\n           resting state data.  If no RICOR regressors exist, see example 9\n           (or just remove any ricor options).\n\n           Censoring due to motion has long been considered appropriate in\n           BOLD FMRI analysis, but is less common for those doing bandpass\n           filtering in RS FMRI because the FFT requires one to either break\n           the time axis (evil) or to replace the censored data with something\n           probably inappropriate.\n\n           Instead, it is slow (no FFT, but maybe SFT :) but effective to\n           regress frequencies within the regression model, where censoring\n           is simple.\n\n           Note: band passing in the face of RETROICOR is questionable.  It may\n                 be questionable in general.  To skip bandpassing, remove the\n                 -regress_bandpass option line.\n\n           Also, align EPI to anat and warp to standard space.\n\n                afni_proc.py -subj_id sb23.e5a.ricor            \\", "help_range": [15870, 17395]}, {"param": "-dsets", "line_start": 340, "length": 5, "param_range": [17420, 17426], "help": "                        -dsets sb23/epi_r??+orig.HEAD           \\\n                        -blocks despike ricor tshift align tlrc \\\n                                volreg blur mask regress        \\\n                        -copy_anat sb23/sb23_mpra+orig          \\\n                        -tcat_remove_first_trs 3                \\", "help_range": [17396, 17725]}, {"param": "-ricor_regs", "line_start": 345, "length": 1, "param_range": [17750, 17761], "help": "                        -ricor_regs_nfirst 3                    \\", "help_range": [14297, 14362]}, {"param": "-ricor_regs", "line_start": 346, "length": 7, "param_range": [17816, 17827], "help": "                        -ricor_regs sb23/RICOR/r*.slibase.1D    \\\n                        -volreg_align_e2a                       \\\n                        -volreg_tlrc_warp                       \\\n                        -blur_size 6                            \\\n                        -regress_motion_per_run                 \\\n                        -regress_censor_motion 0.2              \\\n                        -regress_bandpass 0.01 0.1              \\", "help_range": [17792, 18253]}, {"param": "-regress_apply_mot_types", "line_start": 353, "length": 1, "param_range": [18278, 18302], "help": "                        -regress_apply_mot_types demean deriv   \\", "help_range": [18254, 18319]}, {"param": "-regress_run_clustsim", "line_start": 354, "length": 31, "param_range": [18344, 18365], "help": "                        -regress_run_clustsim no                \\\n                        -regress_est_blur_epits                 \\\n                        -regress_est_blur_errts\n\n        Example 6. A modern example.  GOOD TO CONSIDER. ~2~\n\n           Align the EPI to the anatomy.  Also, process in MNI space, using\n           the 2009c non-linear template.\n\n           For alignment in either direction, add the 'align' block, which\n           aligns the anatomy to the EPI.  To then align the EPI to the anat\n           using the lpc+ZZ cost function (instead of just lpc), apply\n           -volreg_align_e2a, where that transform (inverse) is applied along\n           with the motion alignment.\n\n           On top of that, complete the processing in standard space by running\n           @auto_tlrc on the anat (via the 'tlrc' block) and applying the same\n           transformation to the EPI via -volreg_tlrc_warp.  Again, the EPI\n           transformation is applied along with the motion alignment, using\n           the volume with the minimum outlier fraction as the alignment base\n           (option '-volreg_align_to MIN_OUTLIER').\n\n           So use the given -blocks option, plus 2 extra volreg warps to #3 via\n           '-volreg_align_e2a', '-volreg_tlrc_warp'.\n\n           As an added bonus, censor TR pairs where the Euclidean Norm of the\n           motion derivative exceeds 0.3.  Also, regress motion parameters\n           separately for each run.\n\n                afni_proc.py -subj_id sb23.e6.align                        \\\n                        -copy_anat sb23/sb23_mpra+orig                     \\", "help_range": [18320, 19940]}, {"param": "-dsets", "line_start": 385, "length": 4, "param_range": [19965, 19971], "help": "                        -dsets sb23/epi_r??+orig.HEAD                      \\\n                        -blocks tshift align tlrc volreg blur mask         \\\n                                scale regress                              \\\n                        -tcat_remove_first_trs 3                           \\", "help_range": [19941, 20248]}, {"param": "-align_opts_aea", "line_start": 389, "length": 5, "param_range": [20273, 20288], "help": "                        -align_opts_aea -cost lpc+ZZ                       \\\n                        -tlrc_base MNI152_T1_2009c+tlrc                    \\\n                        -volreg_align_to MIN_OUTLIER                       \\\n                        -volreg_align_e2a                                  \\\n                        -volreg_tlrc_warp                                  \\", "help_range": [20249, 20633]}, {"param": "-regress_stim_times", "line_start": 394, "length": 1, "param_range": [20658, 20677], "help": "                        -regress_stim_times sb23/stim_files/blk_times.*.1D \\", "help_range": [10106, 10182]}, {"param": "-regress_stim_labels", "line_start": 395, "length": 6, "param_range": [20735, 20755], "help": "                        -regress_stim_labels tneg tpos tneu eneg epos      \\\n                                             eneu fneg fpos fneu           \\\n                        -regress_basis 'BLOCK(30,1)'                       \\\n                        -regress_motion_per_run                            \\\n                        -regress_censor_motion 0.3                         \\\n                        -regress_reml_exec                                 \\", "help_range": [20711, 21172]}, {"param": "-regress_opts_3dD", "line_start": 401, "length": 56, "param_range": [21197, 21214], "help": "                        -regress_opts_3dD                                  \\\n                            -gltsym 'SYM: +eneg -fneg'                     \\\n                            -glt_label 1 eneg_vs_fneg                      \\\n                        -regress_est_blur_epits                            \\\n                        -regress_est_blur_errts\n\n           To process in orig space, remove -volreg_tlrc_warp.\n           To apply manual tlrc transformation, use -volreg_tlrc_adwarp.\n           To process as anat aligned to EPI, remove -volreg_align_e2a.\n\n         * Also, one can use ANATICOR with task (-regress_anaticor_fast, say)\n           in the case of -reml_exec.\n\n        Example 7. Similar to 6, but get a little more esoteric. ~2~\n\n           a. Register EPI volumes to the one which has the minimum outlier\n              fraction (so hopefully the least motion), still with cost lpc+ZZ.\n\n           b. Blur only within the brain, as far as an automask can tell.  So\n              add -blur_in_automask to blur only within an automatic mask\n              created internally by 3dBlurInMask (akin to 3dAutomask).\n\n           c. Let the basis functions vary.  For some reason, we expect the\n              BOLD responses to the telephone classes to vary across the brain.\n              So we have decided to use TENT functions there.  Since the TR is\n              3.0s and we might expect up to a 45 second BOLD response curve,\n              use 'TENT(0,45,16)' for those first 3 out of 9 basis functions.\n\n              This means using -regress_basis_multi instead of -regress_basis,\n              and specifying all 9 basis functions appropriately.\n\n           d. Use amplitude modulation.\n\n              We expect responses to email stimuli to vary proportionally with\n              the number of punctuation characters used in the message (in\n              certain brain regions).  So we will use those values as auxiliary\n              parameters 3dDeconvolve by marrying the parameters to the stim\n              times (using 1dMarry).\n\n              Use -regress_stim_types to specify that the epos/eneg/eneu stim\n              classes should be passed to 3dDeconvolve using -stim_times_AM2.\n\n           e. Not only censor motion, but censor TRs when more than 10% of the\n              automasked brain are outliers.  So add -regress_censor_outliers.\n\n           f. Include both de-meaned and derivatives of motion parameters in\n              the regression.  So add '-regress_apply_mot_types demean deriv'.\n\n           g. Output baseline parameters so we can see the effect of motion.\n              So add -bout under option -regress_opts_3dD.\n\n           h. Save on RAM by computing the fitts only after 3dDeconvolve.\n              So add -regress_compute_fitts.\n\n           i. Speed things up.  Have 3dDeconvolve use 4 CPUs and skip the\n              single subject 3dClustSim execution.  So add '-jobs 4' to the", "help_range": [21173, 24114]}, {"param": "-regress_opts_3dD", "line_start": 457, "length": 3, "param_range": [24129, 24146], "help": "              -regress_opts_3dD option and add '-regress_run_clustsim no'.\n\n                afni_proc.py -subj_id sb23.e7.esoteric                     \\", "help_range": [24115, 24267]}, {"param": "-dsets", "line_start": 460, "length": 5, "param_range": [24292, 24298], "help": "                        -dsets sb23/epi_r??+orig.HEAD                      \\\n                        -blocks tshift align tlrc volreg blur mask         \\\n                                scale regress                              \\\n                        -copy_anat sb23/sb23_mpra+orig                     \\\n                        -tcat_remove_first_trs 3                           \\", "help_range": [24268, 24652]}, {"param": "-align_opts_aea", "line_start": 465, "length": 5, "param_range": [24677, 24692], "help": "                        -align_opts_aea -cost lpc+ZZ                       \\\n                        -volreg_align_to MIN_OUTLIER                       \\\n                        -volreg_align_e2a                                  \\\n                        -volreg_tlrc_warp                                  \\\n                        -blur_in_automask                                  \\", "help_range": [24653, 25037]}, {"param": "-regress_stim_times", "line_start": 470, "length": 1, "param_range": [25062, 25081], "help": "                        -regress_stim_times sb23/stim_files/blk_times.*.1D \\", "help_range": [10106, 10182]}, {"param": "-regress_stim_types", "line_start": 471, "length": 3, "param_range": [25139, 25158], "help": "                        -regress_stim_types times times times              \\\n                                            AM2   AM2   AM2                \\\n                                            times times times              \\", "help_range": [25115, 25345]}, {"param": "-regress_stim_labels", "line_start": 474, "length": 3, "param_range": [25370, 25390], "help": "                        -regress_stim_labels tneg tpos tneu                \\\n                                             eneg epos eneu                \\\n                                             fneg fpos fneu                \\", "help_range": [25346, 25576]}, {"param": "-regress_basis_multi", "line_start": 477, "length": 4, "param_range": [25601, 25621], "help": "                        -regress_basis_multi                               \\\n                           'BLOCK(30,1)' 'TENT(0,45,16)' 'BLOCK(30,1)'     \\\n                           'BLOCK(30,1)' 'TENT(0,45,16)' 'BLOCK(30,1)'     \\\n                           'BLOCK(30,1)' 'TENT(0,45,16)' 'BLOCK(30,1)'     \\", "help_range": [25577, 25884]}, {"param": "-regress_apply_mot_types", "line_start": 481, "length": 5, "param_range": [25909, 25933], "help": "                        -regress_apply_mot_types demean deriv              \\\n                        -regress_motion_per_run                            \\\n                        -regress_censor_motion 0.3                         \\\n                        -regress_censor_outliers 0.1                       \\\n                        -regress_compute_fitts                             \\", "help_range": [25885, 26269]}, {"param": "-regress_opts_3dD", "line_start": 486, "length": 5, "param_range": [26294, 26311], "help": "                        -regress_opts_3dD                                  \\\n                            -bout                                          \\\n                            -gltsym 'SYM: +eneg -fneg'                     \\\n                            -glt_label 1 eneg_vs_fneg                      \\\n                            -jobs 4                                        \\", "help_range": [26270, 26654]}, {"param": "-regress_run_clustsim", "line_start": 491, "length": 32, "param_range": [26679, 26700], "help": "                        -regress_run_clustsim no                           \\\n                        -regress_est_blur_epits                            \\\n                        -regress_est_blur_errts\n\n        Example 8. Surface-based analysis. ~2~\n\n           This example is intended to be run from AFNI_data6/FT_analysis.\n           It is provided with the class data in file s03.ap.surface.\n\n           Add -surf_spec and -surf_anat to provide the required spec and\n           surface volume datasets.  The surface volume will be aligned to\n           the current anatomy in the processing script.  Two spec files\n           (lh and rh) are provided, one for each hemisphere (via wildcard).\n\n           Also, specify a (resulting) 6 mm FWHM blur via -blur_size.  This\n           does not add a blur, but specifies a resulting blur level.  So\n           6 mm can be given directly for correction for multiple comparisons\n           on the surface.\n\n           Censor per-TR motion above 0.3 mm.\n\n           Note that no -regress_est_blur_errts option is given, since that\n           applies to the volume only (and since the 6 mm blur is a resulting\n           blur level, so the estimates are not needed).\n\n           The -blocks option is provided, but it is the same as the default\n           for surface-based analysis, so is not really needed here.  Note that\n           the 'surf' block is added and the 'mask' block is removed from the\n           volume-based defaults.\n\n           important options:", "help_range": [26655, 28166]}, {"param": "-blocks", "line_start": 523, "length": 2, "param_range": [28184, 28191], "help": "includes surf, but no mask\n                                  (default blocks for surf, so not needed)", "help_range": [28202, 28303]}, {"param": "-surf_anat", "line_start": 525, "length": 1, "param_range": [28320, 28330], "help": "volume aligned with surface", "help_range": [28338, 28365]}, {"param": "-surf_spec", "line_start": 526, "length": 8, "param_range": [28382, 28392], "help": "spec file(s) for surface\n\n           Note: one would probably want to use standard mesh surfaces here.\n                 This example will be updated with them in the future.\n\n                afni_proc.py -subj_id FT.surf                            \\\n                    -blocks tshift align volreg surf blur scale regress  \\\n                    -copy_anat FT/FT_anat+orig                           \\", "help_range": [28400, 28799]}, {"param": "-dsets", "line_start": 534, "length": 4, "param_range": [28820, 28826], "help": "                    -dsets FT/FT_epi_r?+orig.HEAD                        \\\n                    -surf_anat FT/SUMA/FTmb_SurfVol+orig                 \\\n                    -surf_spec FT/SUMA/FTmb_?h.spec                      \\\n                    -tcat_remove_first_trs 2                             \\", "help_range": [28800, 29099]}, {"param": "-align_opts_aea", "line_start": 538, "length": 4, "param_range": [29120, 29135], "help": "                    -align_opts_aea -cost lpc+ZZ                         \\\n                    -volreg_align_to third                               \\\n                    -volreg_align_e2a                                    \\\n                    -blur_size 6                                         \\", "help_range": [29100, 29399]}, {"param": "-regress_stim_times", "line_start": 542, "length": 1, "param_range": [29420, 29439], "help": "                    -regress_stim_times FT/AV1_vis.txt FT/AV2_aud.txt    \\", "help_range": [29400, 29474]}, {"param": "-regress_stim_labels", "line_start": 543, "length": 4, "param_range": [29495, 29515], "help": "                    -regress_stim_labels vis aud                         \\\n                    -regress_basis 'BLOCK(20,1)'                         \\\n                    -regress_motion_per_run                              \\\n                    -regress_censor_motion 0.3                           \\", "help_range": [29475, 29774]}, {"param": "-regress_opts_3dD", "line_start": 547, "length": 60, "param_range": [29795, 29812], "help": "                    -regress_opts_3dD                                    \\\n                        -jobs 2                                          \\\n                        -gltsym 'SYM: vis -aud' -glt_label 1 V-A\n\n        Example 9. Resting state analysis (modern): ~2~\n\n           With censoring and bandpass filtering.\n\n           This is our suggested way to do pre-processing for resting state\n           analysis, under the assumption that no cardio/physio recordings\n           were made (see example 5 for cardio files).\n\n           Censoring due to motion has long been considered appropriate in\n           BOLD FMRI analysis, but is less common for those doing bandpass\n           filtering in RS FMRI because the FFT requires one to either break\n           the time axis (evil) or to replace the censored data with something\n           probably inappropriate.\n\n           Instead, it is slow (no FFT, but maybe SFT :) but effective to\n           regress frequencies within the regression model, where censoring\n           is simple.\n\n           inputs: anat, EPI\n           output: errts dataset (to be used for correlation)\n\n           special processing:\n              - despike, as another way to reduce motion effect\n                 (see block despike)\n              - censor motion TRs at the same time as bandpassing data\n                 (see -regress_censor_motion, -regress_bandpass)\n              - regress motion parameters AND derivatives\n                 (see -regress_apply_mot_types)\n\n           Note: for resting state data, a more strict threshold may be a good\n                 idea, since motion artifacts should play a bigger role than in\n                 a task-based analysis.\n\n                 So the typical suggestion of motion censoring at 0.3 for task\n                 based analysis has been changed to 0.2 for this resting state\n                 example, and censoring of outliers has also been added.\n\n                 Outliers are typically due to motion, and may capture motion\n                 in some cases where the motion parameters do not, because\n                 motion is not generally a whole-brain-between-TRs event.\n\n           Note: if regressing out regions of interest, either create the ROI\n                 time series before the blur step, or remove blur from the list\n                 of blocks (and apply any desired blur after the regression).\n\n           Note: it might be reasonable to estimate the blur using epits rather\n                 than errts in the case of bandpassing.  Both options are\n                 included here.\n\n           Note: scaling is optional here.  While scaling has no direct effect\n                 on voxel correlations, it does have an effect on ROI averages\n                 used for correlations.\n\n           Other options to consider: -tlrc_NL_warp, -anat_uniform_method\n\n                afni_proc.py -subj_id subj123                                \\", "help_range": [29775, 32724]}, {"param": "-dsets", "line_start": 607, "length": 9, "param_range": [32743, 32749], "help": "                  -dsets epi_run1+orig.HEAD                                  \\\n                  -copy_anat anat+orig                                       \\\n                  -blocks despike tshift align tlrc volreg blur mask regress \\\n                  -tcat_remove_first_trs 3                                   \\\n                  -volreg_align_e2a                                          \\\n                  -volreg_tlrc_warp                                          \\\n                  -regress_censor_motion 0.2                                 \\\n                  -regress_censor_outliers 0.1                               \\\n                  -regress_bandpass 0.01 0.1                                 \\", "help_range": [32725, 33435]}, {"param": "-regress_apply_mot_types", "line_start": 616, "length": 8, "param_range": [33454, 33478], "help": "                  -regress_apply_mot_types demean deriv                      \\\n                  -regress_est_blur_epits                                    \\\n                  -regress_est_blur_errts\n\n       Example 9b. Resting state analysis with ANATICOR. ~2~\n\n           Like example #9, but also regress out the signal from locally\n           averaged white matter.  The only change is adding the option", "help_range": [33436, 33843]}, {"param": "-regress_anaticor.", "line_start": 624, "length": 3, "param_range": [33855, 33873], "help": "           -regress_anaticor.\n\n           Note that -regress_anaticor implies options -mask_segment_anat and", "help_range": [33844, 33952]}, {"param": "-mask_segment_erode", "line_start": 627, "length": 3, "param_range": [33964, 33983], "help": "           -mask_segment_erode.\n\n                afni_proc.py -subj_id subj123                                \\", "help_range": [33953, 34064]}, {"param": "-dsets", "line_start": 630, "length": 10, "param_range": [34083, 34089], "help": "                  -dsets epi_run1+orig.HEAD                                  \\\n                  -copy_anat anat+orig                                       \\\n                  -blocks despike tshift align tlrc volreg blur mask regress \\\n                  -tcat_remove_first_trs 3                                   \\\n                  -volreg_align_e2a                                          \\\n                  -volreg_tlrc_warp                                          \\\n                  -regress_anaticor                                          \\\n                  -regress_censor_motion 0.2                                 \\\n                  -regress_censor_outliers 0.1                               \\\n                  -regress_bandpass 0.01 0.1                                 \\", "help_range": [34065, 34854]}, {"param": "-regress_apply_mot_types", "line_start": 640, "length": 8, "param_range": [34873, 34897], "help": "                  -regress_apply_mot_types demean deriv                      \\\n                  -regress_est_blur_epits                                    \\\n                  -regress_est_blur_errts\n\n       Example 10. Resting state analysis, with tissue-based regressors. ~2~\n\n           Like example #9, but also regress the eroded white matter averages.\n           The WMe mask come from the Classes dataset, created by 3dSeg via the", "help_range": [34855, 35292]}, {"param": "-mask_segment_anat", "line_start": 648, "length": 17, "param_range": [35304, 35322], "help": "           -mask_segment_anat and -mask_segment_erode options.\n\n        ** While -mask_segment_anat also creates a CSF mask, that mask is ALL\n           CSF, not just restricted to the ventricles, for example.  So it is\n           probably not appropriate for use in tissue-based regression.\n\n           CSFe was previously used as an example of what one could do, but as\n           it is not advised, it has been removed.\n\n           Also, align to minimum outlier volume, and align to the anatomy\n           using cost function lpc+ZZ.\n\n           Note: it might be reasonable to estimate the blur using epits rather\n                 than errts in the case of bandpassing.  Both options are\n                 included here.\n\n                afni_proc.py -subj_id subj123                                \\", "help_range": [35293, 36097]}, {"param": "-dsets", "line_start": 665, "length": 4, "param_range": [36116, 36122], "help": "                  -dsets epi_run1+orig.HEAD                                  \\\n                  -copy_anat anat+orig                                       \\\n                  -blocks despike tshift align tlrc volreg blur mask regress \\\n                  -tcat_remove_first_trs 3                                   \\", "help_range": [32725, 33040]}, {"param": "-align_opts_aea", "line_start": 669, "length": 4, "param_range": [36432, 36447], "help": "                  -align_opts_aea -cost lpc+ZZ                               \\\n                  -volreg_align_to MIN_OUTLIER                               \\\n                  -volreg_align_e2a                                          \\\n                  -volreg_tlrc_warp                                          \\", "help_range": [36414, 36729]}, {"param": "-mask_segment_anat", "line_start": 673, "length": 1, "param_range": [36748, 36766], "help": "                  -mask_segment_anat yes                                     \\", "help_range": [36730, 36808]}, {"param": "-mask_segment_erode", "line_start": 674, "length": 4, "param_range": [36827, 36846], "help": "                  -mask_segment_erode yes                                    \\\n                  -regress_censor_motion 0.2                                 \\\n                  -regress_censor_outliers 0.1                               \\\n                  -regress_bandpass 0.01 0.1                                 \\", "help_range": [36809, 37124]}, {"param": "-regress_apply_mot_types", "line_start": 678, "length": 1, "param_range": [37143, 37167], "help": "                  -regress_apply_mot_types demean deriv                      \\", "help_range": [33436, 33514]}, {"param": "-regress_ROI", "line_start": 679, "length": 19, "param_range": [37222, 37234], "help": "                  -regress_ROI WMe                                           \\\n                  -regress_est_blur_epits                                    \\\n                  -regress_est_blur_errts\n\n       Example 10b. Resting state analysis, as 10a with 3dRSFC. ~2~\n\n            This is for band passing and computation of ALFF, etc.\n\n          * This will soon use a modified 3dRSFC.\n\n            Like example #10, but add -regress_RSFC to bandpass via 3dRSFC.\n            Skip censoring and regression band passing because of the bandpass\n            operation in 3dRSFC.\n\n            To correspond to common tractography, this example stays in orig\n            space (no 'tlrc' block, no -volreg_tlrc_warp option).  Of course,\n            going to standard space is an option.\n\n                afni_proc.py -subj_id subj123                                \\", "help_range": [37204, 38066]}, {"param": "-dsets", "line_start": 698, "length": 7, "param_range": [38085, 38091], "help": "                  -dsets epi_run1+orig.HEAD                                  \\\n                  -copy_anat anat+orig                                       \\\n                  -blocks despike tshift align volreg blur mask regress      \\\n                  -tcat_remove_first_trs 3                                   \\\n                  -volreg_align_e2a                                          \\\n                  -blur_size 6.0                                             \\\n                  -mask_apply epi                                            \\", "help_range": [38067, 38619]}, {"param": "-mask_segment_anat", "line_start": 705, "length": 1, "param_range": [38638, 38656], "help": "                  -mask_segment_anat yes                                     \\", "help_range": [36730, 36808]}, {"param": "-mask_segment_erode", "line_start": 706, "length": 2, "param_range": [38717, 38736], "help": "                  -mask_segment_erode yes                                    \\\n                  -regress_bandpass 0.01 0.1                                 \\", "help_range": [38699, 38856]}, {"param": "-regress_apply_mot_types", "line_start": 708, "length": 1, "param_range": [38875, 38899], "help": "                  -regress_apply_mot_types demean deriv                      \\", "help_range": [33436, 33514]}, {"param": "-regress_ROI", "line_start": 709, "length": 2, "param_range": [38954, 38966], "help": "                  -regress_ROI WMe                                           \\\n                  -regress_RSFC                                              \\", "help_range": [38936, 39093]}, {"param": "-regress_run_clustsim", "line_start": 711, "length": 46, "param_range": [39112, 39133], "help": "                  -regress_run_clustsim no                                   \\\n                  -regress_est_blur_errts\n\n       Example 11. Resting state analysis (now even more modern :). ~2~\n\n         o Yes, censor (outliers and motion) and despike.\n         o Align the anatomy and EPI using the lpc+ZZ cost function, rather\n           than the default lpc one.\n         o Register EPI volumes to the one which has the minimum outlier\n              fraction (so hopefully the least motion).\n         o Use non-linear registration to MNI template (non-linear 2009c).\n           * This adds a lot of processing time.\n         o No bandpassing.\n         o Use fast ANATICOR method (slightly different from default ANATICOR).\n         o Use FreeSurfer segmentation for:\n             - regression of first 3 principal components of lateral ventricles\n             - ANATICOR white matter mask (for local white matter regression)\n           * For details on how these masks were created, see \"FREESURFER NOTE\"\n             in the help, as it refers to this \"Example 11\".\n         o Input anat is from FreeSurfer (meaning it is aligned with FS masks).\n             - output from FS is usually not quite aligned with input\n         o Erode FS white matter and ventricle masks before application.\n         o Bring along FreeSurfer parcellation datasets:\nNN interpolated onto the anatomical grid\n             - aeseg : NN interpolated onto the EPI        grid\n           * These 'aseg' follower datasets are just for visualization,\n             they are not actually required for the analysis.\n         o Compute average correlation volumes of the errts against the\n           the gray matter (aeseg) and ventricle (FSVent) masks.\n\n           Note: it might be reasonable to use either set of blur estimates\n                 here (from epits or errts).  The epits (uncleaned) dataset\n                 has all of the noise (though what should be considered noise\n                 in this context is not clear), while the errts is motion\n                 censored.  For consistency in resting state, it would be\n                 reasonable to stick with epits.  They will likely be almost\n                 identical.\n\n\n                afni_proc.py -subj_id FT.11.rest                             \\\n                  -blocks despike tshift align tlrc volreg blur mask regress \\\n                  -copy_anat FT_SurfVol.nii                                  \\\n                  -anat_follower_ROI aaseg anat aparc.a2009s+aseg.nii        \\\n                  -anat_follower_ROI aeseg epi  aparc.a2009s+aseg.nii        \\\n                  -anat_follower_ROI FSvent epi FT_vent.nii                  \\\n                  -anat_follower_ROI FSWe epi FT_white.nii                   \\", "help_range": [39112, 41875]}, {"param": "-anat_follower_erode", "line_start": 757, "length": 1, "param_range": [41899, 41919], "help": "                  -anat_follower_erode FSvent FSWe                           \\", "help_range": [41881, 41959]}, {"param": "-dsets", "line_start": 758, "length": 2, "param_range": [41978, 41984], "help": "                  -dsets FT_epi_r?+orig.HEAD                                 \\\n                  -tcat_remove_first_trs 2                                   \\", "help_range": [41960, 42117]}, {"param": "-align_opts_aea", "line_start": 760, "length": 7, "param_range": [42136, 42151], "help": "                  -align_opts_aea -cost lpc+ZZ                               \\\n                  -tlrc_base MNI152_T1_2009c+tlrc                            \\\n                  -tlrc_NL_warp                                              \\\n                  -volreg_align_to MIN_OUTLIER                               \\\n                  -volreg_align_e2a                                          \\\n                  -volreg_tlrc_warp                                          \\\n                  -regress_motion_per_run                                    \\", "help_range": [42118, 42670]}, {"param": "-regress_ROI", "line_start": 767, "length": 1, "param_range": [42689, 42701], "help": "                  -regress_ROI_PC FSvent 3                                   \\", "help_range": [42671, 42749]}, {"param": "-regress_make_corr_vols", "line_start": 768, "length": 5, "param_range": [42768, 42791], "help": "                  -regress_make_corr_vols aeseg FSvent                       \\\n                  -regress_anaticor_fast                                     \\\n                  -regress_anaticor_label FSWe                               \\\n                  -regress_censor_motion 0.2                                 \\\n                  -regress_censor_outliers 0.1                               \\", "help_range": [42750, 43144]}, {"param": "-regress_apply_mot_types", "line_start": 773, "length": 13, "param_range": [43163, 43187], "help": "                  -regress_apply_mot_types demean deriv                      \\\n                  -regress_est_blur_epits                                    \\\n                  -regress_est_blur_errts\n\n       Example 11b. Similar to 11, but without FreeSurfer. ~2~\n\n         AFNI currently does not have a good program to extract ventricles.\n         But it can make a CSF mask that includes them.  So without FreeSurfer,\n         one could import a ventricle mask from the template (e.g. for TT space,\n         using TT_desai_dd_mpm+tlrc).  For example, assume Talairach space for\n         the analysis, create a ventricle mask as follows:\n\n                3dcalc -a ~/abin/TT_desai_dd_mpm+tlrc                       \\", "help_range": [43145, 43863]}, {"param": "-e", "line_start": 786, "length": 18, "param_range": [43887, 43889], "help": "                       -expr 'amongst(a,152,170)' -prefix template_ventricle\n                3dresample -dxyz 2.5 2.5 2.5 -inset template_ventricle+tlrc \\\n                       -prefix template_ventricle_2.5mm\n\n         o Be explicit with 2.5mm, using '-volreg_warp_dxyz 2.5'.\n         o Use template TT_N27+tlrc, to be aligned with the desai atlas.\n         o No -anat_follower options, but use -mask_import to import the\n           template_ventricle_2.5mm dataset (and call it Tvent).\n         o Use -mask_intersect to intersect ventricle mask with the subject's\n           CSFe mask, making a more reliable subject ventricle mask (Svent).\n         o Ventricle principle components are created as per-run regressors.\n         o Make WMe and Svent correlation volumes, which are just for\n           entertainment purposes anyway.\n         o Run the cluster simulation.\n\n                afni_proc.py -subj_id FT.11b.rest                            \\\n                  -blocks despike tshift align tlrc volreg blur mask regress \\\n                  -copy_anat FT_anat+orig                                    \\", "help_range": [43864, 44973]}, {"param": "-dsets", "line_start": 804, "length": 2, "param_range": [44992, 44998], "help": "                  -dsets FT_epi_r?+orig.HEAD                                 \\\n                  -tcat_remove_first_trs 2                                   \\", "help_range": [41960, 42117]}, {"param": "-align_opts_aea", "line_start": 806, "length": 7, "param_range": [45150, 45165], "help": "                  -align_opts_aea -cost lpc+ZZ                               \\\n                  -tlrc_base TT_N27+tlrc                                     \\\n                  -tlrc_NL_warp                                              \\\n                  -volreg_align_to MIN_OUTLIER                               \\\n                  -volreg_align_e2a                                          \\\n                  -volreg_tlrc_warp                                          \\\n                  -volreg_warp_dxyz 2.5                                      \\", "help_range": [45132, 45684]}, {"param": "-mask_segment_anat", "line_start": 813, "length": 1, "param_range": [45703, 45721], "help": "                  -mask_segment_anat yes                                     \\", "help_range": [36730, 36808]}, {"param": "-mask_segment_erode", "line_start": 814, "length": 4, "param_range": [45782, 45801], "help": "                  -mask_segment_erode yes                                    \\\n                  -mask_import Tvent template_ventricle_2.5mm+tlrc           \\\n                  -mask_intersect Svent CSFe Tvent                           \\\n                  -regress_motion_per_run                                    \\", "help_range": [45764, 46079]}, {"param": "-regress_ROI", "line_start": 818, "length": 1, "param_range": [46098, 46110], "help": "                  -regress_ROI_PC Svent 3                                    \\", "help_range": [46080, 46158]}, {"param": "-regress_ROI_PC_per_run", "line_start": 819, "length": 1, "param_range": [46177, 46200], "help": "                  -regress_ROI_PC_per_run Svent                              \\", "help_range": [46159, 46237]}, {"param": "-regress_make_corr_vols", "line_start": 820, "length": 4, "param_range": [46256, 46279], "help": "                  -regress_make_corr_vols WMe Svent                          \\\n                  -regress_anaticor_fast                                     \\\n                  -regress_censor_motion 0.2                                 \\\n                  -regress_censor_outliers 0.1                               \\", "help_range": [46238, 46553]}, {"param": "-regress_apply_mot_types", "line_start": 824, "length": 3, "param_range": [46572, 46596], "help": "                  -regress_apply_mot_types demean deriv                      \\\n                  -regress_est_blur_epits                                    \\\n                  -regress_est_blur_errts                                    \\", "help_range": [46554, 46790]}, {"param": "-regress_run_clustsim", "line_start": 827, "length": 8, "param_range": [46809, 46830], "help": "                  -regress_run_clustsim yes\n\n       Example 12 background: Multi-echo data processing. ~2~\n\n         Processing multi-echo data should be similar to single echo data,\n         except for perhaps:\n\n            combine         : the addition of a 'combine' block", "help_range": [46791, 47067]}, {"param": "-dsets_me_echo", "line_start": 835, "length": 1, "param_range": [47080, 47094], "help": "specify ME data, per echo", "help_range": [47098, 47123]}, {"param": "-dsets_me_run", "line_start": 836, "length": 1, "param_range": [47136, 47149], "help": "specify ME data, per run (alternative to _echo)", "help_range": [47154, 47201]}, {"param": "-echo_times", "line_start": 837, "length": 1, "param_range": [47214, 47225], "help": "specify echo times (if needed)", "help_range": [47232, 47262]}, {"param": "-combine_method", "line_start": 838, "length": 7, "param_range": [47275, 47290], "help": "specify method to combine echoes (if any)\n\n         An afni_proc.py command might be updated to include something like:\n\n            afni_proc.py ...                                     \\\n                -blocks tshift align tlrc volreg mask combine    \\\n                        blur scale regress                       \\", "help_range": [47293, 47614]}, {"param": "-dsets", "line_start": 845, "length": 1, "param_range": [47631, 47637], "help": "                -dsets_me_echo epi_run*_echo_01.nii              \\", "help_range": [47615, 47681]}, {"param": "-dsets", "line_start": 846, "length": 1, "param_range": [47698, 47704], "help": "                -dsets_me_echo epi_run*_echo_02.nii              \\", "help_range": [47682, 47748]}, {"param": "-dsets", "line_start": 847, "length": 1, "param_range": [47765, 47771], "help": "                -dsets_me_echo epi_run*_echo_03.nii              \\", "help_range": [47749, 47815]}, {"param": "-e", "line_start": 848, "length": 2, "param_range": [47832, 47834], "help": "                -echo_times 15 30.5 41                           \\\n                ...                                              \\", "help_range": [47816, 47949]}, {"param": "-mask_epi_anat", "line_start": 850, "length": 22, "param_range": [47966, 47980], "help": "                -mask_epi_anat yes                               \\\n                -combine_method OC                               \\\n                ...                                              \\\n\n\n       Example 12a. Multi-echo data processing - very simple. ~2~\n\n         Keep it simple and just focus on the basic ME options, plus a few\n         for controlling registration.\n\n         o This example uses 3 echoes of data across just 1 run.\n            - so use a single -dsets_me_run option to input EPI datasets\n         o Echo 2 is used to drive registration for all echoes.\n            - That is the default, but it is good to be explicit.\n         o The echo times are not needed, as the echoes are never combined.\n         o The echo are never combined (in this example), so that there\n           are always 3 echoes, even until the end.\n            - Note that the 'regress' block is not valid for multiple echoes.\n\n                afni_proc.py -subj_id FT.12a.ME                 \\\n                  -blocks tshift align tlrc volreg mask blur    \\\n                  -copy_anat FT_anat+orig                       \\", "help_range": [47950, 49079]}, {"param": "-dsets", "line_start": 872, "length": 23, "param_range": [49098, 49104], "help": "                  -dsets_me_run epi_run1_echo*.nii              \\\n                  -reg_echo 2                                   \\\n                  -tcat_remove_first_trs 2                      \\\n                  -volreg_align_to MIN_OUTLIER                  \\\n                  -volreg_align_e2a                             \\\n                  -volreg_tlrc_warp\n\n       Example 12b. Multi-echo data processing - OC resting state. ~2~\n\n         Still keep this simple, mostly focusing on ME options, plus standard\n         ones for resting state.\n\n         o This example uses 3 echoes of data across just 1 run.\n            - so use a single -dsets_me_run option to input EPI datasets\n         o Echo 2 is used to drive registration for all echoes.\n            - That is the default, but it is good to be explicit.\n         o The echoes are combined via the 'combine' block.\n         o So -echo_times is used to provided them.\n\n                afni_proc.py -subj_id FT.12a.ME                 \\\n                  -blocks tshift align tlrc volreg mask combine \\\n                          blur scale regress                    \\\n                  -copy_anat FT_anat+orig                       \\", "help_range": [49080, 50275]}, {"param": "-dsets", "line_start": 895, "length": 1, "param_range": [50294, 50300], "help": "                  -dsets_me_run epi_run1_echo*.nii              \\", "help_range": [49080, 49145]}, {"param": "-e", "line_start": 896, "length": 3, "param_range": [50360, 50362], "help": "                  -echo_times 15 30.5 41                        \\\n                  -reg_echo 2                                   \\\n                  -tcat_remove_first_trs 2                      \\", "help_range": [50342, 50539]}, {"param": "-align_opts_aea", "line_start": 899, "length": 6, "param_range": [50558, 50573], "help": "                  -align_opts_aea -cost lpc+ZZ                  \\\n                  -tlrc_base MNI152_T1_2009c+tlrc               \\\n                  -tlrc_NL_warp                                 \\\n                  -volreg_align_to MIN_OUTLIER                  \\\n                  -volreg_align_e2a                             \\\n                  -volreg_tlrc_warp                             \\", "help_range": [50540, 50935]}, {"param": "-mask_epi_anat", "line_start": 905, "length": 5, "param_range": [50954, 50968], "help": "                  -mask_epi_anat yes                            \\\n                  -combine_method OC                            \\\n                  -regress_motion_per_run                       \\\n                  -regress_censor_motion 0.2                    \\\n                  -regress_censor_outliers 0.1                  \\", "help_range": [50936, 51265]}, {"param": "-regress_apply_mot_types", "line_start": 910, "length": 16, "param_range": [51284, 51308], "help": "                  -regress_apply_mot_types demean deriv         \\\n                  -regress_est_blur_epits\n\n       Example 12c. Multi-echo data processing - ME-ICA resting state. ~2~\n\n         As above, but run tedana.py for MEICA denoising.\n\n         o Since tedana.py will mask the data, it may be preferable to\n           blur only within that mask (-blur_in_mask yes).\n         o A task analysis using tedana might look much the same,\n           but with the extra -regress options for the tasks.\n\n                afni_proc.py -subj_id FT.12a.ME                 \\\n                  -blocks tshift align tlrc volreg mask combine \\\n                          blur scale regress                    \\\n                  -copy_anat FT_anat+orig                       \\", "help_range": [51266, 52032]}, {"param": "-dsets", "line_start": 926, "length": 1, "param_range": [52051, 52057], "help": "                  -dsets_me_run epi_run1_echo*.nii              \\", "help_range": [49080, 49145]}, {"param": "-e", "line_start": 927, "length": 3, "param_range": [52117, 52119], "help": "                  -echo_times 15 30.5 41                        \\\n                  -reg_echo 2                                   \\\n                  -tcat_remove_first_trs 2                      \\", "help_range": [50342, 50539]}, {"param": "-align_opts_aea", "line_start": 930, "length": 6, "param_range": [52315, 52330], "help": "                  -align_opts_aea -cost lpc+ZZ                  \\\n                  -tlrc_base MNI152_T1_2009c+tlrc               \\\n                  -tlrc_NL_warp                                 \\\n                  -volreg_align_to MIN_OUTLIER                  \\\n                  -volreg_align_e2a                             \\\n                  -volreg_tlrc_warp                             \\", "help_range": [50540, 50935]}, {"param": "-mask_epi_anat", "line_start": 936, "length": 2, "param_range": [52711, 52725], "help": "                  -mask_epi_anat yes                            \\\n                  -combine_method tedana                        \\", "help_range": [52693, 52824]}, {"param": "-blur_in_mask", "line_start": 938, "length": 4, "param_range": [52843, 52856], "help": "                  -blur_in_mask yes                             \\\n                  -regress_motion_per_run                       \\\n                  -regress_censor_motion 0.2                    \\\n                  -regress_censor_outliers 0.1                  \\", "help_range": [52825, 53088]}, {"param": "-regress_apply_mot_types", "line_start": 942, "length": 6, "param_range": [53107, 53131], "help": "                  -regress_apply_mot_types demean deriv         \\\n                  -regress_est_blur_epits\n\n         Consider an alternative combine method, 'tedana_OC_tedort'.\n\n    --------------------------------------------------", "help_range": [53089, 53322]}, {"param": "-ask_me", "line_start": 948, "length": 14, "param_range": [53327, 53334], "help": " ** NOTE: -ask_me is antiquated ** ~2~\n\n        a1. Apply -ask_me in the most basic form, with no other options.\n\n                afni_proc.py -ask_me\n\n        a2. Supply input datasets.\n\n                afni_proc.py -ask_me -dsets ED/ED_r*.HEAD\n\n        a3. Same as a2, but supply the datasets in expanded form.\n            No suffix (.HEAD) is needed when wildcards are not used.\n\n                afni_proc.py -ask_me                          \\", "help_range": [53345, 53791]}, {"param": "-dsets", "line_start": 962, "length": 9, "param_range": [53813, 53819], "help": "                     -dsets ED/ED_r01+orig ED/ED_r02+orig     \\\n                            ED/ED_r03+orig ED/ED_r04+orig     \\\n                            ED/ED_r05+orig ED/ED_r06+orig     \\\n                            ED/ED_r07+orig ED/ED_r08+orig     \\\n                            ED/ED_r09+orig ED/ED_r10+orig\n\n        a4. Supply datasets, stim_times files and labels.\n\n                afni_proc.py -ask_me                                    \\", "help_range": [53792, 54239]}, {"param": "-dsets", "line_start": 971, "length": 1, "param_range": [54264, 54270], "help": "                        -dsets ED/ED_r*.HEAD                            \\", "help_range": [54240, 54313]}, {"param": "-regress_stim_times", "line_start": 972, "length": 1, "param_range": [54338, 54357], "help": "                        -regress_stim_times misc_files/stim_times.*.1D  \\", "help_range": [54314, 54387]}, {"param": "-regress_stim_labels", "line_start": 973, "length": 150, "param_range": [54412, 54432], "help": "                        -regress_stim_labels ToolMovie HumanMovie       \\\n                                             ToolPoint HumanPoint\n\n\n\n    ==================================================\n    Many NOTE sections: ~1~\n    ==================================================\n\n    --------------------------------------------------\n    GENERAL ANALYSIS NOTE: ~2~\n\n    How might one run a full analysis?  Here are some details to consider.\n\n    0. Expect to re-run the full analysis.  This might be to fix a mistake, to\n       change applied options or to run with current software, to name a few\n       possibilities.  So...\n\n         - keep permanently stored input data separate from computed results\n           (one should be able to easily delete the results to start over)\n         - keep scripts in yet another location\n         - use file naming that is consistent across subjects and groups,\n           making it easy to script with\n\n    1. Script everything.  One should be able to carry out the full analysis\n       just by running the main scripts.\n\n       Learning is best done by typing commands and looking at data, including\n       the input to and output from said commands.  But running an analysis for\n       publication should not rely on typing complicated commands or pressing\n       buttons in a GUI (graphical user interface).\n\n         - it is easy to apply to new subjects\n         - the steps can be clear and unambiguous (no magic or black boxes)\n         - some scripts can be included with publication\n           (e.g. an afni_proc.py command, with the AFNI version)\n\n         - using a GUI relies on consistent button pressing, making it much\n           more difficult to *correctly* repeat, or even understand\n\n    2. Analyze and perform quality control on new subjects promptly.\n\n         - any problems with the acquisition would (hopefully) be caught early\n         - can compare basic quality control measures quickly\n\n    3. LOOK AT YOUR DATA.  Quality control is best done by researchers.\n       Software should not be simply trusted.\n\n         - afni_proc.py processing scripts write guiding @ss_review_driver\n           scripts for *minimal* per-subject quality control (i.e. at a\n           minimum, run that for every subject)\n         - initial subjects should be scrutinized (beyond @ss_review_driver)\n\n         - concatenate anat_final datasets to look for consistency\n         - concatenate final_epi datasets to look for consistency\n         - run gen_ss_review_table.py on the out.ss_review*.txt files\n           (making a spreadsheet to quickly scan for outlier subjects)\n\n         - many issues can be detected by software, buy those usually just come\n           as warnings to the researcher\n         - similarly, some issues will NOT be detected by the software\n         - for QC, software can assist the researcher, not replace them\n\n         NOTE: Data from external sites should be heavily scrutinized,\n               including any from well known public repositories.\n\n    4. Consider regular software updates, even as new subjects are acquired.\n       This ends up requiring a full re-analysis at the end.\n\n       If it will take a while (one year or more?) to collect data, update the\n       software regularly (weekly?  monthly?).  Otherwise, the analysis ends up\n       being done with old software.\n\n          - analysis is run with current, rather than old software\n          - will help detect changes in the software (good ones or bad ones)\n          - at a minimum, more quality control tools tend to show up\n          - keep a copy of the prior software version, in case comparisons are\n            desired (@update.afni.binaries does keep one prior version)\n          - the full analysis should be done with one software version, so once\n            all datasets are collected, back up the current analysis and re-run\n            the entire thing with the current software\n          - keep a snapshot of the software package used for the analysis\n          - report the software version in any publication\n\n    5. Here is a sample (tcsh) script that might run a basic analysis on\n       one or more subjects:\n\n       ======================================================================\n       sample analysis script ~3~\n       ======================================================================\n\n       #!/bin/tcsh\n\n       # --------------------------------------------------\n       # note fixed top-level directories\n       set data_root = /main/location/of/all/data\n\n       set input_root = $data_root/scanner_data\n       set output_root = $data_root/subject_analysis\n\n       # --------------------------------------------------\n       # get a list of subjects, or just use one (consider $argv)\n       cd $input root\n       set subjects = ( subj* )\n       cd -\n\n       # or perhaps just process one subject?\n       set subjects = ( subj_017 )\n\n\n       # --------------------------------------------------\n       # process all subjects\n       foreach subj_id ( $subjects )\n\n          # --------------------------------------------------\n          # note input and output directories\n          set subj_indir = $input_root/$subj_id\n          set subj_outdir = $output_root/$subj_id\n\n          # --------------------------------------------------\n          # if output dir exists, this subject has already been processed\n          if ( -d $subj_outdir ) then\n             echo \"** results dir already exists, skipping subject $subj_id\"\n             continue\n          endif\n\n          # --------------------------------------------------\n          # otherwise create the output directory, write an afni_proc.py\n          # command to it, and fire it up\n\n          mkdir -p $subj_outdir\n          cd $subj_outdir\n\n          # create a run.afni_proc script in this directory\n          cat > run.afni_proc << EOF\n\n          # notes:\n          #   - consider different named inputs (rather than OutBrick)\n          #   - verify how many time points to remove at start (using 5)\n          #   - note which template space is preferable (using MNI)\n          #   - consider non-linear alignment via -tlrc_NL_warp\n          #   - choose blur size (using FWHM = 4 mm)\n          #   - choose basis function (using BLOCK(2,1), for example)\n          #   - assuming 4 CPUs for linear regression\n          #   - afni_proc.py will actually run the proc script (-execute)\n\n\n          afni_proc.py -subj_id $subj_id                          \\\n              -blocks tshift align tlrc volreg blur mask regress  \\\n              -copy_anat $subj_indir/anat+orig                    \\", "help_range": [54388, 61025]}, {"param": "-dsets", "line_start": 1123, "length": 5, "param_range": [61040, 61046], "help": "              -dsets                                              \\\n                  $subj_indir/epi_r1+orig                         \\\n                  $subj_indir/epi_r2+orig                         \\\n                  $subj_indir/epi_r3+orig                         \\\n              -tcat_remove_first_trs 5                            \\", "help_range": [61026, 61365]}, {"param": "-align_opts_aea", "line_start": 1128, "length": 10, "param_range": [61380, 61395], "help": "              -align_opts_aea -cost lpc+ZZ                        \\\n              -tlrc_base MNI152_T1_2009c+tlrc                     \\\n              -tlrc_NL_warp                                       \\\n              -volreg_align_to MIN_OUTLIER                        \\\n              -volreg_align_e2a                                   \\\n              -volreg_tlrc_warp                                   \\\n              -blur_size 4.0                                      \\\n              -regress_motion_per_run                             \\\n              -regress_censor_motion 0.3                          \\\n              -regress_reml_exec -regress_3dD_stop                \\", "help_range": [61366, 62045]}, {"param": "-regress_stim_times", "line_start": 1138, "length": 5, "param_range": [62060, 62079], "help": "              -regress_stim_times                                 \\\n                  $stim_dir/houses.txt                            \\\n                  $stim_dir/faces.txt                             \\\n                  $stim_dir/doughnuts.txt                         \\\n                  $stim_dir/pizza.txt                             \\", "help_range": [62046, 62385]}, {"param": "-regress_stim_labels", "line_start": 1143, "length": 3, "param_range": [62400, 62420], "help": "              -regress_stim_labels                                \\\n                  house face nuts za                              \\\n              -regress_basis 'BLOCK(2,1)'                         \\", "help_range": [62386, 62589]}, {"param": "-regress_opts_3dD", "line_start": 1146, "length": 5, "param_range": [62604, 62621], "help": "              -regress_opts_3dD                                   \\\n                  -jobs 4                                         \\\n                  -gltsym 'SYM: house -face' -glt_label 1 H-F     \\\n                  -gltsym 'SYM: nuts -za'    -glt_label 2 N-Z     \\\n              -regress_est_blur_errts                             \\", "help_range": [62590, 62929]}, {"param": "-e", "line_start": 1151, "length": 497, "param_range": [62944, 62946], "help": "              -execute\n\n          EOF\n          # EOF denotes the end of the run.afni_proc command\n\n          # now run the analysis (generate proc and execute)\n          tcsh run.afni_proc\n\n       # end loop over subjects\n       end\n\n       ======================================================================\n\n    --------------------------------------------------\n    QUALITY CONTROL NOTE: ~2~\n\n    Look at the data.\n\n    Nothing replaces a living human performing quality control checks by\n    looking at the data.  And the more a person looks at the data, the better\n    they get at spotting anomalies.\n\n    There are 2 types of QC support generated by afni_proc.py, scripts to help\n    someone review the data, and individual text or image files.\n\n        ----------------------------------------------------------------------\n        scripts (the user can run from the results directory):\n\n           @epi_review.FT               - view original (post-SS) EPI data\n           @ss_review_basic             - show basic QC measures, in text\n           @ss_review_driver            - minimum recommended QC review\n           @ss_review_driver_commands   - same, as pure commands\n\n           Notably, the @ss_review_driver script is recommended as the minimum\n           QC to perform on every subject.\n\n        ----------------------------------------------------------------------\n        other files or datasets:   (* shown or reviewed by @ss_review_driver)\n\n        *  3dDeconvolve.err\n\n              This contains any warnings (or errors) from 3dDeconvolve.  This\n              will be created even if 3dREMLfit is run.\n\n        *  anat_final.$subj\n\n              This AFNI dataset should be registered with the final stats\n              (including final_epi_vr_base) and with any applied template.\n              There is also a version with the skull, anat_w_skull_warped.\n\n        *  blur_est.$subj.1D\n\n              This (text) file has the mixed-model ACF (and possibly the FWHM)\n              parameter estimates of the blur.\n\n           Classes\n\n              If 3dSeg is run for anatomical segmentation, this AFNI dataset\n              contains the results, a set of masks per tissue class.  The\n              white matter mask from this might be used for ANATICOR, for\n              example.\n\n           corr_brain\n\n              This AFNI dataset shows the correlation of every voxel with the\n              global signal (brain average time series).\n\n              One can request other corr_* datasets, based on any tissue or ROI\n              mask.  See -regress_make_corr_vols for details.\n\n        *  dfile_rall.1D (and efile.r??.1D)\n\n              This contains the 6 estimated motion parameters across all runs.\n              These parameters are generally used as regressors of no interest,\n              hopefully per run.  They are also used to generate the enorm time\n              series, which is then used for censoring.\n\n           files_ACF\n\n              This directory contains ACF values at different radii per run.\n              One can plot them using something like:\n\n                set af = files_ACF/out.3dFWHMx.ACF.errts.r01.1D\n                1dplot -one -x $af'[0]' $af'[1,2,3]'\n\n        *  final_epi_vr_base\n\n              This dataset is of the EPI volume registration base (used by\n              3dvolreg), warped to the final space.  It should be in alignment\n              with the anat_final dataset (and the template).\n\n           fitts.$subj\n\n              This dataset contains the model fit to the time series data.\n              One can view these time series together in afni using the\n              Dataset #N plugin.\n\n           full_mask.$subj\n\n              This dataset is a brain mask based on the EPI data, generated\n              by 3dAutomask.  Though the default is to apply it as part of the\n              main regression, it is used for computations like ACF and TSNR.\n\n           ideal_*.1D\n\n              These time series text files are the ideal regressors of\n              interest, if appropriate to calculate.\n\n           mat.basewarp.aff12.1D\n\n              This is used to create the final_epi_vr_base dataset.\n\n              Assuming no non-linear registration (including distortion\n              correction), then this matrix holds the combined affine\n              transformation of the EPI to anat and to standard space,\n              as applied to the volume registration base (it does not contain\n              motion correction transformations).\n\n              Time series registration matrices that include motion correction\n              are in mat.r*.warp.aff12.1D (i.e. one file per run).\n\n              In the case of non-linear registration, there is no single file\n              representing the combined transformation, as it is computed just\n              to apply the transformation by 3dNwarpApply.  This command can be\n              found in the proc script or as the last HISTORY entry seen from\n              the output of \"3dinfo final_epi_vr_base\".\n\n        *  motion_${subj}_enorm.1D\n\n              This time series text file is the L2 (Euclidean) norm of the\n              first (backward) differences of the motion parameters.  The\n              values represent time point to time point estimated motion, and\n              they are used for censoring.  Values are zero at the beginning of\n              each run (motion is not computed across runs).\n\n              A high average of these numbers, particularly after the numbers\n              themselves are censored, is justification for dropping a subject.\n              This average is reported by the @ss_review scripts.\n\n           motion_${subj}_censor.1D\n\n              This is a binary 0/1 time series (matching enorm, say), that\n              distinguishes time points which would be censored (0) from those\n              which would not (1).  It is based on the enorm time series and\n              the -regress_censor_motion limit, with a default to censor in\n              pairs of time points.  There may be a combined censor file, if\n              outlier censoring is done (or if a user censor file is input).\n\n           motion_demean.1D\n\n              This is the same as dfile_rall.1D, the motion parameters as\n              estimated by 3dvolreg, except the the mean per run has been\n              removed.\n\n           motion_deriv.1D\n\n              This contains the first (backward) differences from either\n              motion_demean.1D or dfile_rall.1D.  Values are zero at the start\n              of each run.\n\n           out.allcostX.txt\n\n              This holds anat/EPI registration costs for all cost functions.\n              It might be informational to evaluate alignment across subjects\n              and cost functions.\n\n        *  out.cormat_warn.txt\n\n              This contains warnings about a high correlation between any pair\n              of regressors in the main regression matrix, including baseline\n              terms.\n\n        *  out.gcor.1D\n\n              This contains the global correlation, the average correlation\n              between every pair of voxels in the residual time series dataset.\n              This single value is reported by the @ss_review scripts.\n\n           out.mask_ae_dice.txt\n\n              This contains the Dice coefficient, evaluating the overlap\n              between the anatomical and EPI brain masks.\n\n           out.mask_ae_overlap.txt\n\n              This contains general output from 3dOverlap, for evaluating the\n              overlap between the anatomical and EPI brain masks.\n\n        *  out.pre_ss_warn.txt\n\n              This contains warnings about time point #0 in any run where it\n              might be a pre-steady state time point, based on outliers.\n\n        *  out.ss_review.txt\n\n              This is the text output from @ss_review_basic.  Aside from being\n              shown by the @ss_review scripts, it is useful for being compiled\n              across subjects via gen_ss_review_table.py.\n\n        *  outcount_rall.1D (and outcount.r??.1D)\n\n              This is a time series of the fraction of the brain that is an\n              outlier.  It can be used for censoring.\n\n        *  sum_ideal.1D\n\n              As suggested, this time series is the sum of all non-baseline\n              regressors.  It is generated from X.nocensor.xmat.1D if censoring\n              is done, and from X.xmat.1D otherwise.  This might help one find\n              mistakes in stimulus timing, for example.\n\n        *  TSNR_$subj\n\n              This AFNI dataset contains the voxelwise TSNR after regression.\n              The brainwise average is shown in @ss_review_basic.\n\n          X.xmat.1D\n\n              This is the complete regression matrix, created by 3dDeconvolve.\n              One can view it using 1dplot.  It contains all regressors except\n              for any voxelwise ones (e.g. for ANATICOR).\n\n          X.nocensor.xmat.1D\n\n              This is the same as X.xmat.1D, except the nothing is censored,\n              so all time points are present.\n\n        * X.stim.xmat.1D\n\n              This (text) file has the non-baseline regressors (so presumably\n              of interest), created by 3dDeconvolve.\n\n    --------------------------------------------------\n    RESTING STATE NOTE: ~2~\n\n    Resting state data should be processed with physio recordings (for typical\n    single-echo EPI data).  Without such recordings, bandpassing is currently\n    considered as the default.\n\n    Comment on bandpassing:\n\n        Bandpassing is the norm right now.  However most TRs may be too long\n        for this process to be able to remove the desired components of no\n        interest.  On the flip side, if the TRs are short, the vast majority\n        of the degrees of freedom are sacrificed just to do it.  Perhaps\n        bandpassing will eventually go away, but it is the norm right now.\n\n        Also, there is a danger with bandpassing and censoring in that subjects\n        with a lot of motion may run out of degrees of freedom (for baseline,\n        censoring, bandpassing and removal of other signals of no interest).\n        Many papers have been published where a lot of censoring was done,\n        many regressors of no interest were projected out, and there was a\n        separate bandpass operation.  It is likely that many subjects ended up\n        with negative degrees of freedom, making the resulting signals useless\n        (or worse, misleading garbage).  But without keeping track of it,\n        researchers may not even know.\n\n    Bandpassing and degrees of freedom:\n\n        Bandpassing between 0.01 and 0.1 means, from just the lowpass side,\n        throwing away frequencies above 0.1.  So the higher the frequency of\n        collected data (i.e. the smaller the TR), the higher the fraction of\n        DoF will be thrown away.\n\n        For example, if TR = 2s, then the Nyquist frequency (the highest\n        frequency detectable in the data) is 1/(2*2) = 0.25 Hz.  That is to\n        say, one could only detect something going up and down at a cycle rate\n        of once every 4 seconds (twice the TR).\n\n        So for TR = 2s, approximately 40% of the DoF are kept (0.1/0.25) and\n        60% are lost (frequencies from 0.1 to 0.25) due to bandpassing.\n\n        To generalize, Nyquist = 1/(2*TR), so the fraction of DoF kept is\n\n            fraction kept = 0.1/Nyquist = 0.1/(1/(2*TR)) = 0.1*2*TR = 0.2*TR\n\n        For example,\n\n            at TR = 2 s,   0.4  of DoF are kept (60% are lost)\n            at TR = 1 s,   0.2  of DoF are kept (80% are lost)\n            at TR = 0.5 s, 0.1  of DoF are kept (90% are lost)\n            at TR = 0.1 s, 0.02 of DoF are kept (98% are lost)\n\n        Consider also:\n\n            Shirer WR, Jiang H, Price CM, Ng B, Greicius MD\n            Optimization of rs-fMRI pre-processing for enhanced signal-noise\n                separation, test-retest reliability, and group discrimination\n            Neuroimage. 2015 Aug 15;117:67-79.\n\n            Gohel SR, Biswal BB\n            Functional integration between brain regions at rest occurs in\n                multiple-frequency bands\n            Brain connectivity. 2015 Feb 1;5(1):23-34.\n\n            Caballero-Gaudes C, Reynolds RC\n            Methods for cleaning the BOLD fMRI signal\n            Neuroimage. 2017 Jul 1;154:128-49\n\n    Application of bandpassing in afni_proc.py:\n\n        In afni_proc.py, this is all done in a single regression model (removal\n        of noise and baseline signals, bandpassing and censoring).  If some\n        subject were to lose too many TRs due to censoring, this step would\n        fail, as it should.\n\n        There is an additional option of using simulated motion time series\n        in the regression model, which should be more effective than higher\n        order motion parameters, say.  This is done via @simulate_motion.\n\n    There are 3 main steps (generate ricor regs, pre-process, group analysis):\n\n        step 0: If physio recordings were made, generate slice-based regressors\n                using RetroTS.py.  Such regressors can be used by afni_proc.py\n                via the 'ricor' processing block.\n\n                RetroTS.m is Ziad Saad's MATLAB routine to convert the 2 time\n                series into 13 slice-based regressors.  RetroTS.m requires the\n                signal processing toolkit for MATLAB.\n\n                RetroTS.py is a conversion of RetroTS.m to python by J Zosky,\n                which depends on scipy.  See \"RetroTS.py -help\" for details.\n\n        step 1: analyze with afni_proc.py\n\n                Consider these afni_proc.py -help examples:\n                   5b.  case of ricor and no bandpassing\n                   5c.  ricor and bandpassing and full registration\n                   9.   no ricor, but with bandpassing\n                   9b.  with WMeLocal (local white-matter, eroded) - ANATICOR\n                   10.  also with tissue-based regressors\n                   10b. apply bandpassing via 3dRSFC\n                   soon: extra motion regs via motion simulated time series\n                         (either locally or not)\n                   11.  censor, despike, non-linear registration,\n                        no bandpassing, fast ANATICOR regression,\n                        FreeSurfer masks for ventricle/WM regression\n                      * see \"FREESURFER NOTE\" for more details\n\n            processing blocks:\n\n                despike (shrink large spikes in time series)\n                ricor   (if applicable, remove the RetroTS regressors)\n                tshift  (correct for slice timing)\n                align   (figure out alignment between anat and EPI)\n                tlrc    (figure out alignment between anat and template)\n                volreg  (align anat and EPI together, and to standard template)\n                blur    (apply desired FWHM blur to EPI data)\n                scale   (optional, e.g. before seed averaging)\n                regress (polort, motion, mot deriv, bandpass, censor)\n                        (depending on chosen options)\n                        soon: ANATICOR/WMeLocal\n                              extra motion regressors (via motion simulation)\n\n                ==> \"result\" is errts dataset, \"cleaned\" of known noise sources\n\n        step 2: correlation analysis, hopefully with 3dGroupInCorr\n\n            The inputs to this stage are the single subject errts datasets.\n\n            Ignoring 3dGroupInCorr, the basic steps in a correlation analysis\n            (and corresponding programs) are as follows.  This may be helpful\n            for understanding the process, even when using 3dGroupInCorr.\n\n                a. choose a seed voxel (or many) and maybe a seed radius\n\n                for each subject:\n\n                   b. compute time series from seed\n                      (3dmaskave or 3dROIstats)\n                   c. generate correlation map from seed TS\n                      (3dTcorr1D (or 3dDeconvolve or 3dfim+))\n                   d. normalize R->\"Z-score\" via Fisher's z-transform\n                      (3dcalc -expr atanh)\n\n                e. perform group test, maybe with covariates\n                   (3dttest++: 1-sample, 2-sample or paired)\n\n            To play around with a single subject via InstaCorr:\n\n                a. start afni (maybe show images of both anat and EPI)\n                b. start InstaCorr plugin from menu at top right of afni's\n                   Define Overlay panel\n                c. Setup Icorr:\n                    c1. choose errts dataset\n                       (no Start,End; no Blur (already done in pre-processing))\n                    c2. Automask -> No; choose mask dataset: full_mask\n                    c3. turn off Bandpassing (already done, if desired)\n                d. in image window, show correlations\n                    d1. go to seed location, right-click, InstaCorr Set\n                    OR\n                    d1. hold ctrl-shift, hold left mouse button, drag\n                e. have endless fun\n\n            To use 3dGroupInCorr:\n\n                a. run 3dSetupGroupIncorr with mask, labels, subject datasets\n                   (run once per group of subjects), e.g.\n\n                        3dSetupGroupInCorr                \\\n                            -labels subj.ID.list.txt      \\\n                            -prefix sic.GROUP             \\\n                            -mask EPI_mask+tlrc           \\\n                            errts_subj1+tlrc              \\\n                            errts_subj2+tlrc              \\\n                            errts_subj3+tlrc              \\\n                                ...                       \\\n                            errts_subjN+tlrc\n\n                    ==> sic.GROUP.grpincorr.niml (and .grpincorr.data)\n\n                b. run 3dGroupInCorr on 1 or 2 sic.GROUP datasets, e.g.\n\n                   Here are steps for running 3dGroupInCorr via the afni GUI.\n                   To deal with computers that have multiple users, consider\n                   specifying some NIML port block that others are not using.\n                   Here we use port 2 (-npb 2), just to choose one.\n\n                   b1. start afni:\n\n                        afni -niml -npb 2\n\n                   b2. start 3dGroupInCorr\n\n                        3dGroupInCorr -npb 2                    \\\n                            -setA sic.horses.grpincorr.niml     \\\n                            -setB sic.moths.grpincorr.niml      \\\n                            -labelA horses -labelB moths        \\\n                            -covaries my.covariates.txt         \\\n                            -center SAME -donocov -seedrad 5\n\n                   b3. play with right-click -> InstaCorr Set or\n                      hold ctrl-shift/hold left mouse and drag slowly\n\n                   b4. maybe save any useful dataset via\n                      Define Datamode -> SaveAs OLay (and give a useful name)\n\n                b'. alternative, generate result dataset in batch mode, by\n                    adding -batch and some parameters to the 3dGIC command\n\n                    e.g.  -batch XYZAVE GIC.HvsM.PFC 4 55 26\n\n                    In such a case, afni is not needed at all.  The resulting\n                    GIC.HvsM.PFC+tlrc dataset would be written out without any\n                    need to start the afni GUI.  This works well since seed\n                    coordinates for group tests are generally known in advance.\n\n                    See the -batch option under \"3dGroupInCorr -help\" for many\n                    details and options.\n\n                c. threshold/clusterize resulting datasets, just as with a\n                   task analysis\n\n                   (afni GUI, 3dclust, or 3dmerge)\n\n    --------------------------------------------------\n    FREESURFER NOTE: ~2~\n\n    FreeSurfer output can be used for a few things in afni_proc.py:\n\n        - simple skull stripping (i.e. instead of 3dSkullStrip)\n        - running a surface-based analysis\n        - using parcellation datasets for:\n           - tissue-based regression\n           - creating group probability maps\n           - creating group atlases (e.g. maximum probability maps)\n\n    This NOTE mainly refers to using FreeSurfer parcellations for tissue-based\n    regression, as is done in Example 11.\n\n\n    First run FreeSurfer, then import to AFNI using @SUMA_Make_Spec_FS, then\n    make ventricle and white matter masks from the Desikan-Killiany atlas based\n    parcellation dataset, aparc+aseg.nii.\n\n    Note that the aparc.a2009s segmentations are based on the Destrieux atlas,\n    which might be nicer for probability maps, though the Desikan-Killiany\n    aparc+aseg segmentation is currently used for segmenting white matter and\n    ventricles.  I have not studied the differences.\n\n\n    Example 11 brings the aparc.a2009s+aseg segmentation along (for viewing or\n    atlas purposes, aligned with the result), though the white matter and\n    ventricle masks are based instead on aparc+aseg.nii.\n\n        # run (complete) FreeSurfer on FT.nii\n        recon-all -all -subject FT -i FT.nii\n\n        # import to AFNI, in NIFTI format\n        @SUMA_Make_Spec_FS -sid FT -NIFTI\n\n        # create ventricle and white matter masks\n        #\n        # ** warning: it would be good to convert these indices to labels\n        #             in case the output from FreeSurfer is changed\n\n        3dcalc -a aparc+aseg.nii -datum byte -prefix FT_vent.nii \\", "help_range": [62930, 84488]}, {"param": "-e", "line_start": 1648, "length": 2, "param_range": [84504, 84506], "help": "               -expr 'amongst(a,4,43)'\n        3dcalc -a aparc+aseg.nii -datum byte -prefix FT_WM.nii \\", "help_range": [84489, 84592]}, {"param": "-e", "line_start": 1650, "length": 354, "param_range": [84608, 84610], "help": "               -expr 'amongst(a,2,7,41,46,251,252,253,254,255)'\n\n        # note: 16 (brainstem) was incorrectly included from @ANATICOR\n        #       and then in this help through 2016\n\n    After this, FT_SurfVol.nii, FT_vent.nii and FT_WM.nii (along with the\n    basically unused aparc.a2009s+aseg.nii) are passed to afni_proc.py.\n\n\n  * Be aware that the output from FreeSurfer (e.g. FT_SurfVol.nii) will\n    usually not quite align with the input (e.g. FT.nii).  So parcellation\n    datasets will also not quite align with the input (FT.nii).  Therefore,\n    when passing parcellation volumes to afni_proc.py for tissue-based\n    regression, it is important to use the anatomy output from FreeSurfer\n    as the subject anatomy (input to afni_proc.py).  That way, the anatomy\n    and parcellation datasets will be in register, and therefore the EPI\n    will eventually align with the parcellation datasets.\n\n    If it is important to have the FreeSurfer output align with the input,\n    it might help to pass a modified volume to FreeSurfer.  Use 3dresample\n    and then 3dZeropad (if necessary) to make a volume with 1 mm^3 voxels\n    and an even number voxels in each direction.  The @SUMA_Make_Spec_FS\n    help provides some details on this.\n\n    The exact 3dZeropad command depends on the grid output by 3dresample.\n\n        3dresample -inset FT_anat+orig -dxyz 1 1 1 -prefix FT.1 -rmode Cu\n        3dZeropad -L 1 -prefix FT.1.z.nii FT.1+orig\n        recon-all -all -subject FT -i FT.1.z.nii\n        @SUMA_Make_Spec_FS -sid FT -NIFTI\n\n    --------------------------------------------------\n    TIMING FILE NOTE: ~2~\n\n    One issue that the user must be sure of is the timing of the stimulus\n    files (whether -regress_stim_files or -regress_stim_times is used).\n\n    The 'tcat' step will remove the number of pre-steady-state TRs that the\n    user specifies (defaulting to 0).  The stimulus files, provided by the\n    user, must match datasets that have had such TRs removed (i.e. the stim\n    files should start _after_ steady state has been reached).\n\n    --------------------------------------------------\n    MASKING NOTE: ~2~\n\n    The default operation of afni_proc.py has changed (as of 24 Mar, 2009).\n    Prior to that date, the default was to apply the 'epi' mask.  As of\n    17 Jun 2009, only the 'extents' mask is, if appropriate.\n\n    ---\n\n    There may be 4 masks created by default, 3 for user evaluation and all for\n    possible application to the EPI data (though it may not be recommended).\n    The 4th mask (extents) is a special one that will be applied at volreg when\n    appropriate, unless the user specifies otherwise.\n\n    If the user chooses to apply one of the masks to the EPI regression (again,\n    not necessarily recommended), it is done via the option -mask_apply while\n    providing the given mask type (epi, anat, group or extents).\n\n    --> To apply a mask during regression, use -mask_apply.\n\n    Mask descriptions (afni_proc.py name, dataset name, short description):\n\n    1. epi (\"full_mask\") : EPI Automask\n\n       An EPI mask dataset will be created by running '3dAutomask -dilate 1'\n       on the EPI data after blurring.  The 3dAutomask command is executed per\n       run, after which the masks are combined via a union operation.\n\n    2. anat (\"mask_anat.$subj\") : anatomical skull-stripped mask\n\n       If possible, a subject anatomy mask will be created.  This anatomical\n       mask will be created from the appropriate skull-stripped anatomy,\n       resampled to match the EPI (that is output by 3dvolreg) and changed into\n       a binary mask.\n\n       This requires either the 'align' block or a tlrc anatomy (from the\n       'tlrc' block, or just copied via '-copy_anat').  Basically, it requires\n       afni_proc.py to know of a skull-stripped anatomical dataset.\n\n       By default, if both the anat and EPI masks exist, the overlap between\n       them will be computed for evaluation.\n\n    3. group (\"mask_group\") : skull-stripped @auto_tlrc base\n\n       If possible, a group mask will be created.  This requires the 'tlrc'\n       block, from which the @auto_tlrc -base dataset is chosen as the group\n       anatomy.  It also requires '-volreg_warp_epi' so that the EPI is in\n       standard space.  The group anatomy is then resampled to match the EPI\n       and changed into a binary mask.\n\n    4. extents (\"mask_extents\") : mask based on warped EPI extents\n\n       In the case of transforming the EPI volumes to match the anatomical\n       volume (via either -volreg_align_e2a or -volreg_tlrc_warp), an extents\n       mask will be created.  This is to avoid a motion artifact that arises\n       when transforming from a smaller volume (EPI) to a larger one (anat).\n\n    ** Danger Will Robinson! **\n\n       This EPI extents mask is considered necessary because the align/warp\n       transformation that is applied on top of the volreg alignment transform\n       (applied at once), meaning the transformation from the EPI grid to the\n       anatomy grid will vary per TR.\n\n       The effect of this is seen at the edge voxels (extent edge), where a\n       time series could be zero for many of the TRs, but have valid data for\n       the rest of them.  If this timing just happens to correlate with any\n       regressor, the result could be a strong \"activation\" for that regressor,\n       but which would be just a motion based artifact.\n\n       What makes this particularly bad is that if it does happen, it tends to\n       happen for *a cluster* of many voxels at once, possibly an entire slice.\n       Such an effect is compounded by any additional blur.  The result can be\n       an entire cluster of false activation, large enough to survive multiple\n       comparison corrections.\n\n       Thanks to Laura Thomas and Brian Bones for finding this artifact.\n\n   --> To deal with this, a time series of all 1s is created on the original\n       EPI grid space.  Then for each run it is warped with to the same list of\n       transformations that is applied to the EPI data in the volreg step\n       (volreg xform and either alignment to anat or warp to standard space).\n       The result is a time series of extents of each original volume within\n       the new grid.\n\n       These volumes are then intersected over all TRs of all runs.  The final\n       mask is the set of voxels that have valid data at every TR of every run.\n       Yay.\n\n    5. Classes and Classes_resam: GM, WM, CSF class masks from 3dSeg\n\n       By default, unless the user requests otherwise (-mask_segment_anat no),\n       and if anat_final is skull-stripped, then 3dSeg will be used to segment\n       the anatomy into gray matter, white matter and CSF classes.\n\n       A dataset named Classes is the result of running 3dSeg, which is then\n       resampled to match the EPI and named Classes_resam.\n\n       If the user wanted to, this dataset could be used for regression of\n       said tissue classes (or eroded versions).\n\n\n    --- masking, continued...\n\n    Note that it may still not be a good idea to apply any of the masks to the\n    regression, as it might then be necessary to intersect such masks across\n    all subjects, though applying the 'group' mask might be reasonable.\n\n ** Why has the default been changed?\n\n    It seems much better not to mask the regression data in the single-subject\n    analysis at all, send _all_ of the results to group space, and apply an\n    anatomically-based mask there.  That could be computed from the @auto_tlrc\n    reference dataset or from the union of skull-stripped subject anatomies.\n\n    Since subjects have varying degrees of signal dropout in valid brain areas\n    of the EPI data, the resulting EPI intersection mask that would be required\n    in group space may exclude edge regions that are otherwise desirable.\n\n    Also, it is helpful to see if much 'activation' appears outside the brain.\n    This could be due to scanner or interpolation artifacts, and is useful to\n    note, rather than to simply mask out and never see.\n\n    Rather than letting 3dAutomask decide which brain areas should not be\n    considered valid, create a mask based on the anatomy _after_ the results\n    have been warped to a standard group space.  Then perhaps dilate the mask\n    by one voxel.  Example #11 from '3dcalc -help' shows how one might dilate.\n\n ** Note that the EPI data can now be warped to standard space at the volreg\n    step.  In that case, it might be appropriate to mask the EPI data based\n    on the Talairach template, such as what is used for -base in @auto_tlrc.\n    This can be done via '-mask_apply group'.\n\n    ---\n\n ** For those who have processed some of their data with the older method:\n\n    Note that this change should not be harmful to those who have processed\n    data with older versions of afni_proc.py, as it only adds non-zero voxel\n    values to the output datasets.  If some subjects were analyzed with the\n    older version, the processing steps should not need to change.  It is still\n    necessary to apply an intersection mask across subjects in group space.\n\n    It might be okay to create the intersection mask from only those subjects\n    which were masked in the regression, however one might say that biases the\n    voxel choices toward those subjects, though maybe that does not matter.\n    Any voxels used would still be across all subjects.\n\n    ---\n\n    A mask dataset is necessary when computing blur estimates from the epi and\n    errts datasets.  Also, since it is nice to simply see what the mask looks\n    like, its creation has been left in by default.\n\n    The '-regress_no_mask' option is now unnecessary.\n\n    ---\n\n    Note that if no mask were applied in the 'scaling' step, large percent\n    changes could result.  Because large values would be a detriment to the\n    numerical resolution of the scaled short data, the default is to truncate\n    scaled values at 200 (percent), which should not occur in the brain.\n\n    --------------------------------------------------\n    BLIP NOTE: ~2~\n\n    application of reverse-blip (blip-up/blip-down) registration:\n\n       o compute the median of the forward and reverse-blip data\n       o align them using 3dQwarp -plusminus\n          -> the main output warp is the square root of the forward warp\n             to the reverse, i.e. it warps the forward data halfway\n          -> in theory, this warp should make the EPI anatomically accurate\n\n    order of operations:\n\n       o the blip warp is computed after all initial temporal operations\n         (despike, ricor, tshift)\n       o and before all spatial operations (anat/EPI align, tlrc, volreg)\n\n    notes:\n\n       o If no forward blip time series (volume?) is provided by the user,\n         the first time points from the first run will be used (using the\n         same number of time points as in the reverse blip time series).\n       o As usual, all registration transformations are combined.\n\n    differences with unWarpEPI.py (R Cox, D Glen and V Roopchansingh):\n\n                        afni_proc.py            unWarpEPI.py\n                        --------------------    --------------------\n       tshift step:     before unwarp           after unwarp\n                        (option: after unwarp)\n\n       volreg program:  3dvolreg                3dAllineate\n\n       volreg base:     as before               median warped dset\n                        (option: MEDIAN_BLIP)   (same as MEDIAN_BLIP)\n\n       unifize EPI?     no (option: yes)        yes\n       (align w/anat)\n\n    --------------------------------------------------\n    ANAT/EPI ALIGNMENT CASES NOTE: ~2~\n\n    This outlines the effects of alignment options, to help decide what options\n    seem appropriate for various cases.\n\n    1. EPI to EPI alignment (the volreg block)\n\n        Alignment of the EPI data to a single volume is based on the 3 options\n        -volreg_align_to, -volreg_base_dset and -volreg_base_ind, where the\n        first option is by far the most commonly used.\n\n        Note that a good alternative is: '-volreg_align_to MIN_OUTLIER'.\n\n        The logic of EPI alignment in afni_proc.py is:\n\n            a. if -volreg_base_dset is given, align to that\n               (this volume is copied locally as the dataset ext_align_epi)\n            b. otherwise, use the -volreg_align_to or -volreg_base_ind volume\n\n        The typical case is to align the EPI to one of the volumes used in\n        pre-processing (where the dataset is provided by -dsets and where the\n        particular TR is not removed by -tcat_remove_first_trs).  If the base\n        volume is the first or third (TR 0 or 2) from the first run, or is the\n        last TR of the last run, then -volreg_align_to can be used.\n\n        To specify a TR that is not one of the 3 just stated (first, third or\n        last), -volreg_base_ind can be used.\n\n        To specify a volume that is NOT one of those used in pre-processing\n        (such as the first pre-steady state volume, which would be excluded by\n        the option -tcat_remove_first_trs), use -volreg_base_dset.\n\n    2. anat to EPI alignment cases (the align block)\n\n        This is specific to the 'align' processing block, where the anatomy is\n        aligned to the EPI.  The focus is on which EPI volume the anat gets\n        aligned to.  Whether this transformation is inverted in the volreg\n        block (to instead align the EPI to the anat via -volreg_align_e2a) is\n        an independent consideration.\n\n        The logic of which volume the anatomy gets aligned to is as follows:\n            a. if -align_epi_ext_dset is given, use that for anat alignment\n            b. otherwise, if -volreg_base_dset, use that\n            c. otherwise, use the EPI base from the EPI alignment choice\n\n        To restate this: the anatomy gets aligned to the same volume the EPI\n        gets aligned to *unless* -align_epi_ext_dset is given, in which case\n        that volume is used.\n\n        The entire purpose of -align_epi_ext_dset is for the case where the\n        user might want to align the anat to a different volume than what is\n        used for the EPI (e.g. align anat to a pre-steady state TR but the EPI\n        to a steady state one).\n\n        Output:\n\n           The result of the align block is an 'anat_al' dataset.  This will be\n           in alignment with the EPI base (or -align_epi_ext_dset).\n\n           In the default case of anat -> EPI alignment, the aligned anatomy\n           is actually useful going forward, and is so named 'anat_al_keep'.\n\n           Additionally, if the -volreg_align_e2a option is used (thus aligning\n           the EPI to the original anat), then the aligned anat dataset is no\n           longer very useful, and is so named 'anat_al_junk'.  However, unless\n           an anat+tlrc dataset was copied in for use in -volreg_tlrc_adwarp,\n           the skull-striped anat (anat_ss) becomes the current one going\n           forward.  That is identical to the original anat, except that it\n           went through the skull-stripping step in align_epi_anat.py.\n\n           At that point (e2a case) the pb*.volreg.* datasets are aligned with\n           the original anat or the skull-stripped original anat (and possibly\n           in Talairach space, if the -volreg_tlrc_warp or _adwarp option was\n           applied).\n\n         Checking the results:\n\n           The pb*.volreg.* volumes should be aligned with the anat.  If\n           -volreg_align_e2a was used, it will be with the original anat.\n           If not, then it will be with anat_al_keep.\n\n           Note that at the end of the regress block, whichever anatomical\n           dataset is deemed \"in alignment\" with the stats dataset will be\n           copied to anat_final.$subj.\n\n           So compare the volreg EPI with the final anatomical dataset.\n\n    --------------------------------------------------\n    ANAT/EPI ALIGNMENT CORRECTIONS NOTE: ~2~\n\n    Aligning the anatomy and EPI is sometimes difficult, particularly depending\n    on the contrast of the EPI data (between tissue types).  If the alignment\n    fails to do a good job, it may be necessary to run align_epi_anat.py in a\n    separate location, find options that help it to succeed, and then apply\n    those options to re-process the data with afni_proc.py.\n\n    1. If the anat and EPI base do not start off fairly close in alignment,\n       the -giant_move option may be needed for align_epi_anat.py.  Pass this\n       option to AEA.py via the afni_proc.py option -align_opts_aea:\n\n            afni_proc.py ... -align_opts_aea -giant_move\n\n    2. The default cost function used by align_epi_anat.py is lpc (local\n       Pearson correlation).  If this cost function does not work (probably due\n       to poor or unusual EPI contrast), then consider cost functions such as\n       lpa (absolute lpc), lpc+ (lpc plus fractions of other cost functions) or\n       lpc+ZZ (approximate with lpc+, but finish with pure lpc).\n\n       The lpa and lpc+ZZ cost functions are common alternatives.  The", "help_range": [84593, 101607]}, {"param": "-giant_move", "line_start": 2004, "length": 4, "param_range": [101615, 101626], "help": "       -giant_move option may be necessary independently.\n\n       Examples of some helpful options:", "help_range": [101608, 101707]}, {"param": "-align_opts_aea", "line_start": 2008, "length": 1, "param_range": [101718, 101733], "help": "         -align_opts_aea -cost lpa", "help_range": [101709, 101743]}, {"param": "-align_opts_aea", "line_start": 2009, "length": 1, "param_range": [101753, 101768], "help": "         -align_opts_aea -giant_move", "help_range": [101744, 101780]}, {"param": "-align_opts_aea", "line_start": 2010, "length": 1, "param_range": [101790, 101805], "help": "         -align_opts_aea -cost lpc+ZZ -giant_move", "help_range": [101781, 101830]}, {"param": "-align_opts_aea", "line_start": 2011, "length": 1, "param_range": [101840, 101855], "help": "         -align_opts_aea -check_flip", "help_range": [101831, 101867]}, {"param": "-align_opts_aea", "line_start": 2012, "length": 1, "param_range": [101877, 101892], "help": "         -align_opts_aea -cost lpc+ZZ -giant_move -resample off", "help_range": [101868, 101931]}, {"param": "-align_opts_aea", "line_start": 2013, "length": 16, "param_range": [101941, 101956], "help": "         -align_opts_aea -skullstrip_opts -blur_fwhm 2\n\n    3. Testing alignment with align_epi_anat.py directly.\n\n       When having alignment problems, it may be more efficient to copy the\n       anat and EPI alignment base to a new directory, figure out a good cost\n       function or other options, and then apply them in a new afni_proc.py\n       command.\n\n       For testing purposes, it helps to test many cost functions at once.\n       Besides the cost specified by -cost, other cost functions can be applied\n       via -multi_cost.  This is efficient, since all of the other processing\n       does not need to be repeated.  For example:\n\n         align_epi_anat.py -anat2epi                    \\\n                -anat subj99_anat+orig                  \\", "help_range": [101932, 102694]}, {"param": "-e", "line_start": 2029, "length": 1, "param_range": [102711, 102713], "help": "                -epi pb01.subj99.r01.tshift+orig        \\", "help_range": [102695, 102752]}, {"param": "-e", "line_start": 2030, "length": 1, "param_range": [102769, 102771], "help": "                -epi_base 0 -volreg off -tshift off     \\", "help_range": [102753, 102810]}, {"param": "-giant_move", "line_start": 2031, "length": 129, "param_range": [102827, 102838], "help": "                -giant_move                             \\\n                -cost lpc -multi_cost lpa lpc+ZZ mi\n\n       That adds -giant_move, and uses the basic lpc cost function along with\n       3 additional cost functions (lpa, lpc+ZZ, mi).  The result is 4 new\n       anatomies aligned to the EPI, 1 per cost function:\n\n               subj99_anat_al+orig         - cost func lpc      (see -cost opt)\n               subj99_anat_al_lpa+orig     - cost func lpa         (additional)\n               subj99_anat_al_lpc+ZZ+orig  - cost func lpc+ZZ      (additional)\n               subj99_anat_al_mi+orig      - cost func mi          (additional)\n\n       Also, if part of the dataset gets clipped in the case of -giant_move,\n       consider the align_epi_anat.py option '-resample off'.\n\n    --------------------------------------------------\n    WARP TO TLRC NOTE: ~2~\n\n    afni_proc.py can now apply a +tlrc transformation to the EPI data as part\n    of the volreg step via the option '-volreg_tlrc_warp'.  Note that it can\n    also align the EPI and anatomy at the volreg step via '-volreg_align_e2a'.\n\n    Manual Talairach transformations can also be applied, but separately, after\n    volreg.  See '-volreg_tlrc_adwarp'.\n\n    This tlrc transformation is recommended for many reasons, though some are\n    not yet implemented.  Advantages include:\n\n        - single interpolation of the EPI data\n\n            Done separately, volume registration, EPI to anat alignment and/or\n            the +tlrc transformation interpolate the EPI data 2 or 3 times.  By\n            combining these transformations into a single one, there is no\n            resampling penalty for the alignment or the warp to standard space.\n\n            Thanks to D Glen for the steps used in align_epi_anat.py.\n\n        - EPI time series become directly comparable across subjects\n\n            Since the volreg output is now in standard space, there is already\n            voxel correspondence across subjects with the EPI data.\n\n        - group masks and/or atlases can be applied to the EPI data without\n          additional warping\n\n            It becomes trivial to extract average time series data over ROIs\n            from standard atlases, say.\n\n            This could even be done automatically with afni_proc.py, as part\n            of the single-subject processing stream (not yet implemented).\n            One would have afni_proc.py extract average time series (or maybe\n            principal components) from all the ROIs in a dataset and apply\n            them as regressors of interest or of no interest.\n\n        - with 3dBlurToFWHM, using an AlphaSim look-up table might be possible\n\n            Since the blur and data grid could both be isotropic and integral,\n            and since the transformation could depend on a known anatomy (such\n            as the N27 Colin brain or icbm_452), it would be easy to create a\n            look-up table of AlphaSim results (so users would not actually need\n            to run it).\n\n            The known numbers would correspond to a cluster size (each for a\n            given, common voxel-wise threshold).  This correction could then\n            be applied automatically.  Again, not yet implemented...\n\n        - no interpolation of statistics\n\n            If the user wishes to include statistics as part of the group\n            analysis (e.g. using 3dMEMA.R), this warping becomes more needed.\n            Warping to standard space *after* statistics are generated is not\n            terribly valid.\n\n    --------------------------------------------------\n    RETROICOR NOTE: ~2~\n\n    ** Cardiac and respiratory regressors must be created from an external\n       source, such as the RetroTS.m matlab program written by Z Saad.  The\n       input to that would be the 2+ signals.  The output would be a single\n       file per run, containing 13 or more regressors for each slice.  That\n       set of output files would be applied here in afni_proc.py.\n\n    Removal of cardiac and respiratory regressors can be done using the 'ricor'\n    processing block.  By default, this would be done after 'despike', but\n    before any other processing block.\n\n    These card/resp signals would be regressed out of the MRI data in the\n    'ricor' block, after which processing would continue normally. In the final\n    'regress' block, regressors for slice 0 would be applied (to correctly\n    account for the degrees of freedom and also to remove residual effects).\n        --> This is now only true when using '-regress_apply_ricor yes'.\n            The default as of 30 Jan 2012 is to not include them in the final\n            regression (since degrees of freedom are really not important for a\n            subsequent correlation analysis).\n\n    Users have the option of removing the signal \"per-run\" or \"across-runs\".\n\n    Example R1: 7 runs of data, 13 card/resp regressors, process \"per-run\"\n\n        Since the 13 regressors are processed per run, the regressors can have\n        different magnitudes each run.  So the 'regress' block will actually\n        get 91 extra regressors (13 regressors times 7 runs each).\n\n    Example R2: process \"across-run\"\n\n        In this case the regressors are catenated across runs when they are\n        removed from the data.  The major difference between this and \"per-run\"\n        is that now only 1 best fit magnitude is applied per regressor (not the\n        best for each run).  So there would be only the 13 catenated regressors\n        for slice 0 added to the 'regress' block.\n\n    Those analyzing resting-state data might prefer the per-run method, as it\n    would remove more variance and degrees of freedom might not be as valuable.\n\n    Those analyzing a normal signal model might prefer doing it across-runs,\n    giving up only 13 degrees of freedom, and helping not to over-model the\n    data.\n\n    ** The minimum options would be specifying the 'ricor' block (preferably\n       after despike), along with -ricor_regs and -ricor_regress_method.\n\n    Example R3: afni_proc.py option usage:\n\n        Provide additional options to afni_proc.py to apply the despike and\n        ricor blocks (which will be the first 2 blocks by default), with each\n        regressor named 'slibase*.1D' going across all runs, and where the\n        first 3 TRs are removed from each run (matching -tcat_remove_first_trs,\n        most likely).", "help_range": [102811, 109209]}, {"param": "-do_block", "line_start": 2160, "length": 1, "param_range": [109223, 109232], "help": "            -do_block despike ricor", "help_range": [14177, 14212]}, {"param": "-ricor_regs", "line_start": 2161, "length": 2, "param_range": [109259, 109270], "help": "            -ricor_regs slibase*.1D\n            -ricor_regress_method across-runs", "help_range": [109247, 109328]}, {"param": "-ricor_regs", "line_start": 2163, "length": 125, "param_range": [109341, 109352], "help": "            -ricor_regs_nfirst 3\n\n    --------------------------------------------------\n    RUNS OF DIFFERENT LENGTHS NOTE: ~2~\n\n    In the case that the EPI datasets are not all of the same length, here\n    are some issues that may come up, listed by relevant option:\n\n        -volreg_align_to        OK, as of version 1.49.\n\n        -ricor_regress_method   OK, as of version 3.05.\n\n        -regress_polort         Probably no big deal.\n                                If this option is not used, then the degree of\n                                polynomial used for the baseline will come from\n                                the first run.  Only 1 polort may be applied.\n\n        -regress_est_blur_epits OK, as of version 1.49.\n\n     *  -regress_use_stim_files This may fail, as make_stim_times.py is not\n                                currently prepared to handle runs of different\n                                lengths.\n\n        -regress_censor_motion  OK, as of version 2.14\n\n     * probably will be fixed (please let me know of interest)\n\n    --------------------------------------------------\n    SCRIPT EXECUTION NOTE: ~2~\n\n    The suggested way to run the output processing SCRIPT is via...\n\n        a) if you use tcsh:    tcsh -xef SCRIPT |& tee output.SCRIPT\n\n        b) if you use bash:    tcsh -xef SCRIPT 2>&1 | tee output.SCRIPT\n\n        c) if you use tcsh and the script is executable, maybe use one of:\n\n                            ./SCRIPT |& tee output.SCRIPT\n                            ./SCRIPT 2>&1 | tee output.SCRIPT\n\n    Consider usage 'a' for example:  tcsh -xef SCRIPT |& tee output.SCRIPT\n\n    That command means to invoke a new tcsh with the -xef options (so that\n    commands echo to the screen before they are executed, exit the script\n    upon any error, do not process the ~/.cshrc file) and have it process the\n    SCRIPT file, piping all output to the 'tee' program, which will duplicate\n    output back to the screen, as well as to the given output file.\n\n    parsing the command: tcsh -xef SCRIPT |& tee output.SCRIPT\n\n        a. tcsh\n\n           The script itself is written in tcsh syntax and must be run that way.\n           It does not mean the user must use tcsh.  Note uses 'a' and 'b'.\n           There tcsh is specified by the user.  The usage in 'c' applies tcsh\n           implicitly, because the SCRIPT itself specifies tcsh at the top.\n\n        b. tcsh -xef\n\n           The -xef options are applied to tcsh and have the following effects:\n\n                x : echo commands to screen before executing them\n                e : exit (terminate) the processing on any errors\n                f : do not process user's ~/.cshrc file\n\n           The -x option is very useful so one see not just output from the\n           programs, but the actual commands that produce the output.  It\n           makes following the output much easier.\n\n           The -e option tells the shell to terminate on any error.  This is\n           useful for multiple reasons.  First, it allows the user to easily\n           see the failing command and error message.  Second, it would be\n           confusing and useless to have the script try to continue, without\n           all of the needed data.\n\n           The -f option tells the shell not to process the user's ~/.cshrc\n           (or ~/.tcshrc) file.  The main reason for including this is because\n           of the -x option.  If there were any errors in the user's ~/.cshrc\n           file and -x option were used, they would terminate the shell before\n           the script even started, probably leaving the user confused.\n\n        c. tcsh -xef SCRIPT\n\n           The T-shell is invoked as described above, executing the contents\n           of the specified text file (called 'SCRIPT', for example) as if the\n           user had typed the included commands in their terminal window.\n\n        d. |&\n\n           These symbols are for piping the output of one program to the input\n           of another.  Many people know how to do 'afni_proc.py -help | less'\n           (or maybe '| more').  This script will output a lot of text, and we\n           want to get a copy of that into a text file (see below).\n\n           Piping with '|' captures only stdout (standard output), and would\n           not capture errors and warnings that appear.  Piping with '|&'\n           captures both stdout and stderr (standard error).  The user may not\n           be able to tell any difference between those file streams on the\n           screen, but since programs write to both, we want to capture both.\n\n        e. tee output.SCRIPT\n\n           Where do we want to send this captured stdout and stderr text?  Send\n           it to the 'tee' program.  Like a plumber's tee, the 'tee' program\n           splits the data (not water) stream off into 2 directions.\n\n           Here, one direction that tee sends the output is back to the screen,\n           so the user can still see what is happening.\n\n           The other direction is to the user-specified text file.  In this\n           example it would be 'output.SCRIPT'.  With this use of 'tee', all\n           screen output will be duplicated in that text file.\n\n\n\n    ==================================================\n    OPTIONS:  ~2~\n\n        Informational options, general options, and block options.\n        Block options are ordered by block.\n\n        -----------------------------------------------------------------\n        Informational/terminal options  ~3~", "help_range": [109329, 114824]}, {"param": "-help", "line_start": 2288, "length": 1, "param_range": [114834, 114839], "help": "show this help", "help_range": [114860, 114874]}, {"param": "-hist", "line_start": 2289, "length": 2, "param_range": [114883, 114888], "help": "show the module history", "help_range": [114909, 114932]}, {"param": "-requires_afni_version", "line_start": 2291, "length": 23, "param_range": [114942, 114964], "help": "show AFNI date required by processing script\n\n            Many updates to afni_proc.py are accompanied by corresponding\n            updates to other AFNI programs.  So if the processing script is\n            created on one computer but executed on another (with an older\n            version of AFNI), confusing failures could result.\n\n            The required date is adjusted whenever updates are made that rely\n            on new features of some other program.  If the processing script\n            checks the AFNI version, the AFNI package must be as current as the\n            date output via this option.  Checks are controlled by the option\n            '-check_afni_version'.\n\n            The checking method compares the output of:\n                afni_proc.py -requires_afni_version\n\n            against the most recent date in afni_history:\n                afni_history -past_entries 1\n\n            See also '-requires_afni_hist'.\n\n            See also '-check_afni_version'.", "help_range": [114968, 115953]}, {"param": "-requires_afni_hist", "line_start": 2314, "length": 4, "param_range": [115963, 115982], "help": "show history of -requires_afni_version\n\n            List the history of '-requires_afni_version' dates and reasons.", "help_range": [115989, 116104]}, {"param": "-show_valid_opts", "line_start": 2318, "length": 1, "param_range": [116114, 116130], "help": "show all valid options (brief format)", "help_range": [116140, 116177]}, {"param": "-ver", "line_start": 2319, "length": 5, "param_range": [116186, 116190], "help": "show the version number\n\n        -----------------------------------------------------------------\n        General execution and setup options ~3~", "help_range": [116212, 116358]}, {"param": "-anat_follower", "line_start": 2324, "length": 22, "param_range": [116368, 116382], "help": "specify anat follower dataset\n\n                e.g. -anat_follower GM anat FS_GM_MASK.nii\n\n            Use this option to pass any anatomical follower dataset.  Such a\n            dataset is warped by any transformations that take the original\n            anat to anat_final.\n\n            Anatomical follower datasets are resampled using wsinc5.  The only\n            difference with -anat_follower_ROI is that such ROI datasets are\n            resampled using nearest neighbor interpolation.\n\n               LABEL    : to name and refer to this dataset\n               GRID     : which grid should this be sampled on, anat or epi?\n               DSET     : name of input dataset, changed to copy_af_LABEL\n\n            A default anatomical follower (in the case of skull stripping) is\n            the original anat.  That is to get a warped version that still has\n            a skull, for quality control.\n\n            See also -anat_follower_ROI, anat_follower_erode.", "help_range": [116401, 117368]}, {"param": "-anat_follower_erode", "line_start": 2346, "length": 14, "param_range": [117378, 117398], "help": "        -anat_follower_erode LABEL LABEL ...: erode masks for given labels\n\n                e.g. -anat_follower_erode WMe\n\n            Perform a single erosion step on the mask dataset for the given\n            label.  This is done on the input ROI (anatomical?) grid.\n\n            The erosion step is applied before any transformation, and uses the\n            18-neighbor approach (6 face and 12 edge neighbors, not 8 corner\n            neighbors) in 3dmask_tool.\n\n            See also -regress_ROI_PC, -regress_ROI.\n            Please see '3dmask_tool -help' for more information on eroding.", "help_range": [117370, 117964]}, {"param": "-anat_follower_ROI", "line_start": 2360, "length": 23, "param_range": [117974, 117992], "help": "specify anat follower ROI dataset\n\n                e.g. -anat_follower_ROI aaseg anat aparc.a2009s+aseg.nii\n                e.g. -anat_follower_ROI FSvent epi FreeSurfer_ventricles.nii\n\n            Use this option to pass any anatomical follower dataset.  Such a\n            dataset is warped by any transformations that take the original\n            anat to anat_final.\n\n            Similar to -anat_follower, except that these anatomical follower\n            datasets are resampled using nearest neighbor (NN) interpolation,\n            to preserve data values (as opposed to -anat_follower, which uses\n            wsinc5).  That is the only difference between these options.\n\n               LABEL    : to name and refer to this dataset\n               GRID     : which grid should this be sampled on, anat or epi?\n               DSET     : name of input dataset, changed to copy_af_LABEL\n\n            Labels defined via this option may be used in -regress_ROI or _PC.\n\n            See also -anat_follower, anat_follower_erode, -regress_ROI\n            or -regress_ROI_PC.", "help_range": [118011, 119084]}, {"param": "-anat_has_skull", "line_start": 2383, "length": 7, "param_range": [119094, 119109], "help": "        -anat_has_skull yes/no  : specify whether the anatomy has a skull\n\n                e.g. -anat_has_skull no\n\n            Use this option to block any skull-stripping operations, likely\n            either in the align or tlrc processing blocks.", "help_range": [119086, 119336]}, {"param": "-anat_uniform_method", "line_start": 2390, "length": 14, "param_range": [119346, 119366], "help": "specify uniformity correction method\n\n                e.g. -anat_uniform_method unifize\n\n            Specify the method for anatomical intensity uniformity correction.\n\n                none    : do not do uniformity correction at all\n                default : use 3dUnifize at whim of auto_warp.py\n                unifize : apply 3dUnifize early in processing stream\n                          (so it affects more than auto_warp.py)\n\n            Please see '3dUnifize -help' for details.\n            See also -anat_opts_unif.", "help_range": [119376, 119900]}, {"param": "-anat_opts_unif", "line_start": 2404, "length": 10, "param_range": [119910, 119925], "help": "        -anat_opts_unif OPTS ... : specify extra options for unifize command\n\n                e.g. -anat_opts_unif -Urad 14\n\n            Specify options to be applied to the command used for anatomical\n            intensity uniformity correction, such as 3dUnifize.\n\n            Please see '3dUnifize -help' for details.\n            See also -anat_uniform_method.", "help_range": [119902, 120265]}, {"param": "-anat_unif_GM", "line_start": 2414, "length": 16, "param_range": [120275, 120288], "help": "        -anat_unif_GM yes/no    : also unifize gray matter (lower intensities)\n                                  the default is 'no'\n\n                e.g. -anat_unif_GM yes\n                default: -anat_unif_GM no\n\n            If this is set to yes, 3dUnifize will not only apply uniformity\n            correction across the brain volume, but also to voxels that look\n            like gray matter.  That is to say the option adds '-GM' to the\n            3dUnifize command.\n\n          * The default was changed from yes to no 2014, May 16.\n\n            Please see '3dUnifize -help' for details.\n            See also -anat_uniform_method, -anat_opts_unif.", "help_range": [120267, 120922]}, {"param": "-ask_me", "line_start": 2430, "length": 6, "param_range": [120932, 120939], "help": "ask the user about the basic options to apply\n\n            When this option is used, the program will ask the user how they\n            wish to set the basic options.  The intention is to give the user\n            a feel for what options to apply (without using -ask_me).", "help_range": [120958, 121229]}, {"param": "-bash", "line_start": 2436, "length": 29, "param_range": [121239, 121244], "help": "show example execution command in bash form\n\n            After the script file is created, this program suggests how to run\n            it (piping stdout/stderr through 'tee').  If the user is running\n            the bash shell, this option will suggest the 'bash' form of a\n            command to execute the newly created script.\n\n            example of tcsh form for execution:\n\n                tcsh -x proc.ED.8.glt |& tee output.proc.ED.8.glt\n\n            example of bash form for execution:\n\n                tcsh -x proc.ED.8.glt 2>&1 | tee output.proc.ED.8.glt\n\n            Please see \"man bash\" or \"man tee\" for more information.\n\n        -blocks BLOCK1 ...      : specify the processing blocks to apply\n\n                e.g. -blocks volreg blur scale regress\n                e.g. -blocks despike tshift align volreg blur scale regress\n                default: tshift volreg blur mask scale regress\n\n            The user may apply this option to specify which processing blocks\n            are to be included in the output script.  The order of the blocks\n            may be varied, and blocks may be skipped.\n\n            See also '-do_block' (e.g. '-do_block despike').", "help_range": [121265, 122444]}, {"param": "-check_afni_version", "line_start": 2465, "length": 21, "param_range": [122454, 122473], "help": "        -check_afni_version yes/no : check that AFNI is current enough\n\n                e.g. -check_afni_version no\n                default: yes\n\n            Check that the version of AFNI is recent enough for processing of\n            the afni_proc.py script.\n\n            For the version check, the output of:\n                afni_proc.py -requires_afni_version\n\n            is tested against the most recent date in afni_history:\n                afni_history -past_entries 1\n\n            In the case that newer features in other programs might not be\n            needed by the given afni_proc.py script (depending on the options),\n            the user is left with this option to ignore the AFNI version check.\n\n            Please see 'afni_history -help' or 'afni -ver' for more information.\n            See also '-requires_afni_version'.", "help_range": [122446, 123288]}, {"param": "-check_results_dir", "line_start": 2486, "length": 9, "param_range": [123298, 123316], "help": "        -check_results_dir yes/no : check whether dir exists before proceeding\n\n                e.g. -check_results_dir no\n                default: yes\n\n            By default, if the results directory already exists, the script\n            will terminate before doing any processing.  Set this option to\n            'no' to remove that check.", "help_range": [123290, 123633]}, {"param": "-check_setup_errors", "line_start": 2495, "length": 7, "param_range": [123643, 123662], "help": "        -check_setup_errors yes/no : terminate on setup errors\n\n                e.g. -check_setup_errors yes\n                default: no\n\n            Have the script check $status after each command in the setup\n            processing block.  It is preferable to run the script using the", "help_range": [123635, 123922]}, {"param": "-e", "line_start": 2502, "length": 3, "param_range": [123935, 123937], "help": "            -e option to tcsh (as suggested), but maybe the user does not wish\n            to do so.", "help_range": [123923, 124023]}, {"param": "-copy_anat", "line_start": 2505, "length": 10, "param_range": [124033, 124043], "help": "copy the ANAT dataset to the results dir\n\n                e.g. -copy_anat Elvis/mprage+orig\n\n            This will apply 3dcopy to copy the anatomical dataset(s) to the\n            results directory.  Note that if a +view is not given, 3dcopy will\n            attempt to copy +acpc and +tlrc datasets, also.\n\n            See also '3dcopy -help'.", "help_range": [124059, 124404]}, {"param": "-copy_files", "line_start": 2515, "length": 10, "param_range": [124414, 124425], "help": "        -copy_files file1 ...   : copy file1, etc. into the results directory\n\n                e.g. -copy_files glt_AvsB.txt glt_BvsC.1D glt_eat_cheese.txt\n                e.g. -copy_files contrasts/glt_*.txt\n\n            This option allows the user to copy some list of files into the\n            results directory.  This would happen before the tcat block, so\n            such files may be used for other commands in the script (such as\n            contrast files in 3dDeconvolve, via -regress_opts_3dD).", "help_range": [124406, 124912]}, {"param": "-do_block", "line_start": 2525, "length": 21, "param_range": [124922, 124931], "help": "        -do_block BLOCK_NAME ...: add extra blocks in their default positions\n\n                e.g. -do_block despike ricor\n                e.g. -do_block align\n\n            With this option, any 'optional block' can be applied in its\n            default position.  This includes the following blocks, along with\n            their default positions:\n\n                despike : first (between tcat and tshift)\n                ricor   : just after despike (else first)\n                align   : before tlrc, before volreg\n                tlrc    : after align, before volreg\n                empty   : NO DEFAULT, cannot be applied via -do_block\n\n            Any block not included in -blocks can be added via this option\n            (except for 'empty').\n\n            See also '-blocks', as well as the \"PROCESSING BLOCKS\" section of\n            the -help output.", "help_range": [124914, 125775]}, {"param": "-dsets", "line_start": 2546, "length": 20, "param_range": [125785, 125791], "help": "        -dsets dset1 dset2 ...  : (REQUIRED) specify EPI run datasets\n\n                e.g. -dsets Elvis_run1+orig Elvis_run2+orig Elvis_run3+orig\n                e.g. -dsets Elvis_run*.HEAD\n\n            The user must specify the list of EPI run datasets to analyze.\n            When the runs are processed, they will be written to start with\n            run 1, regardless of whether the input runs were just 6, 7 and 21.\n\n            Note that when using a wildcard it is essential for the EPI\n            datasets to be alphabetical, as that is how the shell will list\n            them on the command line.  For instance, epi_run1+orig through\n            epi_run11+orig is not alphabetical.  If they were specified via\n            wildcard their order would end up as run1 run10 run11 run2 ...\n\n            Note also that when using a wildcard it is essential to specify\n            the datasets suffix, so that the shell doesn't put both the .BRIK\n            and .HEAD filenames on the command line (which would make it twice\n            as many runs of data).", "help_range": [125777, 126842]}, {"param": "-dsets", "line_start": 2566, "length": 6, "param_range": [126852, 126858], "help": "        -dsets_me_echo dset1 dset2 ...  : specify ME datasets for one echo\n                                          (all runs with each option)\n\n           These examples might correspond to 3 echoes across 4 runs.\n\n                e.g. -dsets_me_echo epi_run*.echo_1+orig.HEAD", "help_range": [126844, 127122]}, {"param": "-dsets", "line_start": 2572, "length": 1, "param_range": [127144, 127150], "help": "                     -dsets_me_echo epi_run*.echo_2+orig.HEAD", "help_range": [127123, 127184]}, {"param": "-dsets", "line_start": 2573, "length": 3, "param_range": [127206, 127212], "help": "                     -dsets_me_echo epi_run*.echo_3+orig.HEAD\n\n                e.g. -dsets_me_echo r?.e1.nii", "help_range": [127185, 127293]}, {"param": "-dsets", "line_start": 2576, "length": 1, "param_range": [127315, 127321], "help": "                     -dsets_me_echo r?.e2.nii", "help_range": [127294, 127339]}, {"param": "-dsets", "line_start": 2577, "length": 3, "param_range": [127361, 127367], "help": "                     -dsets_me_echo r?.e3.nii\n\n                e.g. -dsets_me_echo r1.e1.nii r2.e1.nii r3.e1.nii r4.e1.nii", "help_range": [127340, 127462]}, {"param": "-dsets", "line_start": 2580, "length": 1, "param_range": [127484, 127490], "help": "                     -dsets_me_echo r1.e2.nii r2.e2.nii r3.e2.nii r4.e2.nii", "help_range": [127463, 127538]}, {"param": "-dsets", "line_start": 2581, "length": 20, "param_range": [127560, 127566], "help": "                     -dsets_me_echo r1.e3.nii r2.e3.nii r3.e3.nii r4.e3.nii\n\n            This option is convenient when there are more runs than echoes.\n\n            When providing multi-echo data to afni_proc.py, doing all echoes\n            of all runs at once seems messy and error prone.  So one must\n            provide either one echo at a time (easier if there are more runs)\n            or one run at a time (easier if there are fewer runs).\n\n            With this option:\n\n               - use one option per echo (as opposed to per run, below)\n               - each option use should list all run datasets for that echo\n\n            For example, if there are 7 runs and 3 echoes, use 3 options, one\n            per echo, and pass the 7 runs of data for that echo in each.\n\n            See also -dsets_me_run.\n            See also -echo_times and -reg_echo.", "help_range": [127539, 128405]}, {"param": "-dsets", "line_start": 2601, "length": 6, "param_range": [128415, 128421], "help": "        -dsets_me_run dset1 dset2 ...   : specify ME datasets for one run\n                                          (all echoes with each option)\n\n           These examples might correspond to 4 echoes across 2 runs.\n\n                e.g. -dsets_me_run epi_run1.echo_*+orig.HEAD", "help_range": [128407, 128685]}, {"param": "-dsets", "line_start": 2607, "length": 3, "param_range": [128707, 128713], "help": "                     -dsets_me_run epi_run2.echo_*+orig.HEAD\n\n                e.g. -dsets_me_run r1.e*.nii", "help_range": [128686, 128792]}, {"param": "-dsets", "line_start": 2610, "length": 3, "param_range": [128814, 128820], "help": "                     -dsets_me_run r2.e*.nii\n\n                e.g. -dsets_me_run r1.e1.nii r1.e2.nii r1.e3.nii r1.e4.nii", "help_range": [128793, 128913]}, {"param": "-dsets", "line_start": 2613, "length": 20, "param_range": [128935, 128941], "help": "                     -dsets_me_run r2.e1.nii r2.e2.nii r2.e3.nii r2.e4.nii\n\n            This option is convenient when there are more echoes than runs.\n\n            When providing multi-echo data to afni_proc.py, doing all echoes\n            of all runs at once seems messy and error prone.  So one must\n            provide either one echo at a time (easier if there are more runs)\n            or one run at a time (easier if there are fewer runs).\n\n            With this option:\n\n               - use one option per run (as opposed to per echo, above)\n               - each option use should list all echo datasets for that run\n\n            For example, if there are 2 runs and 4 echoes, use 2 options, one\n            per run, and pass the 4 echoes of data for that run in each.\n\n            See also -dsets_me_echo.\n            See also -echo_times and -reg_echo.", "help_range": [128914, 129780]}, {"param": "-e", "line_start": 2633, "length": 9, "param_range": [129790, 129792], "help": "        -echo_times TE1 TE2 TE3 ... : specify echo-times for ME data processing\n\n                e.g. -echo_times 20 30.5 41.2\n\n            Use this option to specify echo times, if they are needed for the\n            'combine' processing block (OC/ME-ICA/tedana).\n\n            See also -combine_method.", "help_range": [129782, 130085]}, {"param": "-execute", "line_start": 2642, "length": 13, "param_range": [130095, 130103], "help": "execute the created processing script\n\n            If this option is applied, not only will the processing script be\n            created, but it will then be executed in the \"suggested\" manner,\n            such as via:\n\n                tcsh -xef proc.sb23 |& tee output.proc.sb23\n\n            Note that it will actually use the bash format of the command,\n            since the system command (C and therefore python) uses /bin/sh.\n\n                tcsh -xef proc.sb23 2>&1 | tee output.proc.sb23", "help_range": [130121, 130617]}, {"param": "-gen_epi_review", "line_start": 2655, "length": 24, "param_range": [130627, 130642], "help": "specify script for EPI review\n\n                e.g. -gen_epi_review review_orig_EPI.txt\n\n            By default, the proc script calls gen_epi_review.py on the original\n            EPI data (from the tcat step, so only missing pre-SS TRs).  This\n            creates a \"drive afni\" script that the user can run to quickly scan\n            that EPI data for apparent issues.\n\n            Without this option, the script will be called @epi_review.$subj,\n            where $subj is the subject ID.\n\n            The script starts afni, loads the first EPI run and starts scanning\n            through time (effectively hitting 'v' in the graph window).  The\n            user can press <enter> in the prompting terminal window to go to\n            each successive run.\n\n            Note that the user has full control over afni, aside from a new run\n            being loaded whey they hit <enter>.  Recall that the <space> key\n            (applied in the graph window) can terminate the 'v' (video mode).\n\n            See 'gen_epi_review.py -help' for details.\n            See also 'no_epi_review', to disable this feature.", "help_range": [130657, 131774]}, {"param": "-no_epi_review", "line_start": 2679, "length": 12, "param_range": [131784, 131798], "help": "        -no_epi_review\n\n            This option is used to prevent writing a gen_epi_review.py command\n            in the processing script (i.e. do not create a script to review the\n            EPI data).\n\n            The only clear reason to want this option is if gen_epi_review.py\n            fails for some reason.  It should not hurt to create that little\n            text file (@epi_review.$subj, by default).\n\n            See also '-gen_epi_review'.", "help_range": [131776, 132233]}, {"param": "-keep_rm_files", "line_start": 2691, "length": 9, "param_range": [132243, 132257], "help": "do not have script delete rm.* files at end\n\n                e.g. -keep_rm_files\n\n            The output script may generate temporary files in a block, which\n            would be given names with prefix 'rm.'.  By default, those files\n            are deleted at the end of the script.  This option blocks that\n            deletion.", "help_range": [132269, 132601]}, {"param": "-move_preproc_files", "line_start": 2700, "length": 7, "param_range": [132611, 132630], "help": "move preprocessing files to preproc.data dir\n\n            At the end of the output script, create a 'preproc.data' directory,\n            and move most of the files there (dfile, outcount, pb*, rm*).\n\n            See also -remove_preproc_files.", "help_range": [132637, 132881]}, {"param": "-no_proc_command", "line_start": 2707, "length": 7, "param_range": [132891, 132907], "help": "do not print afni_proc.py command in script\n\n                e.g. -no_proc_command\n\n            If this option is applied, the command used to generate the output\n            script will be stored at the end of the script.", "help_range": [132917, 133139]}, {"param": "-out_dir", "line_start": 2714, "length": 8, "param_range": [133149, 133157], "help": "specify the output directory for the script\n\n                e.g. -out_dir ED_results\n                default: SUBJ.results\n\n            The AFNI processing script will create this directory and perform\n            all processing in it.", "help_range": [133175, 133411]}, {"param": "-outlier_count", "line_start": 2722, "length": 15, "param_range": [133421, 133435], "help": "        -outlier_count yes/no   : should we count outliers with 3dToutcount?\n\n                e.g. -outlier_count no\n                default: yes\n\n            By default, outlier fractions are computed per TR with 3dToutcount.\n            To disable outlier counting, apply this option with parameter 'no'.\n            This is a yes/no option, meaning those are the only valid inputs.\n\n            Note that -outlier_count must be 'yes' in order to censor outliers\n            with -regress_censor_outliers.\n\n            See \"3dToutcount -help\" for more details.\n            See also -regress_censor_outliers.", "help_range": [133413, 134022]}, {"param": "-outlier_legendre", "line_start": 2737, "length": 11, "param_range": [134032, 134049], "help": "        -outlier_legendre yes/no : use Legendre polynomials in 3dToutcount?\n\n                e.g. -outlier_legendre no\n                default: yes\n\n            By default the -legendre option is passed to 3dToutcount.  Along\n            with using better behaved polynomials, it also allows them to be\n            higher than 3rd order (if desired).\n\n            See \"3dToutcount -help\" for more details.", "help_range": [134024, 134429]}, {"param": "-outlier_polort", "line_start": 2748, "length": 14, "param_range": [134439, 134454], "help": "specify polynomial baseline for 3dToutcount\n\n                e.g. -outlier_polort 3\n                default: same degree that 3dDeconvolve would use:\n                         1 + floor(run_length/150)\n\n            Outlier counts come after detrending the data, where the degree\n            of the polynomial trend defaults to the same that 3dDeconvolve\n            would use.  This option will override the default.\n\n            See \"3dToutcount -help\" for more details.\n            See \"3dDeconvolve -help\" for more details.\n            See also '-regress_polort' and '-outlier_legendre'.", "help_range": [134465, 135054]}, {"param": "-radial_correlate", "line_start": 2762, "length": 28, "param_range": [135064, 135081], "help": "        -radial_correlate yes/no : correlate each voxel with local radius\n\n                e.g. -radial_correlate yes\n                default: no\n\n            With this option set, @radial_correlate will be run on the\n            initial EPI time series datasets.  That creates a 'corr_test'\n            directory that one can review, plus potential warnings (in text)\n            if large clusters of high correlations are found.\n\n            (very abbreviated) method for @radial_correlate:\n                for each voxel\n                   compute average time series within 20 mm radius sphere\n                   correlate central voxel time series with spherical average\n                look for clusters of high correlations\n\n            This is a useful quality control (QC) dataset that helps one find\n            scanner artifacts, particularly including coils going bad.\n\n            To visually check the results, the program text output suggests:\n\n                run command: afni corr_test.results.postdata\n                then set:    Underlay  = epi.SOMETHING\n                             Overlay   = res.SOMETHING.corr\n                             maybe threshold = 0.9, maybe clusterize\n\n            See \"@radial_correlate -help\" for details and a list of options.", "help_range": [135056, 136338]}, {"param": "-reg_echo", "line_start": 2790, "length": 12, "param_range": [136348, 136357], "help": "specify 1-based echo for registration\n\n                e.g. -reg_echo 3\n                default: 2\n\n            Multi-echo data is registered based on a single echo, with the\n            resulting transformations being applied to all echoes.  Use this\n            option to specify the 1-based echo used to drive registration.\n\n            Note that the echo used for driving registration should have\n            reasonable tissue contrast.", "help_range": [136370, 136810]}, {"param": "-remove_preproc_files", "line_start": 2802, "length": 7, "param_range": [136820, 136841], "help": "delete pre-processed data\n\n            At the end of the output script, delete the intermediate data (to\n            save disk space).  Delete dfile*, outcount*, pb* and rm*.\n\n            See also -move_preproc_files.", "help_range": [136846, 137063]}, {"param": "-script", "line_start": 2809, "length": 10, "param_range": [137073, 137080], "help": "specify the name of the resulting script\n\n                e.g. -script ED.process.script\n                default: proc_subj\n\n            The output of this program is a script file.  This option can be\n            used to specify the name of that file.\n\n            See also -scr_overwrite, -subj_id.", "help_range": [137099, 137399]}, {"param": "-scr_overwrite", "line_start": 2819, "length": 9, "param_range": [137409, 137423], "help": "overwrite any existing script\n\n                e.g. -scr_overwrite\n\n            If the output script file already exists, it will be overwritten\n            only if the user applies this option.\n\n            See also -script.", "help_range": [137435, 137660]}, {"param": "-sep_char", "line_start": 2828, "length": 19, "param_range": [137670, 137679], "help": "apply as separation character in filenames\n\n                e.g. -sep_char _\n                default: .\n\n            The separation character is used in many output filenames, such as\n            the default '.' in:\n\n                pb04.Nancy.r07.scale+orig.BRIK\n\n            If (for some crazy reason) an underscore (_) character would be\n            preferable, the result would be:\n\n                pb04_Nancy_r07_scale+orig.BRIK\n\n            If \"-sep_char _\" is applied, so is -subj_curly.\n\n            See also -subj_curly.", "help_range": [137696, 138225]}, {"param": "-subj_curly", "line_start": 2847, "length": 12, "param_range": [138235, 138246], "help": "apply $subj as ${subj}\n\n            The subject ID is used in dataset names is typically used without\n            curly brackets (i.e. $subj).  If something is done where this would\n            result in errors (e.g. \"-sep_char _\"), the curly brackets might be\n            useful to delimit the variable (i.e. ${subj}).\n\n            Note that this option is automatically applied in the case of\n            \"-sep_char _\".\n\n            See also -sep_char.", "help_range": [138261, 138715]}, {"param": "-subj_id", "line_start": 2859, "length": 9, "param_range": [138725, 138733], "help": "specify the subject ID for the script\n\n                e.g. -subj_id elvis\n                default: SUBJ\n\n            The subject ID is used in dataset names and in the output directory\n            name (unless -out_dir is used).  This option allows the user to\n            apply an appropriate naming convention.", "help_range": [138751, 139064]}, {"param": "-test_for_dsets", "line_start": 2868, "length": 9, "param_range": [139074, 139089], "help": "        -test_for_dsets yes/no  : test for existence of input datasets\n\n                e.g. -test_for_dsets no\n                default: yes\n\n            This options controls whether afni_proc.py check for the existence\n            of input datasets.  In general, they must exist when afni_proc.py\n            is run, in order to get run information (TR, #TRs, #runs, etc).", "help_range": [139066, 139440]}, {"param": "-test_stim_files", "line_start": 2877, "length": 30, "param_range": [139450, 139466], "help": "        -test_stim_files yes/no : evaluate stim_files for appropriateness?\n\n                e.g. -test_stim_files no\n                default: yes\n\n            This options controls whether afni_proc.py evaluates the stim_files\n            for validity.  By default, the program will do so.\n\n            Input files are one of local stim_times, global stim_times or 1D\n            formats.  Options -regress_stim_files and -regress_extra_stim_files\n            imply 1D format for input files.  Otherwise, -regress_stim_times is\n            assumed to imply local stim_times format (-regress_global_times\n            implies global stim_times format).\n\n            Checks include:\n\n                1D              : # rows equals total reps\n                local times     : # rows equal # runs\n                                : times must be >= 0.0\n                                : times per run (per row) are unique\n                                : times cannot exceed run time\n                global times    : file must be either 1 row or 1 column\n                                : times must be >= 0.0\n                                : times must be unique\n                                : times cannot exceed total duration of all runs\n\n            This option provides the ability to disable this test.\n\n            See \"1d_tool.py -help\" for details on '-look_like_*' options.\n            See also -regress_stim_files, -regress_extra_stim_files,", "help_range": [139442, 140897]}, {"param": "-regress_stim_times", "line_start": 2907, "length": 2, "param_range": [140910, 140929], "help": "            -regress_stim_times, -regress_local_times, -regress_global_times.", "help_range": [140898, 140975]}, {"param": "-verb", "line_start": 2909, "length": 7, "param_range": [140985, 140990], "help": "specify the verbosity of this script\n\n                e.g. -verb 2\n                default: 1\n\n            Print out extra information during execution.", "help_range": [141011, 141163]}, {"param": "-write_3dD_prefix", "line_start": 2916, "length": 11, "param_range": [141173, 141190], "help": "specify prefix for outputs from 3dd_script\n\n                e.g. -write_3dD_prefix basis.tent.\n                default: test.\n\n            If a separate 3dDeconvolve command script is generated via the\n            option -write_3dD_script, then the given PREFIX will be used for\n            relevant output files. in the script.\n\n            See also -write_3dD_script.", "help_range": [141200, 141569]}, {"param": "-write_3dD_script", "line_start": 2927, "length": 20, "param_range": [141579, 141596], "help": "specify SCRIPT only for 3dDeconvolve command\n\n                e.g. -write_3dD_script run.3dd.tent\n\n            This option is intended to be used with the EXACT same afni_proc.py\n            command (aside from any -write_3dD_* options).  The purpose is to\n            generate a corresponding 3dDeconvolve command script which could\n            be run in the same results directory.\n\n            Alternatively, little things could be changed that would only\n            affect the 3dDeconvolve command in the new script, such as the\n            basis function(s).\n\n            The new script should include a prefix to distinguish output files\n            from those created by the original proc script.\n\n          * This option implies '-test_stim_files no'.\n\n            See also -write_3dD_prefix, -test_stim_files.", "help_range": [141606, 142425]}, {"param": "-write_ppi_3dD_scripts", "line_start": 2947, "length": 3, "param_range": [142435, 142457], "help": "flag: write 3dD scripts for PPI analysis\n\n                e.g. -write_ppi_3dD_scripts                        \\", "help_range": [142461, 142571]}, {"param": "-regress_ppi_stim_files", "line_start": 2950, "length": 1, "param_range": [142593, 142616], "help": "                     -regress_ppi_stim_files PPI_*.1D some_seed.1D \\", "help_range": [142572, 142640]}, {"param": "-regress_ppi_stim_labels", "line_start": 2951, "length": 41, "param_range": [142662, 142686], "help": "                     -regress_ppi_stim_labels PPI_A PPI_B PPI_C seed\n\n            Request 3dDeconvolve scripts for pre-PPI filtering (do regression\n            without censoring) and post-PPI filtering (include PPI regressors\n            and seed).\n\n            This is a convenience method for creating extra 3dDeconvolve\n            command scripts without having to run afni_proc.py multiple times\n            with different options.\n\n            Using this option, afni_proc.py will create the main proc script,\n            plus :\n\n               A. (if censoring was done) an uncensored 3dDeconvolve command\n                  pre-PPI filter script, to create an uncensored errts time\n                  series.\n\n                  This script is akin to using -write_3dD_* to output a\n                  regression script, along with adding -regress_skip_censor.\n                  The regression command should be identical to the original\n                  one, except for inclusion of 3dDeconvolve's -censor option.\n\n               B. a 3dDeconvolve post-PPI filter script to include the PPI\n                  and seed regressors.\n\n                  This script is akin to using -write_3dD_* to output a\n                  regression script, along with passing the PPI and seed\n                  regressors via -regress_extra_stim_files and _labels.\n\n            Use -regress_ppi_stim_files and -regress_ppi_stim_labels to\n            specify the PPI (and seed) regressors and their labels.  These\n            options are currently required.\n\n            See also -regress_ppi_stim_files, -regress_ppi_stim_labels.\n\n        -----------------------------------------------------------------\n        Block options (in default block order) ~3~\n\n        These options pertain to individual processing blocks.  Each option\n        starts with the block name.", "help_range": [142641, 144497]}, {"param": "-tcat_preSS_warn_limit", "line_start": 2992, "length": 13, "param_range": [144507, 144529], "help": "TR #0 outlier limit to warn of pre-SS\n\n                e.g. -tcat_preSS_warn_limit 0.7\n                default: 0.4\n\n            Outlier fractions are computed across TRs in the tcat processing\n            block.  If TR #0 has a large fraction, it might suggest that pre-\n            steady state TRs have been included in the analysis.  If the\n            detected fraction exceeds this limit, a warning will be stored\n            (and output by the @ss_review_basic script).\n\n            The special case of limit = 0.0 implies no check will be done.", "help_range": [144538, 145090]}, {"param": "-tcat_remove_first_trs", "line_start": 3005, "length": 15, "param_range": [145100, 145122], "help": "specify how many TRs to remove from runs\n\n                e.g. -tcat_remove_first_trs 3\n                e.g. -tcat_remove_first_trs 3 1 0 0 3\n                default: 0\n\n            Since it takes several seconds for the magnetization to reach a\n            steady state (at the beginning of each run), the initial TRs of\n            each run may have values that are significantly greater than the\n            later ones.  This option is used to specify how many TRs to\n            remove from the beginning of every run.\n\n            If the number needs to vary across runs, then one number should\n            be specified per run.", "help_range": [145129, 145762]}, {"param": "-tcat_remove_last_trs", "line_start": 3020, "length": 9, "param_range": [145772, 145793], "help": "specify TRs to remove from run ends\n\n                e.g. -tcat_remove_last_trs 10\n                default: 0\n\n            For when the user wants a simple way to shorten each run.\n\n            See also -ricor_regs_rm_nlast.", "help_range": [145800, 146024]}, {"param": "-despike_mask", "line_start": 3029, "length": 13, "param_range": [146034, 146047], "help": "allow Automasking in 3dDespike\n\n            By default, -nomask is applied to 3dDespike.  Since anatomical\n            masks will probably not be contained within the Automask operation\n            of 3dDespike (which uses methods akin to '3dAutomask -dilate 4'),\n            it is left up to the user to speed up this operation via masking.\n\n            Note that the only case in which this should be done is when\n            applying the EPI mask to the regression.\n\n            Please see '3dDespike -help' and '3dAutomask -help' for more\n            information.", "help_range": [146060, 146627]}, {"param": "-despike_new", "line_start": 3042, "length": 19, "param_range": [146637, 146649], "help": "        -despike_new yes/no     : set whether to use new version of 3dDespike\n\n                e.g. -despike_new no\n                default: yes\n\n            There is a '-NEW' option/method in 3dDespike which runs a faster\n            method than the previous L1-norm method (Nov 2013).  The results\n            are similar but not identical (different fits).  The difference in\n            speed is more dramatic for long time series (> 500 time points).\n\n            Use this option to control whether to use the new version.\n\n            Sep 2016: in 3dDespike, -NEW is now the default if the input is\n                      longer than 500 time points.  In such a case -despike_new\n                      has no effect.\n\n            See also env var AFNI_3dDespike_NEW and '3dDespike -help' for more\n            information.", "help_range": [146629, 147455]}, {"param": "-despike_opts_3dDes", "line_start": 3061, "length": 15, "param_range": [147465, 147484], "help": "        -despike_opts_3dDes OPTS... : specify additional options for 3dDespike\n\n                e.g. -despike_opts_3dDes -nomask -ignore 2\n\n            By default, 3dDespike is used with only -prefix and -nomask\n            (unless -despike_mask is applied).  Any other options must be\n            applied via -despike_opts_3dDes.\n\n            Note that the despike block is not applied by default.  To apply\n            despike in the processing script, use either '-do_block despike'\n            or '-blocks ... despike ...'.\n\n            Please see '3dDespike -help' for more information.\n            See also '-do_blocks', '-blocks', '-despike_mask'.", "help_range": [147457, 148111]}, {"param": "-ricor_datum", "line_start": 3076, "length": 16, "param_range": [148121, 148133], "help": "specify output data type from ricor block\n\n                e.g. -ricor_datum float\n\n            By default, if the input is unscaled shorts, the output will be\n            unscaled shorts.  Otherwise the output will be floats.\n\n            The user may override this default with the -ricor_datum option.\n            Currently only 'short' and 'float' are valid parameters.\n\n            Note that 3dREMLfit only outputs floats at the moment.  Recall\n            that the down-side of float data is that it takes twice the disk\n            space, compared with shorts (scaled or unscaled).\n\n            Please see '3dREMLfit -help' for more information.", "help_range": [148147, 148799]}, {"param": "-ricor_polort", "line_start": 3092, "length": 12, "param_range": [148809, 148822], "help": "set the polynomial degree for 3dREMLfit\n\n                e.g. -ricor_polort 4\n                default: 1 + floor(run_length / 75.0)\n\n            The default polynomial degree to apply during the 'ricor' block is\n            similar to that of the 'regress' block, but is based on twice the\n            run length (and so should be almost twice as large).  This is to\n            account for motion, since volreg has typically not happened yet.\n\n            Use -ricor_polort to override the default.", "help_range": [148835, 149334]}, {"param": "-ricor_regress_method", "line_start": 3104, "length": 13, "param_range": [149344, 149365], "help": "process per-run or across-runs\n\n                e.g. -ricor_regress_method across-runs\n                default: NONE: this option is required for a 'ricor' block\n\n            * valid METHOD parameters: per-run, across-runs\n\n            The cardiac and respiratory signals can be regressed out of each\n            run separately, or out of all runs at once.  The user must choose\n            the method, there is no default.\n\n            See \"RETROICOR NOTE\" for more details about the methods.", "help_range": [149378, 149871]}, {"param": "-ricor_regress_solver", "line_start": 3117, "length": 21, "param_range": [149881, 149902], "help": "regress using OLSQ or REML\n\n                e.g. -ricor_regress_solver REML\n                default: OLSQ\n\n            * valid METHOD parameters: OLSQ, REML\n\n            Use this option to specify the regression method for removing the\n            cardiac and respiratory signals.  The default method is ordinary\n            least squares, removing the \"best fit\" of the card/resp signals\n            from the data (also subject to the polort baseline).\n\n            To apply the REML (REstricted Maximum Likelihood) method, use this\n            option.\n\n            Note that 3dREMLfit is used for the regression in either case,\n            particularly since the regressors are slice-based (they are\n            different for each slice).\n\n            Please see '3dREMLfit -help' for more information.", "help_range": [149915, 150719]}, {"param": "-ricor_regs", "line_start": 3138, "length": 15, "param_range": [150729, 150740], "help": "        -ricor_regs REG1 REG2 ...       : specify ricor regressors (1 per run)\n\n                e.g. -ricor_regs slibase*.1D\n\n            This option is required with a 'ricor' processing block.\n\n            The expected format of the regressor files for RETROICOR processing\n            is one file per run, where each file contains a set of regressors\n            per slice.  If there are 5 runs and 27 slices, and if there are 13\n            regressors per slice, then there should be 5 files input, each with\n            351 (=27*13) columns.\n\n            This format is based on the output of RetroTS.m, included in the\n            AFNI distribution (as part of the matlab package), by Z Saad.", "help_range": [150721, 151419]}, {"param": "-ricor_regs_nfirst", "line_start": 3153, "length": 15, "param_range": [151429, 151447], "help": "ignore the first regressor timepoints\n\n                e.g. -ricor_regs_nfirst 2\n                default: 0\n\n            This option is similar to -tcat_remove_first_trs.  It is used to\n            remove the first few TRs from the -ricor_regs regressor files.\n\n            Since it is likely that the number of TRs in the ricor regressor\n            files matches the number of TRs in the original input dataset (via\n            the -dsets option), it is likely that -ricor_regs_nfirst should\n            match -tcat_remove_first_trs.\n\n            See also '-tcat_remove_first_trs', '-ricor_regs', '-dsets'.", "help_range": [151463, 152071]}, {"param": "-ricor_regs_rm_nlast", "line_start": 3168, "length": 9, "param_range": [152081, 152101], "help": "remove the last NUM TRs from each regressor\n\n                e.g. -ricor_regs_rm_nlast 10\n                default: 0\n\n            For when the user wants a simple way to shorten each run.\n\n            See also -tcat_remove_last_trs.", "help_range": [152108, 152340]}, {"param": "-tshift_align_to", "line_start": 3177, "length": 21, "param_range": [152350, 152366], "help": "specify 3dTshift alignment option\n\n                e.g. -tshift_align_to -slice 14\n                default: -tzero 0\n\n            By default, each time series is aligned to the beginning of the\n            TR.  This option allows the users to change the alignment, and\n            applies the option parameters directly to the 3dTshift command\n            in the output script.\n\n            It is likely that the user will use either '-slice SLICE_NUM' or\n            '-tzero ZERO_TIME'.\n\n            Note that when aligning to an offset other than the beginning of\n            the TR, and when applying the -regress_stim_files option, then it\n            may be necessary to also apply -regress_stim_times_offset, to\n            offset timing for stimuli to later within each TR.\n\n            Please see '3dTshift -help' for more information.\n            See also '-regress_stim_times_offset'.", "help_range": [152379, 153273]}, {"param": "-tshift_interp", "line_start": 3198, "length": 8, "param_range": [153283, 153297], "help": "specify the interpolation method for tshift\n\n                e.g. -tshift_interp -Fourier\n                e.g. -tshift_interp -cubic\n                default -quintic\n\n            Please see '3dTshift -help' for more information.", "help_range": [153309, 153537]}, {"param": "-tshift_opts_ts", "line_start": 3206, "length": 10, "param_range": [153547, 153562], "help": "        -tshift_opts_ts OPTS ... : specify extra options for 3dTshift\n\n                e.g. -tshift_opts_ts -tpattern alt+z\n\n            This option allows the user to add extra options to the 3dTshift\n            command.  Note that only one -tshift_opts_ts should be applied,\n            which may be used for multiple 3dTshift options.\n\n            Please see '3dTshift -help' for more information.", "help_range": [153539, 153940]}, {"param": "-blip_forward_dset", "line_start": 3216, "length": 12, "param_range": [153950, 153968], "help": "specify a forward blip dataset\n\n                e.g. -blip_forward_dset epi_forward_blip+orig'[0..9]'\n\n            Without this option, the first TRs of the first input EPI time\n            series would be used as the forward blip dataset.\n\n            See also -blip_revers_dset.\n\n            Please see '3dQwarp -help' for more information, and the -plusminus\n            option in particular.", "help_range": [153976, 154371]}, {"param": "-blip_reverse_dset", "line_start": 3228, "length": 14, "param_range": [154381, 154399], "help": "specify a reverse blip dataset\n\n                e.g. -blip_reverse_dset epi_reverse_blip+orig\n                e.g. -blip_reverse_dset epi_reverse_blip+orig'[0..9]'\n\n            EPI distortion correction can be applied via blip up/blip down\n            acquisitions.  Unless specified otherwise, the first TRs of the\n            first run of typical EPI data specified via -dsets is considered\n            to be the forward direction (blip up, say).  So only the reverse\n            direction data needs separate input.\n\n            Please see '3dQwarp -help' for more information, and the -plusminus\n            option in particular.", "help_range": [154407, 155040]}, {"param": "-blip_opts_qw", "line_start": 3242, "length": 12, "param_range": [155050, 155063], "help": "        -blip_opts_qw OPTS ...  : specify extra options for 3dQwarp\n\n                e.g. -blip_opts_qw -noXdis -noZdis\n\n            This option allows the user to add extra options to the 3dQwarp\n            command specific to the 'blip' processing block.\n\n            There are many options (e.g. for blurring) applied in the 3dQwarp\n            command by afni_proc.py by default, so review the resulting script.\n\n            Please see '3dQwarp -help' for more information.", "help_range": [155042, 155520]}, {"param": "-tlrc_anat", "line_start": 3254, "length": 16, "param_range": [155530, 155540], "help": "run @auto_tlrc on '-copy_anat' dataset\n\n                e.g. -tlrc_anat\n\n            Run @auto_tlrc on the anatomical dataset provided by '-copy_anat'.\n            By default, warp the anat to align with TT_N27+tlrc, unless the\n            '-tlrc_base' option is given.\n\n            The -copy_anat option specifies which anatomy to transform.\n\n         ** Note, use of this option has the same effect as application of the\n            'tlrc' block.\n\n            Please see '@auto_tlrc -help' for more information.\n            See also -copy_anat, -tlrc_base, -tlrc_no_ss and the 'tlrc' block.", "help_range": [155556, 156148]}, {"param": "-tlrc_base", "line_start": 3270, "length": 15, "param_range": [156158, 156168], "help": "run \"@auto_tlrc -base BASE_DSET\"\n\n                e.g. -tlrc_base TT_icbm452+tlrc\n                default: -tlrc_base TT_N27+tlrc\n\n            This option is used to supply an alternate -base dataset for\n            @auto_tlrc (or auto_warp.py).  Otherwise, TT_N27+tlrc will be used.\n\n            Note that the default operation of @auto_tlrc is to \"skull strip\"\n            the input dataset.  If this is not appropriate, consider also the\n            '-tlrc_no_ss' option.\n\n            Please see '@auto_tlrc -help' for more information.\n            See also -tlrc_anat, -tlrc_no_ss.", "help_range": [156184, 156769]}, {"param": "-tlrc_NL_warp", "line_start": 3285, "length": 32, "param_range": [156779, 156792], "help": "use non-linear for template alignment\n\n                e.g. -tlrc_NL_warp\n\n            If this option is applied, then auto_warp.py is applied for the\n            transformation to standard space, rather than @auto_tlrc, which in\n            turn applies 3dQwarp (rather than 3dWarpDrive in @auto_tlrc).\n\n            The output datasets from this operation are:\n\n                INPUT_ANAT+tlrc         : standard space version of anat\n                anat.un.aff.Xat.1D      : affine xform to standard space\n                anat.un.aff.qw_WARP.nii : non-linear xform to standard space\n                                          (displacement vectors across volume)\n\n            The resulting ANAT dataset is copied out of the awpy directory\n            back into AFNI format, and with the original name but new view,\n            while the 2 transformation files (one text file of 12 numbers, one\n            3-volume dataset vectors) are moved out with the original names.\n\n            If -volreg_tlrc_warp is given, then the non-linear transformation\n            will also be applied to the EPI data, sending the 'volreg' output\n            directly to standard space.  As usual, all transformations are\n            combined so that the EPI is only resampled one time.\n\n            Options can be added to auto_warp.py via -tlrc_opts_at.\n\n            Consider use of -anat_uniform_method along with this option.\n\n            Please see 'auto_warp.py -help' for more information.\n            See also -tlrc_opts_at, -anat_uniform_method.", "help_range": [156805, 158342]}, {"param": "-tlrc_NL_warped_dsets", "line_start": 3317, "length": 15, "param_range": [158352, 158373], "help": "        -tlrc_NL_warped_dsets ANAT WARP.1D NL_WARP: import auto_warp.py output\n\n                e.g. -tlrc_NL_warped_dsets anat.nii           \\\n                                           anat.un.aff.Xat.1D \\\n                                           anat.un.aff.qw_WARP.nii\n\n            If the user has already run auto_warp.py on the subject anatomy\n            to transform (non-linear) to standard space, those datasets can\n            be input to save re-processing time.\n\n            They are the same 3 files that would be otherwise created by\n            running auto_warp_py from the proc script.\n\n            When using this option, the 'tlrc' block will be empty of actions.", "help_range": [158344, 159029]}, {"param": "-tlrc_NL_awpy_rm", "line_start": 3332, "length": 9, "param_range": [159039, 159055], "help": "        -tlrc_NL_awpy_rm Y/N    : specify whether to remove awpy directory\n\n                e.g.     -tlrc_NL_awpy_rm no\n                default: -tlrc_NL_awpy_rm yes\n\n            The auto_warp.py program does all its work in an sub-directory\n            called 'awpy', which is removed by default.  Use this option with\n            'no' to save the awpy directory.", "help_range": [159031, 159396]}, {"param": "-tlrc_no_ss", "line_start": 3341, "length": 9, "param_range": [159406, 159417], "help": "add the -no_ss option to @auto_tlrc\n\n                e.g. -tlrc_no_ss\n\n            This option is used to tell @auto_tlrc not to perform the skull\n            strip operation.\n\n            Please see '@auto_tlrc -help' for more information.", "help_range": [159432, 159672]}, {"param": "-tlrc_opts_at", "line_start": 3350, "length": 13, "param_range": [159682, 159695], "help": "        -tlrc_opts_at OPTS ...   : add additional options to @auto_tlrc\n\n                e.g. -tlrc_opts_at -OK_maxite\n\n            This option is used to add user-specified options to @auto_tlrc,\n            specifically those afni_proc.py is not otherwise set to handle.\n\n            In the case of -tlrc_NL_warp, the options will be passed to\n            auto_warp.py, instead.\n\n            Please see '@auto_tlrc -help' for more information.\n            Please see 'auto_warp.py -help' for more information.", "help_range": [159674, 160185]}, {"param": "-tlrc_rmode", "line_start": 3363, "length": 8, "param_range": [160195, 160206], "help": "apply RMODE resampling in @auto_tlrc\n\n                e.g. -tlrc_rmode NN\n\n            This option is used to apply '-rmode RMODE' in @auto_tlrc.\n\n            Please see '@auto_tlrc -help' for more information.", "help_range": [160221, 160431]}, {"param": "-tlrc_suffix", "line_start": 3371, "length": 8, "param_range": [160441, 160453], "help": "apply SUFFIX to result of @auto_tlrc\n\n                e.g. -tlrc_suffix auto_tlrc\n\n            This option is used to apply '-suffix SUFFIX' in @auto_tlrc.\n\n            Please see '@auto_tlrc -help' for more information.", "help_range": [160467, 160687]}, {"param": "-align_epi_ext_dset", "line_start": 3379, "length": 8, "param_range": [160697, 160716], "help": "specify dset/brick for align_epi_anat EPI\n\n                e.g. -align_epi_ext_dset subj10/epi_r01+orig'[0]'\n\n            This option allows the user to specify an external volume for the\n            EPI base used in align_epi_anat.py in the align block.  The user\n            should apply sub-brick selection if the dataset has more than one\n            volume.  This volume would be used for both the -epi and the", "help_range": [160724, 161139]}, {"param": "-e", "line_start": 3387, "length": 31, "param_range": [161152, 161154], "help": "            -epi_base options in align_epi_anat.py.\n\n            The user might want to align to an EPI volume that is not in the\n            processing stream in the case where there is not sufficient EPI\n            contrast left after the magnetization has reached a steady state.\n            Perhaps volume 0 has sufficient contrast for alignment, but is not\n            appropriate for analysis.  In such a case, the user may elect to\n            align to volume 0, while excluding it from the analysis as part of\n            the first volumes removed in -tcat_remove_first_trs.\n\n            e.g. -dsets subj10/epi_r*_orig.HEAD\n                 -tcat_remove_first_trs 3\n                 -align_epi_ext_dset subj10/epi_r01+orig'[0]'\n                 -volreg_align_to first\n\n            Note that even if the anatomy were acquired after the EPI, the user\n            might still want to align the anat to the beginning of some run,\n            and align all the EPIs to a time point close to that.  Since the\n            anat and EPI are being forcibly aligned, it does not make such a\n            big difference whether the EPI base is close in time to the anat\n            acquisition.\n\n            Note that this option does not affect the EPI registration base.\n\n            Note that without this option, the volreg base dataset (whether\n            one of the processed TRs or not) will be applied for anatomical\n            alignment, assuming the align block is applied.\n\n            See also -volreg_base_dset.\n            Please see \"align_epi_anat.py -help\" for more information.", "help_range": [161140, 162733]}, {"param": "-align_opts_aea", "line_start": 3418, "length": 31, "param_range": [162743, 162758], "help": "        -align_opts_aea OPTS ... : specify extra options for align_epi_anat.py\n\n                e.g. -align_opts_aea -cost lpc+ZZ\n                e.g. -align_opts_aea -cost lpc+ZZ -check_flip\n                e.g. -align_opts_aea -Allineate_opts -source_automask+4\n                e.g. -align_opts_aea -giant_move -AddEdge -epi_strip 3dAutomask\n                e.g. -align_opts_aea -skullstrip_opts -blur_fwhm 2\n\n            This option allows the user to add extra options to the alignment\n            command, align_epi_anat.py.\n\n            Note that only one -align_opts_aea option should be given, with\n            possibly many parameters to be passed on to align_epi_anat.py.\n\n            Note the second example.  In order to pass '-source_automask+4' to\n            3dAllineate, one must pass '-Allineate_opts -source_automask+4' to\n            align_epi_anat.py.\n\n            Similarly, the fourth example passes '-blur_fwhm 2' down through\n            align_epi_anat.py to 3dSkullStrip.\n\n          * The -check_flip option to align_epi_anat.py is good for evaluating\n            data from external sources.  Aside from performing the typical\n            registration, it will compare the final registration cost to that\n            of a left/right flipped version.  If the flipped version is lower,\n            one should investigate whether the axes are correctly labeled, or\n            even labeled at all.\n\n            Please see \"align_epi_anat.py -help\" for more information.\n            Please see \"3dAllineate -help\" for more information.", "help_range": [162735, 164291]}, {"param": "-align_epi_strip_method", "line_start": 3449, "length": 17, "param_range": [164301, 164324], "help": "specify EPI skull strip method in AEA\n\n                e.g. -align_epi_strip_method 3dSkullStrip\n                default: 3dAutomask (changed from 3dSkullStrip, 20 Aug, 2013)\n\n            When align_epi_anat.py is used to align the EPI and anatomy, it\n            uses 3dSkullStrip to remove non-brain tissue from the EPI dataset.\n            However afni_proc.py changes that to 3dAutomask by default (as of\n            August 20, 2013).  This option can be used to specify which method\n            to use, one of 3dSkullStrip, 3dAutomask or None.\n\n            This option assumes the 'align' processing block is used.\n\n            Please see \"align_epi_anat.py -help\" for more information.\n            Please see \"3dSkullStrip -help\" for more information.\n            Please see \"3dAutomask -help\" for more information.", "help_range": [164334, 165155]}, {"param": "-align_unifize_epi", "line_start": 3466, "length": 11, "param_range": [165165, 165183], "help": "        -align_unifize_epi yes/no: run uniformity correction on EPI base volume\n\n                e.g. -align_unifize_epi yes\n                default: no\n\n            Use this option to run \"3dUnifize -T2\" on the vr_base dataset\n            for the purpose of alignment to the anat.\n\n            The uniformity corrected volume is only used for anatomical\n            alignment.", "help_range": [165157, 165534]}, {"param": "-volreg_align_e2a", "line_start": 3477, "length": 19, "param_range": [165544, 165561], "help": "align EPI to anatomy at volreg step\n\n            This option is used to align the EPI data to match the anatomy.\n            It is done by applying the inverse of the anatomy to EPI alignment\n            matrix to the EPI data at the volreg step.  The 'align' processing\n            block is required.\n\n            At the 'align' block, the anatomy is aligned to the EPI data.\n            When applying the '-volreg_align_e2a' option, the inverse of that\n            a2e transformation (so now e2a) is instead applied to the EPI data.\n\n            Note that this e2a transformation is catenated with the volume\n            registration transformations, so that the EPI data is still only\n            resampled the one time.  If the user requests -volreg_tlrc_warp,\n            the +tlrc transformation will also be applied at that step in a\n            single transformation.\n\n            See also the 'align' block and '-volreg_tlrc_warp'.", "help_range": [165570, 166510]}, {"param": "-volreg_align_to", "line_start": 3496, "length": 30, "param_range": [166520, 166536], "help": "specify the base position for volume reg\n\n                e.g. -volreg_align_to last\n                e.g. -volreg_align_to MIN_OUTLIER\n                default: third\n\n            This option takes 'first', 'third', 'last' or 'MIN_OUTLIER' as a\n            parameter.  It specifies whether the EPI volumes are registered to\n            the first or third volume (of the first run), the last volume (of\n            the last run), or the volume that is consider a minimum outlier.\n            The choice of 'first' or 'third' might correspond with when the\n            anatomy was acquired before the EPI data.  The choice of 'last'\n            might correspond to when the anatomy was acquired after the EPI\n            data.\n\n            The default of 'third' was chosen to go a little farther into the\n            steady state data.\n\n            Note that this is done after removing any volumes in the initial\n            tcat operation.\n\n          * A special case is if POSN is the string MIN_OUTLIER, in which\n            case the volume with the minimum outlier fraction would be used.\n\n            Since anat and EPI alignment tends to work very well, the choice\n            of alignment base could even be independent of when the anatomy\n            was acquired, making MIN_OUTLIER a good choice.\n\n            Please see '3dvolreg -help' for more information.\n            See also -tcat_remove_first_trs, -volreg_base_ind and", "help_range": [166546, 167980]}, {"param": "-volreg_base_dset.", "line_start": 3526, "length": 2, "param_range": [167993, 168011], "help": "            -volreg_base_dset.", "help_range": [167981, 168011]}, {"param": "-volreg_base_dset", "line_start": 3528, "length": 20, "param_range": [168021, 168038], "help": "specify dset/sub-brick for volreg base\n\n                e.g. -volreg_base_dset subj10/vreg_base+orig'[0]'\n                e.g. -volreg_base_dset MIN_OUTLIER\n\n            This option allows the user to specify an external dataset for the\n            volreg base.  The user should apply sub-brick selection if the\n            dataset has more than one volume.\n\n            For example, one might align to a pre-magnetic steady state volume.\n\n            Note that unless -align_epi_ext_dset is also applied, this volume\n            will be used for anatomical to EPI alignment (assuming that is\n            being done at all).\n\n          * A special case is if DSET is the string MIN_OUTLIER, in which\n            case the volume with the minimum outlier fraction would be used.\n\n            See also -align_epi_ext_dset, -volreg_align_to and -volreg_base_ind.", "help_range": [168047, 168905]}, {"param": "-volreg_base_ind", "line_start": 3548, "length": 18, "param_range": [168915, 168931], "help": "specify run/sub-brick indices for base\n\n                e.g. -volreg_base_ind 10 123\n                default: 0 0\n\n            This option allows the user to specify exactly which dataset and\n            sub-brick to use as the base registration image.  Note that the\n            SUB index applies AFTER the removal of pre-steady state images.\n\n          * The RUN number is 1-based, matching the run list in the output\n            shell script.  The SUB index is 0-based, matching the sub-brick of\n            EPI time series #RUN.  Yes, one is 1-based, the other is 0-based.\n            Life is hard.\n\n            The user can apply only one of the -volreg_align_to and\n            -volreg_base_ind options.\n\n            See also -volreg_align_to, -tcat_remove_first_trs and", "help_range": [168942, 169718]}, {"param": "-volreg_base_dset.", "line_start": 3566, "length": 2, "param_range": [169731, 169749], "help": "            -volreg_base_dset.", "help_range": [167981, 168011]}, {"param": "-volreg_get_allcostX", "line_start": 3568, "length": 20, "param_range": [169759, 169779], "help": "        -volreg_get_allcostX yes/no : compute all anat/EPI costs\n\n                e.g. -volreg_get_allcostX no\n                default: yes\n\n            By default, given the final anatomical dataset (anat_final) and\n            the the final EPI volreg base (final_epi), this option can be used\n            to compute alignment costs between the two volumes across all cost\n            functions from 3dAllineate.  Effectively, it will add the following\n            to the proc script:\n\n                3dAllineate -base FINAL_EPI -input FINAL_ANAT -allcostX\n\n             The text output is stored in the file out.allcostX.txt.\n\n             This operation is informational only, to help evaluate alignment\n             costs across subjects.\n\n             Please see '3dAllineate -help' for more details.", "help_range": [169751, 170558]}, {"param": "-volreg_compute_tsnr", "line_start": 3588, "length": 14, "param_range": [170568, 170588], "help": "        -volreg_compute_tsnr yes/no : compute TSNR datasets from volreg output\n\n                e.g. -volreg_compute_tsnr yes\n                default: no\n\n            Use this option to compute a temporal signal to noise (TSNR)\n            dataset at the end of the volreg block.  Both the signal and noise\n            datasets are from the run 1 output, where the \"signal\" is the mean\n            and the \"noise\" is the detrended time series.\n\n            TSNR = average(signal) / stdev(noise)\n\n            See also -regress_compute_tsnr.", "help_range": [170560, 171099]}, {"param": "-volreg_interp", "line_start": 3602, "length": 8, "param_range": [171109, 171123], "help": "specify the interpolation method for volreg\n\n                e.g. -volreg_interp -quintic\n                e.g. -volreg_interp -Fourier\n                default: -cubic\n\n            Please see '3dvolreg -help' for more information.", "help_range": [171135, 171364]}, {"param": "-volreg_motsim", "line_start": 3610, "length": 13, "param_range": [171374, 171388], "help": "generate motion simulated time series\n\n            Use of this option will result in a 'motsim' (motion simulation)\n            time series dataset that is akin to an EPI dataset altered only\n            by motion and registration (no BOLD, no signal drift, etc).\n\n            This dataset can be used to generate regressors of no interest to\n            be used in the regression block.\n\n            rcr - note relevant options once they are in\n\n            Please see '@simulate_motion -help' for more information.", "help_range": [171400, 171916]}, {"param": "-volreg_opts_ms", "line_start": 3623, "length": 10, "param_range": [171926, 171941], "help": "        -volreg_opts_ms OPTS ... : specify extra options for @simulate_motion\n\n                e.g. -volreg_opts_ms -save_workdir\n\n            This option can be used to pass extra options directly to the\n            @simulate_motion command.\n\n            See also -volreg_motsim.\n            Please see '@simulate_motion -help' for more information.", "help_range": [171918, 172268]}, {"param": "-volreg_opts_vr", "line_start": 3633, "length": 11, "param_range": [172278, 172293], "help": "        -volreg_opts_vr OPTS ... : specify extra options for 3dvolreg\n\n                e.g. -volreg_opts_vr -twopass\n                e.g. -volreg_opts_vr -noclip -nomaxdisp\n\n            This option allows the user to add extra options to the 3dvolreg\n            command.  Note that only one -volreg_opts_vr should be applied,\n            which may be used for multiple 3dvolreg options.\n\n            Please see '3dvolreg -help' for more information.", "help_range": [172270, 172720]}, {"param": "-volreg_no_extent_mask", "line_start": 3644, "length": 30, "param_range": [172730, 172752], "help": "do not create and apply extents mask\n\n                default: apply extents mask\n\n            This option says not to create or apply the extents mask.\n\n            The extents mask:\n\n            When EPI data is transformed to the anatomical grid in either orig\n            or tlrc space (i.e. if -volreg_align_e2a or -volreg_tlrc_warp is\n            applied), then the complete EPI volume will only cover part of the\n            resulting volume space.  Worse than that, the coverage will vary\n            over time, as motion will alter the final transformation (remember\n            that volreg, EPI->anat and ->tlrc transformations are all combined,\n            to prevent multiple resampling steps).  The result is that edge\n            voxels will sometimes have valid data and sometimes not.\n\n            The extents mask is made from an all-1 dataset that is warped with\n            the same per-TR transformations as the EPI data.  The intersection\n            of the result is the extents mask, so that every voxel in the\n            extents mask has data at every time point.  Voxels that are not\n            are missing data from some or all TRs.\n\n            It is called the extents mask because it defines the 'bounding box'\n            of valid EPI data.  It is not quite a tiled box though, as motion\n            changes the location slightly, per TR.\n\n            See also -volreg_align_e2a, -volreg_tlrc_warp.\n            See also the 'extents' mask, in the \"MASKING NOTE\" section above.", "help_range": [172756, 174264]}, {"param": "-volreg_regress_per_run", "line_start": 3674, "length": 4, "param_range": [174274, 174297], "help": "regress motion parameters from each run\n\n            === This option has been replaced by -regress_motion_per_run. ===", "help_range": [174300, 174418]}, {"param": "-volreg_tlrc_adwarp", "line_start": 3678, "length": 20, "param_range": [174428, 174447], "help": "warp EPI to +tlrc space at end of volreg step\n\n                default: stay in +orig space\n\n            With this option, the EPI data will be warped to standard space\n            (via adwarp) at the end of the volreg processing block.  Further\n            processing through regression will be done in standard space.\n\n            This option is useful for applying a manual Talairach transform,\n            which does not work with -volreg_tlrc_warp.  To apply one from\n            @auto_tlrc, -volreg_tlrc_warp is recommended.\n\n            The resulting voxel grid is the minimum dimension, truncated to 3\n            significant bits.  See -volreg_warp_dxyz for details.\n\n            Note: this step requires a transformed anatomy, which can come from\n            the -tlrc_anat option or from -copy_anat importing an existing one.\n\n            Please see 'WARP TO TLRC NOTE' above, for additional details.\n            See also -volreg_tlrc_warp, -volreg_warp_dxyz, -tlrc_anat,", "help_range": [174454, 175436]}, {"param": "-copy_anat.", "line_start": 3698, "length": 2, "param_range": [175449, 175460], "help": "            -copy_anat.", "help_range": [175437, 175460]}, {"param": "-volreg_tlrc_warp", "line_start": 3700, "length": 29, "param_range": [175470, 175487], "help": "warp EPI to +tlrc space at volreg step\n\n                default: stay in +orig space\n\n            With this option, the EPI data will be warped to standard space\n            in the volreg processing block.  All further processing through\n            regression will be done in standard space.\n\n            Warping is done with volreg to apply both the volreg and tlrc\n            transformations in a single step (so a single interpolation of the\n            EPI data).  The volreg transformations (for each volume) are stored\n            and multiplied by the +tlrc transformation, while the volume\n            registered EPI data is promptly ignored.\n\n            The volreg/tlrc (affine or non-linear) transformation is then\n            applied as a single concatenated warp to the unregistered data.\n\n            Note that the transformation concatenation is not possible when\n            using the 12-piece manual transformation (see -volreg_tlrc_adwarp\n            for details).\n\n            The resulting voxel grid is the minimum dimension, truncated to 3\n            significant bits.  See -volreg_warp_dxyz for details.\n\n            Note: this step requires a transformed anatomy, which can come from\n            the -tlrc_anat option or from -copy_anat importing an existing one.\n\n            Please see 'WARP TO TLRC NOTE' above, for additional details.\n            See also -volreg_tlrc_adwarp, -volreg_warp_dxyz, -tlrc_anat,", "help_range": [175496, 176934]}, {"param": "-copy_anat.", "line_start": 3729, "length": 2, "param_range": [176947, 176958], "help": "            -copy_anat.", "help_range": [175437, 175460]}, {"param": "-volreg_warp_dxyz", "line_start": 3731, "length": 34, "param_range": [176968, 176985], "help": "grid dimensions for _align_e2a or _tlrc_warp\n\n                e.g. -volreg_warp_dxyz 3.5\n                default: min dim truncated to 3 significant bits\n                         (see description, below)\n\n            This option allows the user to specify the grid size for output\n            datasets from the -volreg_tlrc_warp and -volreg_align_e2a options.\n            In either case, the output grid will be isotropic voxels (cubes).\n\n            By default, DXYZ is the minimum input dimension, truncated to\n            3 significant bits (for integers, starts affecting them at 9, as\n            9 requires 4 bits to represent).\n\n            Some examples:\n                ----------------------------  (integer range, so >= 4)\n                8.00   ...  9.99   --> 8.0\n                ...\n                4.00   ...  4.99   --> 4.0\n                ----------------------------  (3 significant bits)\n                2.50   ...  2.99   --> 2.5\n                2.00   ...  2.49   --> 2.0\n                1.75   ...  1.99   --> 1.75\n                1.50   ...  1.74   --> 1.5\n                1.25   ...  1.49   --> 1.25\n                1.00   ...  1.24   --> 1.0\n                0.875  ...  0.99   --> 0.875\n                0.75   ...  0.874  --> 0.75\n                0.625  ...  0.74   --> 0.625\n                0.50   ...  0.624  --> 0.50\n                0.4375 ...  0.49   --> 0.4375\n                0.375  ...  0.4374 --> 0.375\n                ...", "help_range": [176994, 178449]}, {"param": "-volreg_zpad", "line_start": 3765, "length": 8, "param_range": [178459, 178471], "help": "specify number of slices for -zpad\n\n                e.g. -volreg_zpad 4\n                default: -volreg_zpad 1\n\n            This option allows the user to specify the number of slices applied\n            via the -zpad option to 3dvolreg.", "help_range": [178485, 178723]}, {"param": "-surf_anat", "line_start": 3773, "length": 37, "param_range": [178733, 178743], "help": "specify surface volume dataset\n\n                e.g. -surf_anat SUMA/sb23_surf_SurfVol+orig\n\n            This option is required in order to do surface-based analysis.\n\n            This volumetric dataset should be the one used for generation of\n            the surface (and therefore should be in perfect alignment).  It may\n            be output by the surface generation software.\n\n            Unless specified by the user, the processing script will register\n            this anatomy with the current anatomy.\n\n            Use -surf_anat_aligned if the surf_anat is already aligned with the\n            current experiment.\n\n            Use '-surf_anat_has_skull no' if the surf_anat has already been\n            skull stripped.\n\n            Please see '@SUMA_AlignToExperiment -help' for more details.\n            See also -surf_anat_aligned, -surf_anat_has_skull.\n            See example #8 for typical usage.\n\n        -surf_spec spec1 [spec2]: specify surface specificatin file(s)\n\n                e.g. -surf_spec SUMA/sb23_?h_141_std.spec\n\n            Use this option to provide either 1 or 2 spec files for surface\n            analysis.  Each file must have lh or rh in the name (to encode\n            the hemisphere), and that can be their only difference.  So if\n            the files do not have such a naming pattern, they should probably\n            be copied to new files that do.  For example, consider the spec\n            files included with the AFNI_data4 sample data:\n\n                SUMA/sb23_lh_141_std.spec\n                SUMA/sb23_rh_141_std.spec", "help_range": [178759, 180330]}, {"param": "-surf_A", "line_start": 3810, "length": 9, "param_range": [180340, 180347], "help": "specify first surface for mapping\n\n                e.g. -surf_A smoothwm\n                default: -surf_A smoothwm\n\n            This option allows the user to specify the first (usually inner)\n            surface for use when mapping from the volume and for blurring.\n            If the option is not given, the smoothwm surface will be assumed.", "help_range": [180366, 180711]}, {"param": "-surf_B", "line_start": 3819, "length": 9, "param_range": [180721, 180728], "help": "specify second surface for mapping\n\n                e.g. -surf_B pial\n                default: -surf_B pial\n\n            This option allows the user to specify the second (usually outer)\n            surface for use when mapping from the volume (not for blurring).\n            If the option is not given, the pial surface will be assumed.", "help_range": [180747, 181084]}, {"param": "-surf_blur_fwhm", "line_start": 3828, "length": 4, "param_range": [181094, 181109], "help": " NO LONGER VALID\n\n            Please use -blur_size, instead.", "help_range": [181120, 181181]}, {"param": "-blur_filter", "line_start": 3832, "length": 13, "param_range": [181191, 181203], "help": "specify 3dmerge filter option\n\n                e.g. -blur_filter -1blur_rms\n                default: -1blur_fwhm\n\n            This option allows the user to specify the filter option from\n            3dmerge.  Note that only the filter option is set here, not the\n            filter size.  The two parts were separated so that users might\n            generally worry only about the filter size.\n\n            Please see '3dmerge -help' for more information.\n            See also -blur_size.", "help_range": [181217, 181706]}, {"param": "-blur_in_automask", "line_start": 3845, "length": 13, "param_range": [181716, 181733], "help": "apply 3dBlurInMask -automask\n\n            This option forces use of 3dBlurInMask -automask, regardless of\n            whether other masks exist and are being applied.\n\n            Note that one would not want to apply -automask via -blur_opts_BIM,\n            as that might result in failure because of multiple -mask options.\n\n            Note that -blur_in_automask implies '-blur_in_mask yes'.\n\n            Please see '3dBlurInMask -help' for more information.\n            See also -blur_in_mask, -blur_opts_BIM.", "help_range": [181742, 182257]}, {"param": "-blur_in_mask", "line_start": 3858, "length": 18, "param_range": [182267, 182280], "help": "        -blur_in_mask yes/no    : specify whether to restrict blur to a mask\n\n                e.g. -blur_in_mask yes\n                default: no\n\n            This option allows the user to specify whether to use 3dBlurInMask\n            instead of 3dmerge for blurring.\n\n            Note that the algorithms are a little different, and 3dmerge comes\n            out a little more blurred.\n\n            Note that 3dBlurInMask uses only FWHM kernel size units, so the\n            -blur_filter should be either -1blur_fwhm or -FWHM.\n\n            Please see '3dBlurInMask -help' for more information.\n            Please see '3dmerge -help' for more information.\n            See also -blur_filter.", "help_range": [182259, 182951]}, {"param": "-blur_opts_BIM", "line_start": 3876, "length": 13, "param_range": [182961, 182975], "help": "        -blur_opts_BIM OPTS ...  : specify extra options for 3dBlurInMask\n\n                e.g. -blur_opts_BIM -automask\n\n            This option allows the user to add extra options to the 3dBlurInMask\n            command.  Only one -blur_opts_BIM should be applied, which may be\n            used for multiple 3dBlurInMask options.\n\n            This option is only useful when '-blur_in_mask yes' is applied.\n\n            Please see '3dBlurInMask -help' for more information.\n            See also -blur_in_mask.", "help_range": [182953, 183465]}, {"param": "-blur_opts_merge", "line_start": 3889, "length": 10, "param_range": [183475, 183491], "help": "        -blur_opts_merge OPTS ... : specify extra options for 3dmerge\n\n                e.g. -blur_opts_merge -2clip -20 50\n\n            This option allows the user to add extra options to the 3dmerge\n            command.  Note that only one -blur_opts_merge should be applied,\n            which may be used for multiple 3dmerge options.\n\n            Please see '3dmerge -help' for more information.", "help_range": [183467, 183865]}, {"param": "-blur_size", "line_start": 3899, "length": 28, "param_range": [183875, 183885], "help": "specify the size, in millimeters\n\n                e.g. -blur_size 6.0\n                default: 4\n\n            This option allows the user to specify the size of the blur used\n            by 3dmerge (or another applied smoothing program).  It is applied\n            as the 'bmm' parameter in the filter option (such as -1blur_fwhm)\n            in 3dmerge.\n\n            Note the relationship between blur sizes, as used in 3dmerge:\n\n                sigma = 0.57735027 * rms = 0.42466090 * fwhm\n                (implying fwhm = 1.359556 * rms)\n\n            Programs 3dmerge and 3dBlurInMask apply -blur_size as an additional\n            gaussian blur.  Therefore smoothing estimates should be computed\n            per subject for the correction for multiple comparisons.\n\n            Programs 3dBlurToFWHM and SurfSmooth apply -blur_size as the\n            resulting blur, and so do not requre blur estimation.\n\n            Please see '3dmerge -help'      for more information.\n            Please see '3dBlurInMask -help' for more information.\n            Please see '3dBlurToFWHM -help' for more information.\n            Please see 'SurfSmooth -help'   for more information.\n            See also -blur_filter.", "help_range": [183901, 185108]}, {"param": "-blur_to_fwhm", "line_start": 3927, "length": 17, "param_range": [185118, 185131], "help": "blur TO the blur size (not add a blur size)\n\n            This option changes the program used to blur the data.  Instead of\n            using 3dmerge, this applies 3dBlurToFWHM.  So instead of adding a\n            blur of size -blur_size (with 3dmerge), the data is blurred TO the\n            FWHM of the -blur_size.\n\n            Note that 3dBlurToFWHM should be run with a mask.  So either:\n                o  put the 'mask' block before the 'blur' block, or\n                o  use -blur_in_automask\n            It is not appropriate to include non-brain in the blur estimate.\n\n            Note that extra options can be added via -blur_opts_B2FW.\n\n            Please see '3dBlurToFWHM -help' for more information.\n            See also -blur_size, -blur_in_automask, -blur_opts_B2FW.", "help_range": [185144, 185928]}, {"param": "-blur_opts_B2FW", "line_start": 3944, "length": 10, "param_range": [185938, 185953], "help": "        -blur_opts_B2FW OPTS ... : specify extra options for 3dBlurToFWHM\n\n                e.g. -blur_opts_B2FW -rate 0.2 -temper\n\n            This allows the user to add extra options to the 3dBlurToFWHM\n            command.  Note that only one -blur_opts_B2FW should be applied,\n            which may be used for multiple 3dBlurToFWHM options.\n\n            Please see '3dBlurToFWHM -help' for more information.", "help_range": [185930, 186342]}, {"param": "-mask_apply", "line_start": 3954, "length": 23, "param_range": [186352, 186363], "help": "specify which mask to apply in regression\n\n                e.g. -mask_apply group\n\n            If possible, masks will be made for the EPI data, the subject\n            anatomy, the group anatomy and EPI warp extents.  This option is\n            used to specify which of those masks to apply to the regression.\n\n            Valid choices: epi, anat, group, extents.\n\n            A subject 'anat' mask will be created if the EPI anat anatomy are\n            aligned, or if the EPI data is warped to standard space via the\n            anat transformation.  In any case, a skull-stripped anat will exist.\n\n            A 'group' anat mask will be created if the 'tlrc' block is used\n            (via the -blocks or -tlrc_anat options).  In such a case, the anat\n            template will be made into a binary mask.\n\n            This option makes -regress_apply_mask obsolete.\n\n            See \"MASKING NOTE\" and \"DEFAULTS\" for details.\n            See also -blocks.", "help_range": [186378, 187340]}, {"param": "-mask_dilate", "line_start": 3977, "length": 16, "param_range": [187350, 187362], "help": "specify the automask dilation\n\n                e.g. -mask_dilate 3\n                default: 1\n\n            By default, the masks generated from the EPI data are dilated by\n            1 step (voxel), via the -dilate option in 3dAutomask.  With this\n            option, the user may specify the dilation.  Valid integers must\n            be at least zero.\n\n            Note that 3dAutomask dilation is a little different from the\n            natural voxel-neighbor dilation.\n\n            Please see '3dAutomask -help' for more information.\n            See also -mask_type.", "help_range": [187376, 187947]}, {"param": "-mask_epi_anat", "line_start": 3993, "length": 14, "param_range": [187957, 187971], "help": "        -mask_epi_anat yes/no : apply epi_anat mask in place of EPI mask\n\n                e.g. -mask_epi_anat yes\n\n            An EPI mask might be applied to the data either for simple\n            computations (e.g. global brain correlation, GCOR), or actually\n            applied to the EPI data.  The EPI mask $full_mask is used for most\n            such computations, by default.\n\n            The mask_epi_anat dataset is an intersection of full_mask and\n            mask_anat, and might be better suited to such computations.\n\n            Use this option to apply mask_epi_anat in place of full_mask.", "help_range": [187949, 188554]}, {"param": "-mask_import", "line_start": 4007, "length": 23, "param_range": [188564, 188576], "help": "import a final grid mask with the given label\n\n                e.g. -mask_import Tvent template_ventricle_3mm+tlrc\n\n            Use this option to import a mask that is aligned with the final\n            EPI data _and_ is on the final grid.\n\n                o  this might be based on the group template\n                o  this should already be resampled appropriately\n                o  no warping or resampling will be done to this dataset\n\n            This mask can be applied via LABEL as other masks, using options\n            like: -regress_ROI, -regress_ROI_PC, -regress_make_corr_vols,\n                  -regress_anaticor_label, -mask_intersect, -mask_union.\n\n            For example, one might import a ventricle mask from the template,\n            intersect it with the subject specific CSFe (eroded CSF) mask,\n            and possibly take the union with WMe (eroded white matter), before\n            using the result for principle component regression, as in:\n\n                -mask_import Tvent template_ventricle_3mm+tlrc \\\n                -mask_intersect Svent CSFe Tvent               \\\n                -mask_union WM_vent Svent WMe                  \\", "help_range": [188590, 189757]}, {"param": "-regress_ROI", "line_start": 4030, "length": 5, "param_range": [189774, 189786], "help": "                -regress_ROI_PC WM_vent 3                      \\\n\n            See also -regress_ROI, -regress_ROI_PC, -regress_make_corr_vols,\n                     -regress_anaticor_label, -mask_intersect, -mask_union.", "help_range": [189758, 189976]}, {"param": "-mask_intersect", "line_start": 4035, "length": 13, "param_range": [189986, 190001], "help": "intersect 2 masks\n\n                e.g. -mask_intersect Svent CSFe Tvent\n\n            Use this option to intersect 2 known masks to create a new mask.\n            NEW_LABEL will be the label of the result, while MASK_A and MASK_B\n            should be labels for existing masks.\n\n            One could use this to intersect a template ventricle mask with each\n            subject's specific CSFe (eroded CSF) mask from 3dSeg, for example.\n\n            See -mask_import for more details.", "help_range": [190028, 190514]}, {"param": "-mask_union", "line_start": 4048, "length": 13, "param_range": [190524, 190535], "help": "take union of 2 masks\n\n                e.g. -mask_union WM_vent Svent WMe\n\n            Use this option to take the union of 2 known masks to create a new\n            mask.  NEW_LABEL will be the label of the result, while MASK_A and\n            MASK_B should be labels for existing masks.\n\n            One could use this to create union of CSFe and WMe for principle\n            component regression, for example.\n\n            See -mask_import for more details.", "help_range": [190562, 191023]}, {"param": "-mask_rm_segsy", "line_start": 4061, "length": 14, "param_range": [191033, 191047], "help": "        -mask_rm_segsy Y/N  : choose whether to delete the Segsy directory\n\n                e.g. -mask_rm_segsy no\n                default: yes\n\n            This option is a companion to -mask_segment_anat.\n\n            In the case of running 3dSeg to segment the anatomy, a resulting\n            Segsy directory is created.  Since the main result is a Classes\n            dataset, and to save disk space, the Segsy directory is removed\n            by default.  Use this option to preserve it.\n\n            See also -mask_segment_anat.", "help_range": [191025, 191560]}, {"param": "-mask_segment_anat", "line_start": 4075, "length": 31, "param_range": [191570, 191588], "help": "        -mask_segment_anat Y/N  : choose whether to segment anatomy\n\n                e.g. -mask_segment_anat yes\n                default: no (if anat_final is skull-stripped)\n\n            This option controls whether 3dSeg is run to segment the anatomical\n            dataset.  Such a segmentation would then be resampled to match the\n            grid of the EPI data.\n\n            When this is run, 3dSeg creates the Classes dataset, which is a\n            composition mask of the GM/WM/CSF (gray matter, white matter and\n            cerebral spinal fluid) regions.  Then 3dresample is used to create\n            Classes_resam, the same mask but at the resolution of the EPI.\n\n            Such a dataset might have multiple uses, such as tissue-based\n            regression.  Note that for such a use, the ROI time series should\n            come from the volreg data, before any blur.\n\n          * Mask labels created by -mask_segment_anat and -mask_segment_erode\n            can be applied with -regress_ROI and -regress_ROI_PC.\n\n          * The CSF mask is of ALL CSF (not just in the ventricles), and is\n            therefore not very appropriate to use with tissue-based regression.\n\n            Consider use of -anat_uniform_method along with this option.\n\n            Please see '3dSeg -help' for more information.\n            Please see '3dUnifize -help' for more information.\n            See also -mask_rm_segsy, -anat_uniform_method -mask_segment_erode,\n             and -regress_ROI, -regress_ROI_PC.", "help_range": [191562, 193073]}, {"param": "-mask_segment_erode", "line_start": 4106, "length": 14, "param_range": [193083, 193102], "help": "        -mask_segment_erode Y/N\n\n                e.g. -mask_segment_erode Yes\n                default: yes (if -regress_ROI or -regress_anaticor)\n\n            This option is a companion to -mask_segment_anat.\n\n            Anatomical segmentation is used to create GM (gray matter), WM\n            (white matter) and CSF masks.  When the _erode option is applied,\n            eroded versions of those masks are created via 3dmask_tool.\n\n            See also -mask_segment_anat, -regress_anaticor.\n            Please see '3dmask_tool -help' for more information.", "help_range": [193075, 193635]}, {"param": "-mask_test_overlap", "line_start": 4120, "length": 13, "param_range": [193645, 193663], "help": "        -mask_test_overlap Y/N  : choose whether to test anat/EPI mask overlap\n\n                e.g. -mask_test_overlap No\n                default: Yes\n\n            If the subject anatomy and EPI masks are computed, then the default\n            operation is to run 3dABoverlap to evaluate the overlap between the\n            two masks.  Output is saved in a text file.\n\n            This option allows one to disable such functionality.\n\n            Please see '3dABoverlap -help' for more information.", "help_range": [193637, 194138]}, {"param": "-mask_type", "line_start": 4133, "length": 15, "param_range": [194148, 194158], "help": "specify 'union' or 'intersection' mask type\n\n                e.g. -mask_type intersection\n                default: union\n\n            This option is used to specify whether the mask applied to the\n            analysis is the union of masks from each run, or the intersection.\n            The only valid values for TYPE are 'union' and 'intersection'.\n\n            This is not how to specify whether a mask is created, that is\n            done via the 'mask' block with the '-blocks' option.\n\n            Please see '3dAutomask -help', '3dMean -help' or '3dcalc -help'.\n            See also -mask_dilate, -blocks.", "help_range": [194174, 194786]}, {"param": "-combine_method", "line_start": 4148, "length": 37, "param_range": [194796, 194811], "help": "specify method for combining echoes\n\n                e.g. -combine_method OC\n                default: OC\n\n            When using the 'combine' block to combine echoes (for each run),\n            this option can be used to specify the method used.   Methods:\n\n                mean             : simple mean of echoes\n                OC               : optimally combined (via @compute_OC_weights)\n                                   (current default is OC_A)\n                OC_A             : original log(mean()) regression method\n                OC_B             : newer log() time series regression method\n                                   (there is little difference between OC_A\n                                   and OC_B)\n                OC_tedort        : OC, and pass tedana orts to regression\n                tedana           : run tedana.py, using output dn_ts_OC.nii\n                tedana_OC        : run tedana.py, using output ts_OC.nii\n                                   (i.e. use tedana.py for optimally combined)\n                tedana_OC_tedort : tedana_OC, and include tedana orts\n\n            The OC/OC_A combine method is from Posse et. al., 1999, and then\n            applied by Kundu et. al., 2011 and presented by Javier in a 2017\n            summer course.\n\n            The 'tedort' methods are applied using @extract_meica_ortvec,\n            which projects the 'good' MEICA components out of the 'bad' ones,\n            and saves those as regressors to be applied later.  Otherwise, some\n            of the 'good' components are removed with the 'bad.  The tedort\n            method can be applied with either AFNI OC or tedana OC (meaning\n            the respective OC method would be applied to combine the echoes,\n            and the tedort components will be passed on to the regress block).\n\n            Please see '@compute_OC_weights -help' for more information.\n            Please see '@extract_meica_ortvec -help' for more information.\n            See also -combine_tedana_path.", "help_range": [194822, 196837]}, {"param": "-combine_opts_tedana", "line_start": 4185, "length": 9, "param_range": [196847, 196867], "help": "        -combine_opts_tedana OPT OPT ... : specify extra options for tedana.py\n\n                e.g. -combine_opts_tedana --sourceTEs=-1 --kdaw=10 --rdaw=1\n\n            Use this option to pass extra options through to tedana.py.\n            This applies to any tedana-based -combine_method.\n\n            See also -combine_method.", "help_range": [196839, 197168]}, {"param": "-combine_opts_tedwrap", "line_start": 4194, "length": 7, "param_range": [197178, 197199], "help": "        -combine_opts_tedwrap OPT OPT ... : pass options to tedana_wrapper.py\n\n                e.g. -combine_opts_tedwrap -tedana_is_exec\n\n            Use this option to pass extra options to tedana_wrapper.py.\n            This applies to any tedana-based -combine_method.", "help_range": [197170, 197442]}, {"param": "-combine_tedana_path", "line_start": 4201, "length": 12, "param_range": [197452, 197472], "help": "specify path to tedana.py\n\n                e.g. -combine_tedana_path ~/testbin/meica.libs/tedana.py\n                default: from under afni binaries directory\n\n            If one wishes to use a version of tedana.py other than what comes\n            with AFNI, this option allows one to specify that file.\n\n            This applies to any tedana-based -combine_method.\n\n            See also -combine_method.", "help_range": [197480, 197888]}, {"param": "-scale_max_val", "line_start": 4213, "length": 21, "param_range": [197898, 197912], "help": "specify the maximum value for scaled data\n\n                e.g. -scale_max_val 1000\n                default 200\n\n            The scale step multiples the time series for each voxel by a\n            scalar so that the mean for that particular run is 100 (allowing\n            interpretation of EPI values as a percentage of the mean).\n\n            Values of 200 represent a 100% change above the mean, and so can\n            probably be considered garbage (or the voxel can be considered\n            non-brain).  The output values are limited so as not to sacrifice\n            the precision of the values of short datasets.  Note that in a\n            short (2-byte integer) dataset, a large range of values means\n            bits of accuracy are lost for the representation.\n\n            No max will be applied if MAX is <= 100.\n\n            Please see 'DATASET TYPES' in the output of '3dcalc -help'.\n            See also -scale_no_max.", "help_range": [197924, 198862]}, {"param": "-scale_no_max", "line_start": 4234, "length": 10, "param_range": [198872, 198885], "help": "do not apply a limit to the scaled values\n\n            The default limit for scaled data is 200.  Use of this option will\n            remove any limit from being applied.\n\n            A limit on the scaled data is highly encouraged when working with\n            'short' integer data, especially when not applying a mask.\n\n            See also -scale_max_val.", "help_range": [198898, 199256]}, {"param": "-regress_3dD_stop", "line_start": 4244, "length": 8, "param_range": [199266, 199283], "help": "3dDeconvolve should stop after X-matrix gen\n\n            Use this option to tell 3dDeconvolve to stop after generating the\n            X-matrix (via -x1D_stop).  This is useful if the user only wishes\n            to run the regression through 3dREMLfit.\n\n            See also -regress_reml_exec.", "help_range": [199292, 199587]}, {"param": "-regress_anaticor", "line_start": 4252, "length": 28, "param_range": [199597, 199614], "help": "generate errts using ANATICOR method\n\n            Apply the ANATICOR method of HJ Jo, regressing out the WMeLocal\n            time series, which varies across voxels.\n\n            WMeLocal is the average time series from all voxels within 45 mm\n            which are in the eroded white matter mask.\n\n            The script will run the standard regression via 3dDeconvolve (or\n            stop after setting up the X-matrix, if the user says to), and use\n            that X-matrix, possibly censored, in 3dTproject.  The WMeLocal time\n            series is applied along with the X-matrix to get the result.\n\n            Note that other 4-D time series might be regressed out via the\n            3dTproject step, as well.\n\n            In the case of task-based ANATICOR, -regress_reml_exec is required,\n            which uses 3dREMLfit to regress the voxel-wise ANATICOR regressors.\n\n            This option implies -mask_segment_anat and -mask_segment_erode.\n\n          * Consider use of -regress_anaticor_fast, instead.\n\n            Please see \"@ANATICOR -help\" for more detail, including the paper\n            reference for the method.\n            See also -mask_segment_anat, -mask_segment_erode, -regress_3dD_stop.\n            See also -regress_reml_exec.", "help_range": [199623, 200884]}, {"param": "-regress_anaticor_label", "line_start": 4280, "length": 9, "param_range": [200894, 200917], "help": "specify LABEL for ANATICOR ROI\n\n            To go with either -regress_anaticor or -regress_anaticor_fast,\n            this option is used the specifiy an alternate label of an ROI\n            mask to be used in the ANATICOR step.  The default LABEL is WMe\n            (eroded white matter from 3dSeg).\n\n            When this option is included, it is up to the user to make sure\n            afni_proc.py has such a label, either by including options:", "help_range": [200926, 201377]}, {"param": "-mask_segment_anat", "line_start": 4289, "length": 1, "param_range": [201394, 201412], "help": "                -mask_segment_anat (and possibly -mask_segment_erode),", "help_range": [201378, 201448]}, {"param": "-regress_ROI", "line_start": 4290, "length": 5, "param_range": [201465, 201477], "help": "                -regress_ROI_PC, -regress_ROI, or -anat_follower_ROI.\n\n            Any known label made via those options may be used.\n\n            See also -mask_segment_anat, -mask_segment_erode, -regress_ROI_PC,", "help_range": [201449, 201663]}, {"param": "-anat_follower_ROI.", "line_start": 4295, "length": 2, "param_range": [201680, 201699], "help": "                -anat_follower_ROI.", "help_range": [201664, 201699]}, {"param": "-regress_anaticor_radius", "line_start": 4297, "length": 14, "param_range": [201709, 201733], "help": "specify RADIUS for 3dLocalstat\n\n            To go with -regress_anaticor, use this option to specify the radius\n            of spheres within which local white matter is averaged.  A small\n            radius means the white matter is more local.  It is also faster.\n\n            If no white matter is found within the specified distance of some\n            voxel, the effect is that ANATICOR will simply not happen at that\n            voxel.  That is a reasonable \"failure\" case, in that it says there\n            is simply no white matter close enough to regress out (again, at\n            the given voxel).\n\n            See also -regress_anaticor.", "help_range": [201743, 202392]}, {"param": "-regress_anaticor_fast", "line_start": 4311, "length": 30, "param_range": [202402, 202424], "help": "generate errts using fast ANATICOR method\n\n            This applies basically the same method as with -regress_anaticor,\n            above.  While -regress_anaticor creates WMeLocal dataset by\n            getting the average white matter voxel within a fixed radius, the\n            'fast' method computes it by instead integrating the white matter\n            over a gaussian curve.\n\n            There some basic effects of using the 'fast' method:\n\n                1. Using a Gaussian curve to compute each voxel-wise regressor\n                   gives more weight to the white matter that is closest to\n                   each given voxel.  The FWHM of this 3D kernel is specified\n                   by -regress_anaticor_fwhm, with a default of 30 mm.\n\n                2. If there is no close white matter (e.g. due to a poor\n                   segmentation), the Gaussian curve will likely find white\n                   matter far away, instead of creating an empty regressor.\n\n                3. This is quite a bit faster, because it is done by creating\n                   a time series of all desired white matter voxels, blurring\n                   it, and then just regressing out that dataset.  The blur\n                   operation is much faster than a localstat one.\n\n            Please see \"@ANATICOR -help\" for more detail, including the paper\n            reference for the method.\n            See also -regress_anaticor_fwhm/\n            See also -mask_segment_anat, -mask_segment_erode, -regress_3dD_stop.\n            See also -regress_anaticor.", "help_range": [202428, 203990]}, {"param": "-regress_anaticor_fwhm", "line_start": 4341, "length": 19, "param_range": [204000, 204022], "help": "specify FWHM for 'fast' ANATICOR, in mm\n\n                e.g.     -regress_anaticor_fwhm 20\n                default: -regress_anaticor_fwhm 30\n\n            This option applies to -regress_anaticor_fast.\n\n            The 'fast' ANATICOR method blurs the time series of desired white\n            matter voxels using a Gaussian kernel with the given FWHM (full\n            width at half maximum).\n\n            To understand the FWHM, note that it is essentially the diameter of\n            a sphere where the contribution from points at that distance\n            (FWHM/2) contribute half as much as the center point.  For example,\n            if FWHM=10mm, then any voxel at a distance of 5 mm would contribute\n            half as much as a voxel at the center of the kernel.\n\n            See also -regress_anaticor_fast.", "help_range": [204031, 204849]}, {"param": "-regress_apply_mask", "line_start": 4360, "length": 11, "param_range": [204859, 204878], "help": "apply the mask during scaling and regression\n\n            By default, any created union mask is not applied to the analysis.\n            Use this option to apply it.\n\n         ** This option is essentially obsolete.  Please consider -mask_apply\n            as a preferable option to choose which mask to apply.\n\n            See \"MASKING NOTE\" and \"DEFAULTS\" for details.\n            See also -blocks, -mask_apply.", "help_range": [204885, 205298]}, {"param": "-regress_apply_mot_types", "line_start": 4371, "length": 31, "param_range": [205308, 205332], "help": "        -regress_apply_mot_types TYPE1 ... : specify motion regressors\n\n                e.g. -regress_apply_mot_types basic\n                e.g. -regress_apply_mot_types deriv\n                e.g. -regress_apply_mot_types demean deriv\n                default: demean\n\n            By default, the motion parameters from 3dvolreg are applied in the\n            regression, but after first removing the mean, per run.  This is\n            the application of the 'demean' regressors.\n\n            This option gives the ability to choose a combination of:\n\n                basic:  dfile_rall.1D - the parameters straight from 3dvolreg\n                        (or an external motion file, see -regress_motion_file)\n                demean: 'basic' params with the mean removed, per run\n                deriv:  per-run derivative of 'basic' params (de-meaned)\n\n         ** Note that basic and demean cannot both be used, as they would cause\n            multi-collinearity with the constant drift parameters.\n\n         ** Note also that basic and demean will give the same results, except\n            for the betas of the constant drift parameters (and subject to\n            computational precision).\n\n         ** A small side effect of de-meaning motion parameters is that the\n            constant drift terms should evaluate to the mean baseline.\n\n            See also -regress_motion_file, -regress_no_motion_demean,\n            -regress_no_motion_deriv, -regress_no_motion.", "help_range": [205300, 206769]}, {"param": "-regress_apply_ricor", "line_start": 4402, "length": 11, "param_range": [206779, 206799], "help": "        -regress_apply_ricor yes/no : apply ricor regs in final regression\n\n                e.g.     -regress_apply_ricor yes\n                default: no\n\n            This is from a change in the default behavior 30 Jan 2012.  Prior\n            to then, the 13 (?) ricor regressors from slice 0 would be applied\n            in the final regression (mostly accounting for degrees of freedom).\n            But since resting state analysis relies on a subsequent correlation\n            analysis, it seems cleaner not to regress them (a second time).", "help_range": [206771, 207318]}, {"param": "-regress_bandpass", "line_start": 4413, "length": 37, "param_range": [207328, 207345], "help": "bandpass the frequency range\n\n                e.g.  -regress_bandpass 0.01 0.1\n\n            This option is intended for use in resting state analysis.\n\n            Use this option to perform bandpass filtering during the linear\n            regression.  While such an operation is slow (much slower than the\n            FFT using 3dBandpass), doing it during the regression allows one to\n            perform (e.g. motion) censoring at the same time.\n\n            This option has a similar effect to running 3dBandpass, e.g. the\n            example of '-regress_bandpass 0.01 0.1' is akin to running:\n\n                3dBandpass -ort motion.1D -band 0.01 0.1\n\n            except that it is done in 3dDeconvolve using linear regression.\n            And censoring is easy in the context of regression.\n\n            Note that the Nyquist frequency is 0.5/TR.  That means that if the\n            TR were >= 5 seconds, there would be no frequencies within the band\n            range of 0.01 to 0.1 to filter.  So there is no point to such an\n            operation.\n\n            On the flip side, if the TR is 1.0 second or shorter, the range of\n            0.01 to 0.1 would remove about 80% of the degrees of freedom (since\n            everything above 0.1 is filtered/removed, up through 0.5).  This\n            might result in a model that is overfit, where there are almost as\n            many (or worse, more) regressors than time points to fit.\n\n            So a 0.01 to 0.1 bandpass filter might make the most sense for a\n            TR in [2.0, 3.0], or so.\n\n            A different filter range would affect this, of course.\n\n            See also -regress_censor_motion.", "help_range": [207359, 209031]}, {"param": "-regress_basis", "line_start": 4450, "length": 22, "param_range": [209041, 209055], "help": "specify the regression basis function\n\n                e.g. -regress_basis 'BLOCK(4,1)'\n                e.g. -regress_basis 'BLOCK(5)'\n                e.g. -regress_basis 'TENT(0,14,8)'\n                default: GAM\n\n            This option is used to set the basis function used by 3dDeconvolve\n            in the regression step.  This basis function will be applied to\n            all user-supplied regressors (please let me know if there is need\n            to apply different basis functions to different regressors).\n\n         ** Note that use of dmBLOCK requires -stim_times_AM1 (or AM2).  So\n            consider option -regress_stim_types.\n\n         ** If using -regress_stim_types 'file' for a particular regressor,\n            the basis function will be ignored.  In such a case, it is safest\n            to use 'NONE' for the corresponding basis function.\n\n            Please see '3dDeconvolve -help' for more information, or the link:\n                https://afni.nimh.nih.gov/afni/doc/misc/3dDeconvolveSummer2004\n            See also -regress_basis_normall, -regress_stim_times,", "help_range": [209067, 210158]}, {"param": "-regress_stim_types", "line_start": 4472, "length": 2, "param_range": [210180, 210199], "help": "                     -regress_stim_types, -regress_basis_multi.", "help_range": [210159, 210222]}, {"param": "-regress_basis_multi", "line_start": 4474, "length": 12, "param_range": [210232, 210252], "help": "        -regress_basis_multi BASIS BASIS .. : specify multiple basis functions\n\n                e.g. -regress_basis_multi 'BLOCK(30,1)' 'TENT(0,45,16)' \\\n                                          'BLOCK(30,1)' dmUBLOCK\n\n            In the case that basis functions vary across stim classes, use\n            this option to list a basis function for each class.  The given\n            basis functions should correspond to the listed -regress_stim_times\n            files, just as the -regress_stim_labels entries do.\n\n            See also -regress_basis.", "help_range": [210224, 210776]}, {"param": "-regress_basis_normall", "line_start": 4486, "length": 12, "param_range": [210786, 210808], "help": "specify the magnitude of basis functions\n\n                e.g. -regress_basis_normall 1.0\n\n            This option is used to set the '-basis_normall' parameter in\n            3dDeconvolve.  It specifies the height of each basis function.\n\n            For the example basis functions, -basis_normall is not recommended.\n\n            Please see '3dDeconvolve -help' for more information.\n            See also -regress_basis.", "help_range": [210816, 211239]}, {"param": "-regress_censor_extern", "line_start": 4498, "length": 12, "param_range": [211249, 211271], "help": "        -regress_censor_extern CENSOR.1D : supply an external censor file\n\n                e.g. -regress_censor_extern censor_bad_trs.1D\n\n            This option is used to provide an initial censor file, if there\n            is some censoring that is desired beyond the automated motion and\n            outlier censoring.\n\n            Any additional censoring (motion or outliers) will be combined.\n\n             See also -regress_censor_motion, -regress_censor_outliers.", "help_range": [211241, 211713]}, {"param": "-regress_censor_motion", "line_start": 4510, "length": 40, "param_range": [211723, 211745], "help": "censor TRs with excessive motion\n\n                e.g. -regress_censor_motion 0.3\n\n            This option is used to censor TRs where the subject moved too much.\n            \"Too much\" is decided by taking the derivative of the motion\n            parameters (ignoring shifts between runs) and the sqrt(sum squares)\n            per TR.  If this Euclidean Norm exceeds the given LIMIT, the TR\n            will be censored.\n\n            This option will result in the creation of 3 censor files:\n\n                motion_$subj_censor.1D\n                motion_$subj_CENSORTR.txt\n                motion_$subj_enorm.1D\n\n            motion_$subj_censor.1D is a 0/1 columnar file to be applied to\n            3dDeconvolve via -censor.  A row with a 1 means to include that TR,\n            while a 0 means to exclude (censor) it.\n\n            motion_$subj_CENSORTR.txt is a short text file listing censored\n            TRs, suitable for use with the -CENSORTR option in 3dDeconvolve.\n            The -censor option is the one applied however, so this file is not\n            used, but may be preferable for users to have a quick peek at.\n\n            motion_$subj_enorm.1D is the time series that the LIMIT is applied\n            to in deciding which TRs to censor.  It is the Euclidean norm of\n            the derivatives of the motion parameters.  Plotting this will give\n            users a visual indication of why TRs were censored.\n\n            By default, the TR prior to the large motion derivative will also\n            be censored.  To turn off that behavior, use -regress_censor_prev\n            with parameter 'no'.\n\n            If censoring the first few TRs from each run is also necessary,\n            use -regress_censor_first_trs.\n\n            Please see '1d_tool.py -help' for information on censoring motion.\n            See also -regress_censor_prev and -regress_censor_first_trs.", "help_range": [211754, 213646]}, {"param": "-regress_censor_first_trs", "line_start": 4550, "length": 16, "param_range": [213656, 213681], "help": "censor the first N TRs in each run\n\n                e.g.     -regress_censor_first_trs 3\n                default: N = 0\n\n            If, for example, censoring the first 3 TRs per run is desired, a\n            user might add \"-CENSORTR '*:0-2'\" to the -regress_opts_3dD option.\n            However, when using -regress_censor_motion, these censoring options\n            must be combined into one for 3dDeconvolve.\n\n            The -regress_censor_first_trs censors those TRs along with any with\n            large motion.\n\n            See '-censor_first_trs' under '1d_tool.py -help' for details.\n            See also '-regress_censor_motion'.", "help_range": [213687, 214329]}, {"param": "-regress_censor_prev", "line_start": 4566, "length": 17, "param_range": [214339, 214359], "help": "        -regress_censor_prev yes/no  : censor TRs preceding large motion\n\n                default: -regress_censor_prev yes\n\n            Since motion spans two TRs, the derivative is not quite enough\n            information to decide whether it is more appropriate to censor\n            the earlier or later TR.  To error on the safe side, many users\n            choose to censor both.\n\n            Use this option to specify whether to include the previous TR\n            when censoring.\n\n            By default this option is applied as 'yes'.  Users may elect not\n            not to censor the previous TRs by setting this to 'no'.\n\n            See also -regress_censor_motion.", "help_range": [214331, 215011]}, {"param": "-regress_censor_outliers", "line_start": 4583, "length": 24, "param_range": [215021, 215045], "help": "censor TRs with excessive outliers\n\n                e.g. -regress_censor_outliers 0.15\n\n            This option is used to censor TRs where too many voxels are flagged\n            as outliers by 3dToutcount.  LIMIT should be in [0.0, 1.0], as it\n            is a limit on the fraction of masked voxels.\n\n            '3dToutcount -automask -fraction' is used to output the fraction of\n            (auto)masked voxels that are considered outliers at each TR.  If\n            the fraction of outlier voxels is greater than LIMIT for some TR,\n            that TR is censored out.\n\n            Depending on the scanner settings, early TRs might have somewhat\n            higher intensities.  This could lead to the first few TRs of each\n            run being censored.  To avoid censoring the first few TRs of each\n            run, apply the -regress_skip_first_outliers option.\n\n            Note that if motion is also being censored, the multiple censor\n            files will be combined (multiplied) before 3dDeconvolve.\n\n            See '3dToutcount -help' for more details.\n            See also -regress_skip_first_outliers, -regress_censor_motion.", "help_range": [215054, 216203]}, {"param": "-regress_compute_gcor", "line_start": 4607, "length": 32, "param_range": [216213, 216234], "help": "        -regress_compute_gcor yes/no : compute GCOR from unit errts\n\n                e.g. -regress_compute_gcor no\n                default: yes\n\n            By default, the global correlation (GCOR) is computed from the\n            masked residual time series (errts).\n\n            GCOR can be thought of as the result of:\n                A1. compute the correlations of each voxel with every other\n                    --> can be viewed as an NMASK x NMASK correlation matrix\n                A2. compute GCOR: the average of the NMASK^2 values\n\n            Since step A1 would take a lot of time and disk space, a more\n            efficient computation is desirable:\n                B0. compute USET: scale each voxel time series to unit length\n                B1. compute GMU: the global mean of this unit dataset\n                B2. compute a correlation volume (of each time series with GMU)\n                B3. compute the average of this volume\n\n            The actual computation is simplified even further, as steps B2 and\n            B3 combine as the L2 norm of GMU.  The result is:\n                B2'. length(GMU)^2  (or the sum of squares of GMU)\n\n            The steps B0, B1 and B2' are performed in the proc script.\n\n            Note: This measure of global correlation is a single number in the\n                  range [0, 1] (not in [-1, 1] as some might expect).\n\n            Note: computation of GCOR requires a residual dataset, an EPI mask,\n                  and a volume analysis (no surface at the moment).", "help_range": [216205, 217734]}, {"param": "-regress_compute_tsnr", "line_start": 4639, "length": 23, "param_range": [217744, 217765], "help": "        -regress_compute_tsnr yes/no : compute TSNR datasets from errts\n\n                e.g. -regress_compute_tsnr no\n                default: yes\n\n            By default, a temporal signal to noise (TSNR) dataset is created at\n            the end of the regress block.  The \"signal\" is the all_runs dataset\n            (input to 3dDeconvolve), and the \"noise\" is the errts dataset (the\n            residuals from 3dDeconvolve).  TSNR is computed (per voxel) as the\n            mean signal divided by the standard deviation of the noise.\n\n               TSNR = average(signal) / stdev(noise)\n\n            The main difference between the TSNR datasets from the volreg and\n            regress blocks is that the data in the regress block has been\n            smoothed and \"completely\" detrended (detrended according to the\n            regression model: including polort, motion and stim responses).\n\n            Use this option to prevent the TSNR dataset computation in the\n            'regress' block.\n\n            See also -volreg_compute_tsnr.", "help_range": [217736, 218782]}, {"param": "-regress_fout", "line_start": 4662, "length": 8, "param_range": [218792, 218805], "help": "        -regress_fout yes/no         : output F-stat sub-bricks\n\n                e.g. -regress_fout no\n                default: yes\n\n            This option controls whether to apply -fout in 3dDeconvolve.  The\n            default is yes.", "help_range": [218784, 219022]}, {"param": "-regress_make_cbucket", "line_start": 4670, "length": 24, "param_range": [219032, 219053], "help": "        -regress_make_cbucket yes/no : add a -cbucket option to 3dDeconvolve\n\n                default: 'no'\n\n            Recall that the -bucket dataset (no 'c') contains beta weights and\n            various statistics, but generally not including baseline terms\n            (polort and motion).\n\n            The -cbucket dataset (with a 'c') is a little different in that it\n            contains:\n                - ONLY betas (no t-stats, no F-stats, no contrasts)\n                - ALL betas (including baseline terms)\n            So it has one volume (beta) per regressor in the X-matrix.\n\n            The use is generally for 3dSynthesize, to recreate time series\n            datasets akin to the fitts, but where the user can request any set\n            of parameters to be included (for example, the polort and the main\n            2 regressors of interest).\n\n            Setting this to 'yes' will result in the -cbucket option being\n            added to the 3dDeconvolve command.\n\n            Please see '3dDeconvolve -help' for more details.", "help_range": [219024, 220074]}, {"param": "-regress_make_corr_vols", "line_start": 4694, "length": 27, "param_range": [220084, 220107], "help": "        -regress_make_corr_vols LABEL1 ... : create correlation volume dsets\n\n                e.g. -regress_make_corr_vols aeseg FSvent\n                default: one is made against full_mask\n\n            This option is used to specify extra correlation volumes to compute\n            based on the residuals (so generally for resting state analysis).\n\n            What is a such a correlation volume?\n\n               Given: errts     : the residuals from the linear regression\n                      a mask    : to correlate over, e.g. full_mask\n\n               Compute: for each voxel (in the errts, say), compute the average\n                  correlation over all voxels within the given mask.  In some\n                  sense, this is a measure of self correlation over a specified\n                  region.\n\n               This is a mean correlation rather than a correlation with the\n               mean.\n\n            The labels specified can be from any ROI mask, such as those coming\n            via -anat_follower_ROI, -regress_ROI_PC, or from the automatic\n            masks from -mask_segment_anat.\n\n            See also -anat_follower_ROI, -regress_ROI_PC, -mask_segment_anat.", "help_range": [220076, 221261]}, {"param": "-regress_mot_as_ort", "line_start": 4721, "length": 5, "param_range": [221271, 221290], "help": "        -regress_mot_as_ort yes/no : regress motion parameters using -ortvec\n\n                default: no\n\n            By default, motion parameters are applied to 3dvolreg using", "help_range": [221263, 221441]}, {"param": "-stim_file", "line_start": 4726, "length": 1, "param_range": [221454, 221464], "help": "            -stim_file and -stim_base.  Use this option to apply them using", "help_range": [221442, 221517]}, {"param": "-ortvec", "line_start": 4727, "length": 7, "param_range": [221530, 221537], "help": "            -ortvec, instead.\n\n            One difference is in having a \"cleaner\" 3dDeconvolve command,\n            without the many extra -stim_file options.  Another is a change in\n            the labels associated with the individual parameters.  Otherwise,\n            all results should be the same.", "help_range": [221518, 221823]}, {"param": "-regress_motion_per_run", "line_start": 4734, "length": 22, "param_range": [221833, 221856], "help": "regress motion parameters from each run\n\n                default: regress motion parameters catenated across runs\n\n            By default, motion parameters from the volreg block are catenated\n            across all runs, providing 6 (assuming 3dvolreg) regressors of no\n            interest in the regression block.\n\n            With -regress_motion_per_run, the motion parameters from each run\n            are used as separate regressors, providing a total of (6 * nruns)\n            regressors.\n\n            This allows for the magnitudes of the regressors to vary over each\n            run, rather than using a single (best) magnitude over all runs.\n            So more motion-correlated variance can be accounted for, at the\n            cost of the extra degrees of freedom (6*(nruns-1)).\n\n            This option will apply to all motion regressors, including\n            derivatives (if requested).\n\n            ** This option was previously called -volreg_regress_per_run. **", "help_range": [221859, 222842]}, {"param": "-regress_skip_first_outliers", "line_start": 4756, "length": 15, "param_range": [222852, 222880], "help": "ignore the first NSKIP TRs\n\n                e.g. -regress_skip_first_outliers 4\n                default: 0\n\n            When using -regress_censor_outliers, any TR with too high of an\n            outlier fraction will be censored.  But depending on the scanner\n            settings, early TRs might have somewhat higher intensities, leading\n            to them possibly being inappropriately censored.\n\n            To avoid censoring any the first few TRs of each run, apply the\n            -regress_skip_first_outliers option.\n\n            See also -regress_censor_outliers.", "help_range": [222889, 223464]}, {"param": "-regress_compute_fitts", "line_start": 4771, "length": 23, "param_range": [223474, 223496], "help": "compute fitts via 3dcalc, not 3dDecon\n\n            This option is to save memory during 3dDeconvolve, in the case\n            where the user has requested both the fitts and errts datasets.\n\n            Normally 3dDeconvolve is used to compute both the fitts and errts\n            time series.  But if memory gets tight, it is worth noting that\n            these datasets are redundant, one can be computed from the other\n            (given the all_runs dataset).\n\n                all_runs = fitts + errts\n\n            Using -regress_compute_fitts, -fitts is no longer applied in 3dD\n            (though -errts is).  Instead, note that an all_runs dataset is\n            created just after 3dDeconvolve.  After that step, the script will\n            create fitts as (all_runs-errts) using 3dcalc.\n\n            Note that computation of both errts and fitts datasets is required\n            for this option to be applied.\n\n            See also -regress_est_blur_errts, -regress_errts_prefix,\n            -regress_fitts_prefix and -regress_no_fitts.", "help_range": [223505, 224551]}, {"param": "-regress_cormat_warnings", "line_start": 4794, "length": 13, "param_range": [224561, 224585], "help": "        -regress_cormat_warnings Y/N : specify whether to get cormat warnings\n\n                e.g. -mask_cormat_warnings No\n                default: Yes\n\n            By default, '1d_tool.py -show_cormat_warnings' is run on the\n            regression matrix.  Any large, pairwise correlations are shown\n            in text output (which is also saved to a text file).\n\n            This option allows one to disable such functionality.\n\n            Please see '1d_tool.py -help' for more details.", "help_range": [224553, 225048]}, {"param": "-regress_est_blur_epits", "line_start": 4807, "length": 19, "param_range": [225058, 225081], "help": "estimate the smoothness of the EPI data\n\n            This option specifies to run 3dFWHMx on each of the EPI datasets\n            used for regression, the results of which are averaged.  These blur\n            values are saved to the file blur_est.$subj.1D, along with any\n            similar output from errts.\n\n            These blur estimates may be input to AlphaSim, for any multiple\n            testing correction done for this subject.  If AlphaSim is run at\n            the group level, it is reasonable to average these estimates\n            across all subjects (assuming they were scanned with the same\n            protocol and at the same scanner).\n\n            The mask block is required for this operation (without which the\n            estimates are not reliable).\n\n            Please see '3dFWHMx -help' for more information.\n            See also -regress_est_blur_errts.", "help_range": [225089, 225975]}, {"param": "-regress_est_blur_errts", "line_start": 4826, "length": 21, "param_range": [225985, 226008], "help": "estimate the smoothness of the errts\n\n            This option specifies to run 3dFWHMx on the errts dataset, output\n            from the regression (by 3dDeconvolve).\n\n            These blur estimates may be input to AlphaSim, for any multiple\n            testing correction done for this subject.  If AlphaSim is run at\n            the group level, it is reasonable to average these estimates\n            across all subjects (assuming they were scanned with the same\n            protocol and at the same scanner).\n\n            Note that the errts blur estimates should be not only slightly\n            more accurate than the epits blur estimates, but they should be\n            slightly smaller, too (which is beneficial).\n\n            The mask block is required for this operation (without which the\n            estimates are not reliable).\n\n            Please see '3dFWHMx -help' for more information.\n            See also -regress_est_blur_epits.", "help_range": [226016, 226966]}, {"param": "-regress_errts_prefix", "line_start": 4847, "length": 11, "param_range": [226976, 226997], "help": "specify a prefix for the -errts option\n\n                e.g. -regress_fitts_prefix errts\n\n            This option is used to add a -errts option to 3dDeconvolve.  As\n            with -regress_fitts_prefix, only the PREFIX is specified, to which\n            the subject ID will be added.\n\n            Please see '3dDeconvolve -help' for more information.\n            See also -regress_fitts_prefix.", "help_range": [227007, 227404]}, {"param": "-regress_fitts_prefix", "line_start": 4858, "length": 14, "param_range": [227414, 227435], "help": "specify a prefix for the -fitts option\n\n                e.g. -regress_fitts_prefix model_fit\n                default: fitts\n\n            By default, the 3dDeconvolve command in the script will be given\n            a '-fitts fitts' option.  This option allows the user to change\n            the prefix applied in the output script.\n\n            The -regress_no_fitts option can be used to eliminate use of -fitts.\n\n            Please see '3dDeconvolve -help' for more information.\n            See also -regress_no_fitts.", "help_range": [227445, 227964]}, {"param": "-regress_global_times", "line_start": 4872, "length": 16, "param_range": [227974, 227995], "help": "specify -stim_times as global times\n\n                default: 3dDeconvolve figures it out, if it can\n\n            By default, the 3dDeconvolve determines whether -stim_times files\n            are local or global times by the first line of the file.  If it\n            contains at least 2 times (which include '*' characters), it is\n            considered as local_times, otherwise as global_times.\n\n            The -regress_global_times option is mostly added to be symmetric\n            with -regress_local_times, as the only case where it would be\n            needed is when there are other times in the first row, but the\n            should still be viewed as global.\n\n            See also -regress_local_times.", "help_range": [228005, 228719]}, {"param": "-regress_local_times", "line_start": 4888, "length": 19, "param_range": [228729, 228749], "help": "specify -stim_times as local times\n\n                default: 3dDeconvolve figures it out, if it can\n\n            By default, the 3dDeconvolve determines whether -stim_times files\n            are local or global times by the first line of the file.  If it\n            contains at least 2 times (which include '*' characters), it is\n            considered as local_times, otherwise as global_times.\n\n            In the case where the first run has only 1 stimulus (maybe even\n            every run), the user would need to put an extra '*' after the\n            first stimulus time.  If the first run has no stimuli, then two\n            would be needed ('* *'), but only for the first run.\n\n            Since this may get confusing, being explicit by adding this option\n            is a reasonable thing to do.\n\n            See also -regress_global_times.", "help_range": [228760, 229614]}, {"param": "-regress_iresp_prefix", "line_start": 4907, "length": 16, "param_range": [229624, 229645], "help": "specify a prefix for the -iresp option\n\n                e.g. -regress_iresp_prefix model_fit\n                default: iresp\n\n            This option allows the user to change the -iresp prefix applied in\n            the 3dDeconvolve command of the output script.\n\n            By default, the 3dDeconvolve command in the script will be given a\n            set of '-iresp iresp' options, one per stimulus type, unless the\n            regression basis function is GAM.  In the case of GAM, the response\n            form is assumed to be known, so there is no need for -iresp.\n\n            The stimulus label will be appended to this prefix so that a sample\n            3dDeconvolve option might look one of these 2 examples:", "help_range": [229655, 230376]}, {"param": "-iresp", "line_start": 4923, "length": 1, "param_range": [230394, 230400], "help": "                -iresp 7 iresp_stim07", "help_range": [230378, 230415]}, {"param": "-iresp", "line_start": 4924, "length": 7, "param_range": [230432, 230438], "help": "                -iresp 7 model_fit_donuts\n\n            The -regress_no_iresp option can be used to eliminate use of -iresp.\n\n            Please see '3dDeconvolve -help' for more information.\n            See also -regress_no_iresp, -regress_basis.", "help_range": [230416, 230662]}, {"param": "-regress_make_ideal_sum", "line_start": 4931, "length": 23, "param_range": [230672, 230695], "help": "        -regress_make_ideal_sum IDEAL.1D : create IDEAL.1D file from regressors\n\n                e.g. -regress_make_ideal_sum ideal_all.1D\n\n            By default, afni_proc.py will compute a 'sum_ideal.1D' file that\n            is the sum of non-polort and non-motion regressors from the\n            X-matrix.  This -regress_make_ideal_sum option is used to specify\n            the output file for that sum (if sum_idea.1D is not desired).\n\n            Note that if there is nothing in the X-matrix except for polort and\n            motion regressors, or if 1d_tool.py cannot tell what is in there\n            (if there is no header information), then all columns will be used.\n\n            Computing the sum means adding a 1d_tool.py command to figure out\n            which columns should be used in the sum (since mixing GAM, TENT,\n            etc., makes it harder to tell up front), and a 3dTstat command to\n            actually sum those columns of the 1D X-matrix (the X-matrix is\n            output by 3dDeconvolve).\n\n            Please see '3dDeconvolve -help', '1d_tool.py -help' and\n            '3dTstat -help'.\n            See also -regress_basis, -regress_no_ideal_sum.", "help_range": [230664, 231846]}, {"param": "-regress_motion_file", "line_start": 4954, "length": 14, "param_range": [231856, 231876], "help": "        -regress_motion_file FILE.1D  : use FILE.1D for motion parameters\n\n                e.g. -regress_motion_file motion.1D\n\n            Particularly if the user performs motion correction outside of\n            afni_proc.py, they may wish to specify a motion parameter file\n            other than dfile_rall.1D (the default generated in the volreg\n            block).\n\n            Note: such files no longer need to be copied via -copy_files.\n\n            If the motion file is in a remote directory, include the path,\n            e.g. -regress_motion_file ../subject17/data/motion.1D .", "help_range": [231848, 232438]}, {"param": "-regress_no_fitts", "line_start": 4968, "length": 9, "param_range": [232448, 232465], "help": "do not supply -fitts to 3dDeconvolve\n\n                e.g. -regress_no_fitts\n\n            This option prevents the program from adding a -fitts option to\n            the 3dDeconvolve command in the output script.\n\n            See also -regress_fitts_prefix.", "help_range": [232474, 232731]}, {"param": "-regress_no_ideal_sum", "line_start": 4977, "length": 8, "param_range": [232741, 232762], "help": "do not create sum_ideal.1D from regressors\n\n            By default, afni_proc.py will compute a 'sum_ideal.1D' file that\n            is the sum of non-polort and non-motion regressors from the\n            X-matrix.  This option prevents that step.\n\n            See also -regress_make_ideal_sum.", "help_range": [232770, 233064]}, {"param": "-regress_no_ideals", "line_start": 4985, "length": 14, "param_range": [233074, 233092], "help": "do not generate ideal response curves\n\n                e.g. -regress_no_ideals\n\n            By default, if the GAM or BLOCK basis function is used, ideal\n            response curve files are generated for each stimulus type (from\n            the output X matrix using '3dDeconvolve -x1D').  The names of the\n            ideal response function files look like 'ideal_LABEL.1D', for each\n            stimulus label, LABEL.\n\n            This option is used to suppress generation of those files.\n\n            See also -regress_basis, -regress_stim_labels.", "help_range": [233100, 233653]}, {"param": "-regress_no_iresp", "line_start": 4999, "length": 11, "param_range": [233663, 233680], "help": "do not supply -iresp to 3dDeconvolve\n\n                e.g. -regress_no_iresp\n\n            This option prevents the program from adding a set of -iresp\n            options to the 3dDeconvolve command in the output script.\n\n            By default -iresp will be used unless the basis function is GAM.\n\n            See also -regress_iresp_prefix, -regress_basis.", "help_range": [233689, 234048]}, {"param": "-regress_no_mask", "line_start": 5010, "length": 13, "param_range": [234058, 234074], "help": "do not apply the mask in regression\n\n            ** This is now the default, making the option unnecessary.\n\n            This option prevents the program from applying the mask dataset\n            in the scaling or regression steps.\n\n            If the user does not want to apply a mask in the regression\n            analysis, but wants the full_mask dataset for other reasons\n            (such as computing blur estimates), this option can be used.\n\n            See also -regress_est_blur_epits, -regress_est_blur_errts.", "help_range": [234084, 234606]}, {"param": "-regress_no_motion", "line_start": 5023, "length": 7, "param_range": [234616, 234634], "help": "do not apply motion params in 3dDeconvolve\n\n                e.g. -regress_no_motion\n\n            This option prevents the program from adding the registration\n            parameters (from volreg) to the 3dDeconvolve command.", "help_range": [234642, 234866]}, {"param": "-regress_no_motion_demean", "line_start": 5030, "length": 13, "param_range": [234876, 234901], "help": "do not compute de-meaned motion parameters\n\n                default: do compute them\n\n            Even if they are not applied in the regression, the default is to\n            compute de-meaned motion parameters.  These may give the user a\n            better idea of motion regressors, since their scale will not be\n            affected by jumps across run breaks or multi-run drift.\n\n            This option prevents the program from even computing such motion\n            parameters.  The only real reason to not do it is if there is some\n            problem with the command.", "help_range": [234904, 235482]}, {"param": "-regress_no_motion_deriv", "line_start": 5043, "length": 19, "param_range": [235492, 235516], "help": "do not compute motion parameter derivatives\n\n                default: do compute them\n\n            Even if they are not applied in the regression, the default is to\n            compute motion parameter derivatives (and de-mean them).  These can\n            give the user a different idea about motion regressors, since the\n            derivatives are a better indication of per-TR motion.  Note that\n            the 'enorm' file that is created (and optionally used for motion\n            censoring) is basically made by collapsing (via the Euclidean Norm\n            - the square root of the sum of the squares) these 6 derivative\n            columns into one.\n\n            This option prevents the program from even computing such motion\n            parameters.  The only real reason to not do it is if there is some\n            problem with the command.\n\n                See also -regress_censor_motion.", "help_range": [235520, 236426]}, {"param": "-regress_opts_3dD", "line_start": 5062, "length": 14, "param_range": [236436, 236453], "help": "        -regress_opts_3dD OPTS ...   : specify extra options for 3dDeconvolve\n\n                e.g. -regress_opts_3dD -gltsym ../contr/contrast1.txt  \\\n                                       -glt_label 1 FACEvsDONUT        \\\n                                       -jobs 6                         \\\n                                       -GOFORIT 8\n\n            This option allows the user to add extra options to the 3dDeconvolve\n            command.  Note that only one -regress_opts_3dD should be applied,\n            which may be used for multiple 3dDeconvolve options.\n\n            Please see '3dDeconvolve -help' for more information, or the link:\n                https://afni.nimh.nih.gov/afni/doc/misc/3dDeconvolveSummer2004", "help_range": [236428, 237159]}, {"param": "-regress_opts_reml", "line_start": 5076, "length": 12, "param_range": [237169, 237187], "help": "        -regress_opts_reml OPTS ...  : specify extra options for 3dREMLfit\n\n                e.g. -regress_opts_reml                                 \\\n                        -gltsym ../contr/contrast1.txt FACEvsDONUT      \\\n                        -MAXa 0.92\n\n            This option allows the user to add extra options to the 3dREMLfit\n            command.  Note that only one -regress_opts_reml should be applied,\n            which may be used for multiple 3dREMLfit options.\n\n            Please see '3dREMLfit -help' for more information.", "help_range": [237161, 237703]}, {"param": "-regress_ppi_stim_files", "line_start": 5088, "length": 14, "param_range": [237713, 237736], "help": "        -regress_ppi_stim_files FILE FILE ... : specify PPI (and seed) files\n\n                e.g. -regress_ppi_stim_files PPI.1.A.1D PPI.2.B.1D PPI.3.seed.1D\n\n            Use this option to pass PPI stimulus files for inclusion in\n            3dDeconvolve command.  This list is essentially appended to\n            (and could be replaced by) -regress_extra_stim_files.\n\n          * These are not timing files, but direct regressors.\n\n            Use -regress_ppi_stim_labels to specify the corresponding labels.\n\n            See also -write_ppi_3dD_scripts, -regress_ppi_stim_labels.", "help_range": [237705, 238289]}, {"param": "-regress_ppi_stim_labels", "line_start": 5102, "length": 12, "param_range": [238299, 238323], "help": "        -regress_ppi_stim_labels LAB1 LAB2 ... : specify PPI (and seed) labels\n\n                e.g. -regress_ppi_stim_files PPI.taskA PPI.taskB PPI.seed\n\n            Use this option to specify labels for the PPI stimulus files\n            specified via -regress_ppi_stim_files.  This list is essentially\n            appended to (and could be replaced by) -regress_extra_stim_labels.\n\n            Use -regress_ppi_stim_labels to specify the corresponding labels.\n\n            See also -write_ppi_3dD_scripts, -regress_ppi_stim_labels.", "help_range": [238291, 238825]}, {"param": "-regress_polort", "line_start": 5114, "length": 16, "param_range": [238835, 238850], "help": "specify the polynomial degree of baseline\n\n                e.g. -regress_polort 2\n                default: 1 + floor(run_length / 150.0)\n\n            3dDeconvolve models the baseline for each run separately, using\n            Legendre polynomials (by default).  This option specifies the\n            degree of polynomial.  Note that this will create DEGREE * NRUNS\n            regressors.\n\n            The default is computed from the length of a run, in seconds, as\n            shown above.  For example, if each run were 320 seconds, then the\n            default polort would be 3 (cubic).\n\n            Please see '3dDeconvolve -help' for more information.", "help_range": [238861, 239519]}, {"param": "-regress_reml_exec", "line_start": 5130, "length": 16, "param_range": [239529, 239547], "help": "execute 3dREMLfit, matching 3dDeconvolve cmd\n\n            3dDeconvolve automatically creates a 3dREMLfit command script to\n            match the regression model of 3dDeconvolve.  Via this option, the\n            user can have that command executed.\n\n            Note that the X-matrix used in 3dREMLfit is actually generated by\n            3dDeconvolve.  The 3dDeconvolve command generates both the X-matrix\n            and the 3dREMLfit command script, and so it must be run regardless\n            of whether it actually performs the regression.\n\n            To terminate 3dDeconvolve after creation of the X-matrix and\n            3dREMLfit command script, apply -regress_3dD_stop.\n\n            See also -regress_3dD_stop.", "help_range": [239555, 240280]}, {"param": "-regress_ROI", "line_start": 5146, "length": 28, "param_range": [240290, 240302], "help": "        -regress_ROI R1 R2 ... : specify a list of mask averages to regress out\n\n                e.g. -regress_ROI WMe\n                e.g. -regress_ROI brain WMe CSF\n                e.g. -regress_ROI FSvent FSwhite\n\n            Use this option to regress out one more more known ROI averages.\n            ROIs that can be generated from -mask_segment_anat/_erode include:\n\n                name    description     source dataset    creation program\n                -----   --------------  --------------    ----------------\n                brain   EPI brain mask  full_mask         3dAutomask\n                CSF     CSF             mask_CSF_resam    3dSeg -> Classes\n                CSFe    CSF (eroded)    mask_CSFe_resam   3dSeg -> Classes\n                GM      gray matter     mask_GM_resam     3dSeg -> Classes\n                GMe     gray (eroded)   mask_GMe_resam    3dSeg -> Classes\n                WM      white matter    mask_WM_resam     3dSeg -> Classes\n                WMe     white (eroded)  mask_WMe_resam    3dSeg -> Classes\n\n            Other ROI labels can come from -anat_follower_ROI options, i.e.\n            imported masks.\n\n          * Use of this option requires either -mask_segment_anat or labels\n            defined via -anat_follower_ROI options.\n\n            See also -mask_segment_anat/_erode, -anat_follower_ROI.\n            Please see '3dSeg -help' for more information on the masks.", "help_range": [240282, 241699]}, {"param": "-regress_ROI_PC", "line_start": 5174, "length": 3, "param_range": [241709, 241724], "help": "regress out PCs within mask\n\n                e.g. -regress_ROI_PC vent 3", "help_range": [241743, 241815]}, {"param": "-regress_ROI", "line_start": 5177, "length": 60, "param_range": [241837, 241849], "help": "                     -regress_ROI_PC WMe 3\n\n            Add the top principal components (PCs) over an anatomical mask as\n            regressors of no interest.\n\nthe class label given to this set of regressors\n              - NUM_PC  : the number of principal components to include\n\n            The LABEL can apply to something defined via -mask_segment_anat\n            maybe with -mask_segment_erode, or from -anat_follower_ROI\n            (assuming 'epi' grid), or 'brain' (full_mask).  The -mask_segment*\n            options define ROI labels implicitly (see above), while the user\n            defines ROI labels in any -anat_follower_ROI options.\n\n            Method (including 'follower' steps):\n\n              If -anat_follower_ROI is used to define the label, then the\n              follower ROI steps would first be applied to that dataset.\n\n              If ROIs are created 'automatically' via 3dSeg (-mask_segment_anat)\n              then the follower steps do not apply.\n\n              F1. if requested (-anat_follower_erode) erode the ROI mask\n              F2. apply all anatomical transformations to the ROI mask\n                  a. catenate all anatomical transformations\n                     i.   anat to EPI?\n                     ii.  affine xform of anat to template?\n                     iii. subsequent non-linear xform of anat to template?\n                  b. sample the transformed mask on the EPI grid\n                  c. use nearest neighbor interpolation, NN\n\n           Method (post-mask alignment):\n\n              P1. extract the top NUM_PC principal components from the volume\n                  registered EPI data, over the mask\n                  a. detrend the volume registered EPI data at the polort level\n                     to be used in the regression, per run\n                  b. catenate the detrended volreg data across runs\n                  c. compute the top PCs from the (censored?) time series\n                  d. if censoring, zero-fill the time series with volumes of\n                     zeros at the censored TRs, to maintain TR correspondence\n              P2. include those PCs as regressors of no interest\n                  a. apply with: 3dDeconvolve -ortvec PCs LABEL\n\n            Typical usage might start with the FreeSurfer parcellation of the\n            subject's anatomical dataset, followed by ROI extraction using\n            3dcalc (to make a new dataset of just the desired regions).  Then\n            choose the number of components to extract and a label.\n\n            That ROI dataset, PC count and label are then applied with this\n            option.\n\n          * The given MASK must be in register with the anatomical dataset,\n            though it does not necessarily need to be on the anatomical grid.\n\n          * Multiple -regress_ROI_PC options can be used.\n\n            See also -anat_follower, -anat_follower_ROI, -regress_ROI_erode,\n            and -regress_ROI.", "help_range": [241837, 244783]}, {"param": "-regress_ROI_per_run", "line_start": 5237, "length": 12, "param_range": [244798, 244818], "help": "        -regress_ROI_per_run LABEL ... : regress these ROIs per run\n\n                e.g. -regress_ROI_per_run vent\n                e.g. -regress_ROI_per_run vent WMe\n\n            Use this option to create the given ROI regressors per run.\n            Instead of creating one regressor spanning all runs, this option\n            leads to creating one regressor per run, akin to splitting the\n            long regressor across runs, and zero-padding to be the same length.\n\n            See also -regress_ROI_PC, -regress_ROI_PC_per_run.", "help_range": [244790, 245325]}, {"param": "-regress_ROI_PC_per_run", "line_start": 5249, "length": 18, "param_range": [245335, 245358], "help": "        -regress_ROI_PC_per_run LABEL ... : regress these PCs per run\n\n                e.g. -regress_ROI_PC_per_run vent\n                e.g. -regress_ROI_PC_per_run vent WMe\n\n            Use this option to create the given PC regressors per run.  So\n            if there are 4 runs and 3 'vent' PCs were requested with the\n            option \"-regress_ROI_PC vent 3\", then applying this option with\n            the 'vent' label results in not 3 regressors (one per PC), but\n            12 regressors (one per PC per run).\n\n            Note that unlike the -regress_ROI_per_run case, this is not merely\n            splitting one signal across runs.  In this case the principle\n            components are be computed per run, almost certainly resulting in\n            different components than those computed across all runs at once.\n\n            See also -regress_ROI_PC, -regress_ROI_per_run.", "help_range": [245327, 246220]}, {"param": "-regress_RSFC", "line_start": 5267, "length": 14, "param_range": [246230, 246243], "help": "perform bandpassing via 3dRSFC\n\n            Use this option flag to run 3dRSFC after the linear regression\n            step (presumably to clean resting state data).  Along with the\n            bandpassed data, 3dRSFC will produce connectivity parameters,\n            saved in the RSFC directory by the proc script.\n\n            The -regress_bandpass option is required, and those bands will be\n            passed directly to 3dRSFC.  Since bandpassing will be done only\n            after the linear regression, censoring is not advisable.\n\n            See also -regress_bandpass, -regress_censor_motion.\n            Please see '3dRSFC -help' for more information.", "help_range": [246256, 246920]}, {"param": "-regress_RONI", "line_start": 5281, "length": 16, "param_range": [246930, 246943], "help": "        -regress_RONI IND1 ...  : specify a list of regressors of no interest\n\n                e.g. -regress_RONI 1 17 22\n\n            Use this option flag regressors as ones of no interest, meaning\n            they are applied to the baseline (for full-F) and the corresponding\n            beta weights are not output (by default at least).\n\n            The indices in the list should match those given to 3dDeconvolve.\n            They start at 1 first with the main regressors, and then with any\n            extra regressors (given via -regress_extra_stim_files).  Note that\n            these do not apply to motion regressors.\n\n            The user is encouraged to check the 3dDeconvolve command in the\n            processing script, to be sure they are applied correctly.", "help_range": [246922, 247699]}, {"param": "-regress_stim_labels", "line_start": 5297, "length": 7, "param_range": [247709, 247729], "help": "        -regress_stim_labels LAB1 ...   : specify labels for stimulus classes\n\n                e.g. -regress_stim_labels houses faces donuts\n                default: stim01 stim02 stim03 ...\n\n            This option is used to apply a label to each stimulus type.  The\n            number of labels should equal the number of files used in the", "help_range": [247701, 248043]}, {"param": "-regress_stim_times", "line_start": 5304, "length": 8, "param_range": [248056, 248075], "help": "            -regress_stim_times option, or the total number of columns in the\n            files used in the -regress_stim_files option.\n\n            These labels will be applied as '-stim_label' in 3dDeconvolve.\n\n            Please see '3dDeconvolve -help' for more information.\n            See also -regress_stim_times, -regress_stim_labels.", "help_range": [248044, 248386]}, {"param": "-regress_stim_times", "line_start": 5312, "length": 13, "param_range": [248396, 248415], "help": "        -regress_stim_times FILE1 ... : specify files used for -stim_times\n\n                e.g. -regress_stim_times ED_stim_times*.1D\n                e.g. -regress_stim_times times_A.1D times_B.1D times_C.1D\n\n            3dDeconvolve will be run using '-stim_times'.  This option is\n            used to specify the stimulus timing files to be applied, one\n            file per stimulus type.  The order of the files given on the\n            command line will be the order given to 3dDeconvolve.  Each of\n            these timing files will be given along with the basis function\n            specified by '-regress_basis'.\n\n            The user must specify either -regress_stim_times or", "help_range": [248388, 249075]}, {"param": "-regress_stim_files", "line_start": 5325, "length": 23, "param_range": [249088, 249107], "help": "            -regress_stim_files if regression is performed, but not both.\n            Note the form of the files is one row per run.  If there is at\n            most one stimulus per run, please add a trailing '*'.\n\n            Labels may be specified using the -regress_stim_labels option.\n\n            These two examples of such files are for a 3-run experiment.  In\n            the second example, there is only 1 stimulus at all, occurring in\n            run #2.\n\n                e.g.            0  12.4  27.3  29\n                                *\n                                30 40 50\n\n                e.g.            *\n                                20 *\n                                *\n\n            Please see '3dDeconvolve -help' for more information, or the link:\n                https://afni.nimh.nih.gov/afni/doc/misc/3dDeconvolveSummer2004\n            See also -regress_stim_files, -regress_stim_labels, -regress_basis,\n                     -regress_basis_normall, -regress_polort.", "help_range": [249076, 250075]}, {"param": "-regress_stim_files", "line_start": 5348, "length": 24, "param_range": [250085, 250104], "help": "        -regress_stim_files FILE1 ... : specify TR-locked stim files\n\n                e.g. -regress_stim_files ED_stim_file*.1D\n                e.g. -regress_stim_files stim_A.1D stim_B.1D stim_C.1D\n\n            Without the -regress_use_stim_files option, 3dDeconvolve will be\n            run using '-stim_times', not '-stim_file'.  The user can still\n            specify the 3dDeconvolve -stim_file files here, but they would\n            then be converted to -stim_times files using the script,\n            make_stim_times.py .\n\n            It might be more educational for the user to run make_stim_times.py\n            outside afni_proc.py (such as was done before example 2, above), or\n            to create the timing files directly.\n\n            Each given file can be for multiple stimulus classes, where one\n            column is for one stim class, and each row represents a TR.  So\n            each file should have NUM_RUNS * NUM_TRS rows.\n\n            The stim_times files will be labeled stim_times.NN.1D, where NN\n            is the stimulus index.\n\n            Note that if the stimuli were presented at a fixed time after\n            the beginning of a TR, the user should consider the option,", "help_range": [250077, 251286]}, {"param": "-regress_stim_times", "line_start": 5372, "length": 7, "param_range": [251299, 251318], "help": "            -regress_stim_times_offset, to apply that offset.\n\n            ---\n\n            If the -regress_use_stim_files option is provided, 3dDeconvolve\n            will be run using each stim_file as a regressor.  The order of the\n            regressors should match the order of any labels, provided via the", "help_range": [251287, 251599]}, {"param": "-regress_stim_labels", "line_start": 5379, "length": 9, "param_range": [251612, 251632], "help": "            -regress_stim_labels option.\n\n            Alternately, this can be done via -regress_stim_times, along\n            with -regress_stim_types 'file'.\n\n            Please see '3dDeconvolve -help' for more information, or the link:\n                https://afni.nimh.nih.gov/afni/doc/misc/3dDeconvolveSummer2004\n            See also -regress_stim_times, -regress_stim_labels, -regress_basis,\n                     -regress_basis_normall, -regress_polort,", "help_range": [251600, 252060]}, {"param": "-regress_stim_times", "line_start": 5388, "length": 2, "param_range": [252082, 252101], "help": "                     -regress_stim_times_offset, -regress_use_stim_files.", "help_range": [252061, 252134]}, {"param": "-regress_extra_stim_files", "line_start": 5390, "length": 6, "param_range": [252144, 252169], "help": "        -regress_extra_stim_files FILE1 ... : specify extra stim files\n\n                e.g. -regress_extra_stim_files resp.1D cardiac.1D\n                e.g. -regress_extra_stim_files regs_of_no_int_*.1D\n\n            Use this option to specify extra files to be applied with the", "help_range": [252136, 252415]}, {"param": "-stim_file", "line_start": 5396, "length": 9, "param_range": [252428, 252438], "help": "            -stim_file option in 3dDeconvolve (as opposed to the more usual\n            option, -stim_times).\n\n            These files will not be converted to stim_times format.\n\n            Corresponding labels can be given with -regress_extra_stim_labels.\n\n            See also -regress_extra_stim_labels, -regress_ROI, -regress_RONI.", "help_range": [252416, 252753]}, {"param": "-regress_extra_stim_labels", "line_start": 5405, "length": 14, "param_range": [252763, 252789], "help": "        -regress_extra_stim_labels LAB1 ... : specify extra stim file labels\n\n                e.g. -regress_extra_stim_labels resp cardiac\n\n            If -regress_extra_stim_files is given, the user may want to specify\n            labels for those extra stimulus files.  This option provides that\n            mechanism.  If this option is not given, default labels will be\n            assigned (like stim17, for example).\n\n            Note that the number of entries in this list should match the\n            number of extra stim files.\n\n            See also -regress_extra_stim_files.", "help_range": [252755, 253341]}, {"param": "-regress_stim_times_offset", "line_start": 5419, "length": 29, "param_range": [253351, 253377], "help": "add OFFSET to -stim_times files\n\n                e.g. -regress_stim_times_offset 1.25\n                e.g. -regress_stim_times_offset -9.2\n                default: 0\n\n            With -regress_stim_times:\n\n               If the -regress_stim_times option is uses, and if ALL stim files\n               are timing files, then timing_tool.py will be used to add the\n               time offset to each -regress_stim_times file as it is copied into\n               the stimuli directory (near the beginning of the script).\n\n            With -regress_stim_files:\n\n               If the -regress_stim_files option is used (so the script would\n               convert -stim_files to -stim_times before 3dDeconvolve), the\n               user may want to add an offset to the times in the resulting\n               timing files.\n\n               For example, if -tshift_align_to is applied and the user chooses\n               to align volumes to the middle of the TR, it might be appropriate\n               to add TR/2 to the times of the stim_times files.\n\n               This OFFSET will be applied to the make_stim_times.py command in\n               the output script.\n\n            Please see 'make_stim_times.py -help' for more information.\n            See also -regress_stim_files, -regress_use_stim_files,", "help_range": [253387, 254684]}, {"param": "-regress_stim_times", "line_start": 5448, "length": 2, "param_range": [254706, 254725], "help": "                     -regress_stim_times and -tshift_align_to.", "help_range": [254685, 254747]}, {"param": "-regress_stim_types", "line_start": 5450, "length": 35, "param_range": [254757, 254776], "help": "        -regress_stim_types TYPE1 TYPE2 ... : specify list of stim types\n\n                e.g. -regress_stim_types times times AM2 AM2 times AM1 file\n                e.g. -regress_stim_types AM2\n                default: times\n\n            If amplitude, duration or individual modulation is desired with\n            any of the stimulus timing files provided via -regress_stim_files,\n            then this option should be used to specify one (if all of the types\n            are the same) or a list of stimulus timing types.  One can also use\n            the type 'file' for the case of -stim_file, where the input is a 1D\n            regressor instead of stimulus times.\n\n            The types should be (possibly repeated) elements of the set:\n            {times, AM1, AM2, IM}, where they indicate:\n\n                times:  a standard stimulus timing file (not married)\n                        ==> use -stim_times in 3dDeconvolve command\n\n                AM1:    have one or more married parameters\n                        ==> use -stim_times_AM1 in 3dDeconvolve command\n\n                AM2:    have one or more married parameters\n                        ==> use -stim_times_AM2 in 3dDeconvolve command\n\n                IM:     NO married parameters, but get beta for each stim\n                        ==> use -stim_times_IM in 3dDeconvolve command\n\n                file:   a 1D regressor, not a stimulus timing file\n                        ==> use -stim_file in 3dDeconvolve command\n\n            Please see '3dDeconvolve -help' for more information.\n            See also -regress_stim_times.\n            See also example 7 (esoteric options).", "help_range": [254749, 256395]}, {"param": "-regress_use_stim_files", "line_start": 5485, "length": 14, "param_range": [256405, 256428], "help": "use -stim_file in regression, not -stim_times\n\n            The default operation of afni_proc.py is to convert TR-locked files\n            for the 3dDeconvolve -stim_file option to timing files for the\n            3dDeconvolve -stim_times option.\n\n            If the -regress_use_stim_times option is provided, then no such\n            conversion will take place.  This assumes the -regress_stim_files\n            option is applied to provide such -stim_file files.\n\n            This option has been renamed from '-regress_no_stim_times'.\n\n            Please see '3dDeconvolve -help' for more information.\n            See also -regress_stim_files, -regress_stim_times,", "help_range": [256431, 257099]}, {"param": "-regress_stim_labels", "line_start": 5499, "length": 5, "param_range": [257121, 257141], "help": "                     -regress_stim_labels.\n\n        -----------------------------------------------------------------\n        3dClustSim options ~3~", "help_range": [257100, 257248]}, {"param": "-regress_run_clustsim", "line_start": 5504, "length": 19, "param_range": [257258, 257279], "help": "        -regress_run_clustsim yes/no : add 3dClustSim attrs to stats dset\n\n                e.g. -regress_run_clustsim no\n                default: yes\n\n            This option controls whether 3dClustSim will be executed after the\n            regression analysis.  Since the default is 'yes', the effective use\n            of this option would be to turn off the operation.\n\n            3dClustSim is a more advanced version of AlphaSim, and generates a\n            table of cluster sizes/alpha values that can be then stored in the\n            stats dataset for a simple multiple comparison correction in the\n            cluster interface of the afni GUI.\n\n            The blur estimates and mask dataset are required, and so the\n            option is only relevant in the context of blur estimation.\n\n            Please see '3dClustSim -help' for more information.\n            See also -regress_est_blur_epits, -regress_est_blur_epits and", "help_range": [257250, 258189]}, {"param": "-regress_opts_CS", "line_start": 5523, "length": 2, "param_range": [258211, 258227], "help": "                     -regress_opts_CS.", "help_range": [258190, 258228]}, {"param": "-regress_CS_NN", "line_start": 5525, "length": 20, "param_range": [258238, 258252], "help": "specify NN levels for 3dClustSim command\n\n                e.g.     -regress_CS_NN 1\n                default: -regress_CS_NN 123\n\n            This option allows the user to specify which nearest neighbors to\n            consider when clustering.  Cluster results will be generated for\n            each included NN level.  Using multiple levels means being able to\n            choose between those same levels when looking at the statistical\n            results using the afni GUI.\n\n            The LEVELS should be chosen from the set {1,2,3}, where the\n            respective levels mean \"shares a face\", \"shares an edge\" and\n            \"shares a corner\", respectively.  Any non-empty subset can be used.\n            They should be specified as is with 3dClustSim.\n\n            So there are 7 valid subsets: 1, 2, 3, 12, 13, 23, and 123.\n\n            Please see '3dClustSim -help' for details on its '-NN' option.", "help_range": [258264, 259178]}, {"param": "-regress_opts_CS", "line_start": 5545, "length": null, "param_range": [259188, 259204], "help": "        -regress_opts_CS OPTS ...    : specify extra options for 3dClustSim\n\n                e.g. -regress_opts_CS -athr 0.05 0.01 0.005 0.001\n\n            This option allows the user to add extra options to the 3dClustSim\n            command.  Only 1 such option should be applied, though multiple\n            options to 3dClustSim can be included.\n\n            Please see '3dClustSim -help' for more information.\n            See also -regress_run_clustsim.\n\n\n    - R Reynolds  Dec, 2006                             thanks to Z Saad\n    ===========================================================================", "help_range": [259180, 259793]}]}