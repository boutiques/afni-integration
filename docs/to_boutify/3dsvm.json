{
 "helptext": [
  "",
  "Program: 3dsvm",
  "",
  "+++++++++++ 3dsvm: support vector machine analysis of brain data  +++++++++++",
  "",
  "3dsvm - temporally predictive modeling with the support vector machine",
  "",
  "   This program provides the ability to perform support vector machine",
  "   (SVM) learning on AFNI datasets using the SVM-light package (version 5)",
  "   developed by Thorsten Joachims (http://svmlight.joachims.org/).",
  "",
  "-----------------------------------------------------------------------------",
  "Usage:",
  "------",
  "\t 3dsvm [options] ",
  "",
  "Examples:",
  "---------",
  "1. Training: basic options require a training run, category (class) labels ",
  "   for each timepoint, and an output model. In general, it usually makes ",
  "   sense to include a mask file to exclude at least non-brain voxels",
  "",
  "\t 3dsvm -trainvol run1+orig \\ ",
  "\t       -trainlabels run1_categories.1D \\ ",
  "\t       -mask mask+orig \\ ",
  "\t       -model model_run1",
  "",
  "2. Training: obtain model alphas (a_run1.1D) and ",
  "   model weights (fim: run1_fim+orig)",
  "",
  "\t 3dsvm -alpha a_run1 \\",
  "\t       -trainvol run1+orig \\ ",
  "\t       -trainlabels run1_categories.1D \\ ",
  "\t       -mask mask+orig \\ ",
  "\t       -model model_run1",
  "\t       -bucket run1_fim",
  "",
  "3. Training: exclude some time points using a censor file ",
  "",
  "\t 3dsvm -alpha a_run1 \\",
  "\t       -trainvol run1+orig \\ ",
  "\t       -trainlabels run1_categories.1D \\ ",
  "\t       -censor censor.1D \\ ",
  "\t       -mask mask+orig \\ ",
  "\t       -model model_run1",
  "\t       -bucket run1_fim",
  "",
  "4. Training: control svm model complexity (C value)",
  "",
  "\t 3dsvm -c 100.0 \\",
  "\t       -alpha a_run1 \\",
  "\t       -trainvol run1+orig \\ ",
  "\t       -trainlabels run1_categories.1D \\ ",
  "\t       -censor censor.1D \\ ",
  "\t       -mask mask+orig \\ ",
  "\t       -model model_run1",
  "\t       -bucket run1_fim",
  "",
  "5. Training: using a kernel ",
  "",
  "\t 3dsvm -c 100.0 \\",
  "\t       -kernel polynomial -d 2 \\",
  "\t       -alpha a_run1 \\",
  "\t       -trainvol run1+orig \\ ",
  "\t       -trainlabels run1_categories.1D \\ ",
  "\t       -censor censor.1D \\ ",
  "\t       -mask mask+orig \\ ",
  "\t       -model model_run1",
  "",
  "6. Training: using regression ",
  "",
  "\t 3dsvm -type regression \\",
  "\t       -c 100.0 \\",
  "\t       -e 0.001 \\",
  "\t       -alpha a_run1 \\",
  "\t       -trainvol run1+orig \\ ",
  "\t       -trainlabels run1_categories.1D \\ ",
  "\t       -censor censor.1D \\ ",
  "\t       -mask mask+orig \\ ",
  "\t       -model model_run1",
  "",
  "7. Testing: basic options require a testing run, a model, and an output",
  "   predictions file",
  "",
  "\t 3dsvm -testvol run2+orig \\",
  "\t       -model model_run1+orig \\",
  "\t       -predictions pred2_model1",
  "",
  "8. Testing: compare predictions with 'truth' ",
  "",
  "\t 3dsvm -testvol run2+orig \\",
  "\t       -model model_run1+orig \\",
  "\t       -testlabels run2_categories.1D \\",
  "\t       -predictions pred2_model1",
  "",
  "9. Testing: use -classout to output integer thresholded class predictions",
  "   (rather than continuous valued output)",
  "",
  "\t 3dsvm -classout \\",
  "\t       -testvol run2+orig \\",
  "\t       -model model_run1+orig \\",
  "\t       -testlabels run2_categories.1D \\",
  "\t       -predictions pred2_model1",
  "",
  "",
  "options:",
  "--------",
  "",
  "------------------- TRAINING OPTIONS -------------------------------------------",
  "-type tname            Specify tname:",
  "",
  "                             classification [default]",
  "                             regression",
  "",
  "                       to select between classification or regression.",
  "",
  "-trainvol trnname      A 3D+t AFNI brik dataset to be used for training. ",
  "",
  "-mask mname            Specify a mask dataset to only perform the analysis",
  "                       on non-zero mask voxels.",
  "                       ++ If '-mask' is not used '-nomodelmask must be",
  "                          specified. ",
  "                       For example, a mask of the whole brain can be ",
  "                       generated by using 3dAutomask, or more specific ROIs",
  "                       could be generated with the Draw Dataset plugin or",
  "                       converted from a thresholded functional dataset. ",
  "                       The mask is specified during training but is also ",
  "                       considered part of the model output and is ",
  "                       automatically applied to test data. ",
  "",
  "-nomodelmask           Flag to enable the omission of a mask file. This is ",
  "                       required if '-mask' is not used.",
  "",
  "-trainlabels lname     lname = filename of class category .1D labels ",
  "                       corresponding to the stimulus paradigm for the ",
  "                       training data set. The number of labels in the ",
  "                       selected file must be equal to the number of ",
  "                       time points in the training dataset. The labels",
  "                       must be arranged in a single column, and they can",
  "                       be any of the following values: ",
  "",
  "                              0    - class 0",
  "                              1    - class 1",
  "                              n    - class n (where n is a positive integer)",
  "                              9999 - censor this point ",
  "",
  "                       See also -censor.",
  "",
  "-censor cname          Specify a .1D censor file that allows the user",
  "                       to ignore certain samples in the training data.",
  "                       To ignore a specific sample, put a 0 in the",
  "                       row corresponding to the time sample - i.e., to",
  "                       ignore sample t, place a 0 in row t of the file.",
  "                       All samples that are to be included for training",
  "                       must have a 1 in the corresponding row. If no",
  "                       censor file is specified, all samples will be used ",
  "                       for training. Note the lname file specified by",
  "                       trainlabels can also be used to censor time points",
  "                       (see -trainlabels).",
  "",
  "-kernel kfunc          kfunc = string specifying type of kernel function:",
  "",
  "                             linear     : <u,v>  [default] ",
  "                             polynomial : (s<u,v> + r)^d ",
  "                             rbf        : radial basis function",
  "                                          exp(-gamma ||u-v||^2) ",
  "                             sigmoid    : tanh(s <u,v> + r)) ",
  "",
  "                       note: kernel parameters use SVM-light syntax:",
  "",
  "                             -d int     : d parameter in polyniomial kernel",
  "                                            3 [default]",
  "                             -g float   : gamma parameter in rbf kernel",
  "                                            1.0 [default]",
  "                             -s float   : s parameter in sigmoid/poly kernel",
  "                                            1.0 [default]",
  "                             -r float   : r parameter in sigmoid/poly kernel",
  "                                            1.0 [default]",
  "",
  "-max_iterations int    Specify the maximum number of iterations for the",
  "                       optimization. 1 million [default].",
  "",
  "-alpha aname           Write the alphas to aname.1D ",
  "",
  "-wout                  Flag to output sum of weighted linear support ",
  "                       vectors to the bucket file. This is one means of",
  "                       generating an \"activation map\" from linear kernel",
  "                       SVMs see (LaConte et al., 2005). NOTE: this is ",
  "                       currently not required since it is the only output",
  "                       option.",
  "",
  "-bucket bprefix        Currently only outputs the sum of weighted linear ",
  "                       support vectors written out to a functional (fim) ",
  "                       brik file. This is one means of generating an ",
  "                       \"activation map\" from linear kernel SVMS ",
  "                       (see LaConte et al, 2005). ",
  "",
  "------------------- TRAINING AND TESTING MUST SPECIFY MODNAME ------------------",
  "-model modname         modname = basename for the model brik.",
  "",
  "                       Training: modname is the basename for the output",
  "                       brik containing the SVM model",
  "",
  "                           3dsvm -trainvol run1+orig \\ ",
  "                                 -trainlabels run1_categories.1D \\ ",
  "                                 -mask mask+orig \\ ",
  "                                 -model model_run1",
  "",
  "                       Testing: modname is the name for the input brik",
  "                       containing the SVM model.",
  "",
  "                           3dsvm -testvol run2+orig \\ ",
  "                                 -model model_run1+orig  \\ ",
  "                                 -predictions pred2_model1",
  "",
  "-nomodelfile           Flag to enable the omission of a model file. This is ",
  "                       required if '-model' is not used during training. ",
  "                       ** Be careful, you might not be able to perform testing!",
  "",
  "------------------- TESTING OPTIONS --------------------------------------------",
  "-testvol tstname       A 3D or 3D+t AFNI brik dataset to be used for testing. ",
  "                       A major assumption is that the training and testing  ",
  "                       volumes are aligned, and that voxels are of same number, ",
  "                       volume, etc. ",
  "",
  "-predictions pname     pname = basename for .1D prediction file(s). ",
  "                       Prediction files contain a single column, where each line ",
  "                       holds the predicted value for the corresponding volume in",
  "                       the test dataset. By default, the predicted values take ",
  "                       on a continuous range; to output integer-valued class",
  "                       decision values use the -classout flag.",
  "                       For classification: Values bellow 0.5 correspond to ",
  "                       (class A) and values above 0.5 to (class B), where A < B. ",
  "                       For more than two classes a separate prediction file for ",
  "                       each possible pair of training classes and one additional ",
  "                       \"overall\" file containing the predicted (integer-valued)",
  "                       class membership is generated.",
  "                       For regression: Each value is the predicted parametric rate ",
  "                       for the corresponding volume in the test dataset. ",
  "",
  "-classout              Flag to specify that pname files should be integer-",
  "                       valued, corresponding to class category decisions.",
  "",
  "-nopredcensored        Do not write predicted values for censored time-points",
  "                       to predictions file.",
  "",
  "-nodetrend             Flag to specify that pname files should NOT be ",
  "                       linearly detrended (detrending is performed by default).",
  "                       ** Set this options if you are using GLM beta maps as",
  "                          input for example. Temporal detrending only ",
  "                          makes sense if you are using time-dependent",
  "                          data (chronological order!) as input.",
  "",
  "-nopredscale           Do not scale predictions. If used, values below 0.0 ",
  "                       correspond to (class A) and values above 0.0 to",
  "                       (class B).",
  "",
  "-testlabels tlname     tlname = filename of 'true' class category .1D labels ",
  "                       for the test dataset. It is used to calculate the ",
  "                       prediction accuracy performance of SVM classification. ",
  "                       If this option is not specified, then performance ",
  "                       calculations are not made. Format is the same as ",
  "                       lname specified for -trainlabels. ",
  "",
  "-multiclass mctype     mctype specifies the multiclass algorithm for ",
  "                       classification. Current implementations use 1-vs-1",
  "                       two-class SVM models.",
  "",
  "                       mctype must be one of the following: ",
  "",
  "                             DAG   :  Directed Acyclic Graph [default] ",
  "                             vote  :  Max Wins from votes of all 1-vs-1 models ",
  "",
  "                       see http:\\\\lacontelab.org\\3dsvm.html for details and",
  "                       references.",
  "",
  "------------------- INFORMATION OPTIONS ---------------------------------------",
  "-help                  this help",
  "",
  "-version               print version history including rough description",
  "                       of changes",
  "",
  "",
  "",
  "",
  "-------------------- SVM-light learn help -----------------------------",
  "",
  "SVM-light V5.00: Support Vector Machine, learning module     30.06.02stim",
  "",
  "Copyright: Thorsten Joachims, thorsten@ls8.cs.uni-dortmund.de",
  "",
  "This software is available for non-commercial use only. It must not",
  "be modified and distributed without prior permission of the author.",
  "The author is not responsible for implications from the use of this",
  "software.",
  "",
  "   usage: svm_learn [options] example_file model_file",
  "",
  "Arguments:",
  "         example_file-> file with training data",
  "         model_file  -> file to store learned decision rule in",
  "General options:",
  "         -?          -> this help",
  "         -v [0..3]   -> level (default 1)",
  "Learning options:",
  "         -z {c,r,p}  -> select between classification (c), regression (r),",
  "                        and preference ranking (p) (default classification)",
  "         -c float    -> C: trade-off between training error",
  "                        and margin (default [avg. x*x]^-1)",
  "         -w [0..]    -> epsilon width of tube for regression",
  "                        (default 0.1)",
  "         -j float    -> Cost: cost-factor, by which training errors on",
  "                        positive examples outweight errors on negative",
  "                        examples (default 1) (see [4])",
  "         -b [0,1]    -> use biased hyperplane (i.e. x*w+b>0) instead",
  "                        of unbiased hyperplane (i.e. x*w>0) (default 1)",
  "         -i [0,1]    -> remove inconsistent training examples",
  "                        and retrain (default 0)",
  "Performance estimation options:",
  "         -x [0,1]    -> compute leave-one-out estimates (default 0)",
  "                        (see [5])",
  "         -o ]0..2]   -> value of rho for XiAlpha-estimator and for pruning",
  "                        leave-one-out computation (default 1.0) (see [2])",
  "         -k [0..100] -> search depth for extended XiAlpha-estimator ",
  "                        (default 0)",
  "Transduction options (see [3]):",
  "         -p [0..1]   -> fraction of unlabeled examples to be classified",
  "                        into the positive class (default is the ratio of",
  "                        positive and negative examples in the training data)",
  "Kernel options:",
  "         -t int      -> type of kernel function:",
  "                        0: linear (default)",
  "                        1: polynomial (s a*b+c)^d",
  "                        2: radial basis function exp(-gamma ||a-b||^2)",
  "                        3: sigmoid tanh(s a*b + c)",
  "                        4: user defined kernel from kernel.h",
  "         -d int      -> parameter d in polynomial kernel",
  "         -g float    -> parameter gamma in rbf kernel",
  "         -s float    -> parameter s in sigmoid/poly kernel",
  "         -r float    -> parameter c in sigmoid/poly kernel",
  "         -u string   -> parameter of user defined kernel",
  "Optimization options (see [1]):",
  "         -q [2..]    -> maximum size of QP-subproblems (default 10)",
  "         -n [2..q]   -> number of new variables entering the working set",
  "                        in each iteration (default n = q). Set n<q to prevent",
  "                        zig-zagging.",
  "         -m [5..]    -> size of cache for kernel evaluations in MB (default 40)",
  "                        The larger the faster...",
  "         -e float    -> eps: Allow that error for termination criterion",
  "                        [y [w*x+b] - 1] >= eps (default 0.001)",
  "         -h [5..]    -> number of iterations a variable needs to be",
  "                        optimal before considered for shrinking (default 100)",
  "         -f [0,1]    -> do final optimality check for variables removed",
  "                        by shrinking. Although this test is usually ",
  "                        positive, there is no guarantee that the optimum",
  "                        was found if the test is omitted. (default 1)",
  "Output options:",
  "         -l string   -> file to write predicted labels of unlabeled",
  "                        examples into after transductive learning",
  "         -a string   -> write all alphas to this file after learning",
  "                        (in the same order as in the training set)",
  "",
  "More details in:",
  "[1] T. Joachims, Making Large-Scale SVM Learning Practical. Advances in",
  "    Kernel Methods - Support Vector Learning, B. Schoelkopf and C. Burges and",
  "    A. Smola (ed.), MIT Press, 1999.",
  "[2] T. Joachims, Estimating the Generalization performance of an SVM",
  "    Efficiently. International Conference on Machine Learning (ICML), 2000.",
  "[3] T. Joachims, Transductive Inference for Text Classification using Support",
  "    Vector Machines. International Conference on Machine Learning (ICML),",
  "    1999.",
  "[4] K. Morik, P. Brockhausen, and T. Joachims, Combining statistical learning",
  "    with a knowledge-based approach - A case study in intensive care  ",
  "    monitoring. International Conference on Machine Learning (ICML), 1999.",
  "[5] T. Joachims, Learning to Classify Text Using Support Vector",
  "    Machines: Methods, Theory, and Algorithms. Dissertation, Kluwer,",
  "    2002.",
  "",
  "",
  "",
  "-------------------- SVM-light classify help -----------------------------",
  "",
  "SVM-light V5.00: Support Vector Machine, classification module     30.06.02",
  "",
  "Copyright: Thorsten Joachims, thorsten@ls8.cs.uni-dortmund.de",
  "",
  "This software is available for non-commercial use only. It must not",
  "be modified and distributed without prior permission of the author.",
  "The author is not responsible for implications from the use of this",
  "software.",
  "",
  "   usage: svm_classify [options] example_file model_file output_file",
  "",
  "options: -h         -> this help",
  "         -v [0..3]  -> verbosity level (default 2)",
  "         -f [0,1]   -> 0: old output format of V1.0",
  "                    -> 1: output the value of decision function (default)",
  "",
  "",
  "",
  "--------------------------------------------------------------------------",
  "Significant programming contributions by: ",
  "",
  "  Jeff W. Prescott, William A. Curtis, Ziad Saad, Rick Reynolds, ",
  "  R. Cameron Craddock, Jonathan M. Lisinski, and  Stephen M. LaConte ",
  "",
  "Original version written by JP and SL, August 2006 ",
  "Released to general public, July 2007 ",
  "",
  "Questions/Comments/Bugs - email slaconte@vtc.vt.edu ",
  "",
  "",
  "Reference:",
  "LaConte, S., Strother, S., Cherkassky, V. and Hu, X. 2005. Support vector",
  "    machines for temporal classification of block design fMRI data. ",
  "    NeuroImage, 26, 317-329.",
  "",
  "Specific to real-time fMRI:",
  "S. M. LaConte. (2011). Decoding fMRI brain states in real-time. ",
  "    NeuroImage, 56:440-54.",
  "S. M. LaConte, S. J. Peltier, and X. P. Hu. (2007). Real-time fMRI using ",
  "brain-state classification. Hum Brain Mapp, 208:1033\u20131044. ",
  "",
  "Please also consider to reference:",
  "T. Joachims, Making Large-Scale SVM Learning Practical.",
  "     Advances in Kernel Methods - Support Vector Learning,",
  "     B. Schoelkopf and C. Burges and A. Smola (ed.), MIT Press, 1999.",
  "",
  "RW Cox. AFNI: Software for analysis and visualization of",
  "    functional magnetic resonance neuroimages.",
  "    Computers and Biomedical Research, 29:162-173, 1996.",
  ""
 ],
 "params": [
  {
   "param_range": [
    816,
    821
   ],
   "help_range": [
    821,
    974
   ]
  },
  {
   "param_range": [
    983,
    992
   ],
   "help_range": [
    751,
    806
   ]
  },
  {
   "param_range": [
    1057,
    1062
   ],
   "help_range": [
    821,
    860
   ]
  },
  {
   "param_range": [
    1110,
    1117
   ],
   "help_range": [
    1117,
    1211
   ]
  },
  {
   "param_range": [
    1220,
    1229
   ],
   "help_range": [
    751,
    806
   ]
  },
  {
   "param_range": [
    1294,
    1301
   ],
   "help_range": [
    1301,
    1313
   ]
  },
  {
   "param_range": [
    1323,
    1328
   ],
   "help_range": [
    821,
    860
   ]
  },
  {
   "param_range": [
    1376,
    1383
   ],
   "help_range": [
    1383,
    1489
   ]
  },
  {
   "param_range": [
    1498,
    1507
   ],
   "help_range": [
    751,
    806
   ]
  },
  {
   "param_range": [
    1572,
    1579
   ],
   "help_range": [
    1301,
    1313
   ]
  },
  {
   "param_range": [
    1601,
    1606
   ],
   "help_range": [
    821,
    860
   ]
  },
  {
   "param_range": [
    1654,
    1661
   ],
   "help_range": [
    1661,
    1778
   ]
  },
  {
   "param_range": [
    1787,
    1796
   ],
   "help_range": [
    751,
    806
   ]
  },
  {
   "param_range": [
    1861,
    1868
   ],
   "help_range": [
    1301,
    1313
   ]
  },
  {
   "param_range": [
    1890,
    1895
   ],
   "help_range": [
    1895,
    2056
   ]
  },
  {
   "param_range": [
    2065,
    2074
   ],
   "help_range": [
    751,
    806
   ]
  },
  {
   "param_range": [
    2139,
    2146
   ],
   "help_range": [
    1301,
    1313
   ]
  },
  {
   "param_range": [
    2168,
    2173
   ],
   "help_range": [
    2173,
    2964
   ]
  },
  {
   "param_range": [
    2965,
    2970
   ],
   "help_range": [
    3002,
    3169
   ]
  },
  {
   "param_range": [
    3171,
    3180
   ],
   "help_range": [
    3180,
    3243
   ]
  },
  {
   "param_range": [
    3246,
    3251
   ],
   "help_range": [
    3251,
    3970
   ]
  },
  {
   "param_range": [
    3973,
    3985
   ],
   "help_range": [
    3985,
    4104
   ]
  },
  {
   "param_range": [
    4106,
    4118
   ],
   "help_range": [
    4137,
    4852
   ]
  },
  {
   "param_range": [
    4854,
    4861
   ],
   "help_range": [
    4861,
    5607
   ]
  },
  {
   "param_range": [
    5609,
    5616
   ],
   "help_range": [
    5640,
    6062
   ]
  },
  {
   "param_range": [
    6093,
    6095
   ],
   "help_range": [
    6106,
    6195
   ]
  },
  {
   "param_range": [
    6225,
    6227
   ],
   "help_range": [
    6238,
    6325
   ]
  },
  {
   "param_range": [
    6355,
    6357
   ],
   "help_range": [
    6368,
    6460
   ]
  },
  {
   "param_range": [
    6490,
    6492
   ],
   "help_range": [
    6503,
    6595
   ]
  },
  {
   "param_range": [
    6597,
    6612
   ],
   "help_range": [
    6612,
    6726
   ]
  },
  {
   "param_range": [
    6728,
    6734
   ],
   "help_range": [
    6734,
    6779
   ]
  },
  {
   "param_range": [
    6782,
    6787
   ],
   "help_range": [
    6787,
    7172
   ]
  },
  {
   "param_range": [
    7174,
    7181
   ],
   "help_range": [
    7181,
    7589
   ]
  },
  {
   "param_range": [
    7590,
    7596
   ],
   "help_range": [
    7623,
    8301
   ]
  },
  {
   "param_range": [
    8303,
    8315
   ],
   "help_range": [
    8315,
    8615
   ]
  },
  {
   "param_range": [
    8616,
    8624
   ],
   "help_range": [
    8624,
    8888
   ]
  },
  {
   "param_range": [
    8891,
    8903
   ],
   "help_range": [
    8922,
    9954
   ]
  },
  {
   "param_range": [
    9957,
    9966
   ],
   "help_range": [
    9966,
    10105
   ]
  },
  {
   "param_range": [
    10107,
    10122
   ],
   "help_range": [
    10122,
    10228
   ]
  },
  {
   "param_range": [
    10230,
    10240
   ],
   "help_range": [
    10240,
    10662
   ]
  },
  {
   "param_range": [
    10664,
    10676
   ],
   "help_range": [
    10676,
    10844
   ]
  },
  {
   "param_range": [
    10846,
    10857
   ],
   "help_range": [
    10878,
    11280
   ]
  },
  {
   "param_range": [
    11283,
    11294
   ],
   "help_range": [
    11294,
    11879
   ]
  },
  {
   "param_range": [
    11880,
    11885
   ],
   "help_range": [
    11885,
    11912
   ]
  },
  {
   "param_range": [
    11914,
    11922
   ],
   "help_range": [
    11922,
    12678
   ]
  },
  {
   "param_range": [
    12688,
    12690
   ],
   "help_range": [
    12690,
    12738
   ]
  },
  {
   "param_range": [
    12748,
    12750
   ],
   "help_range": [
    12750,
    12889
   ]
  },
  {
   "param_range": [
    12899,
    12901
   ],
   "help_range": [
    12901,
    13008
   ]
  },
  {
   "param_range": [
    13018,
    13020
   ],
   "help_range": [
    13020,
    13107
   ]
  },
  {
   "param_range": [
    13117,
    13119
   ],
   "help_range": [
    13119,
    13304
   ]
  },
  {
   "param_range": [
    13314,
    13316
   ],
   "help_range": [
    13316,
    13445
   ]
  },
  {
   "param_range": [
    13455,
    13457
   ],
   "help_range": [
    13457,
    13587
   ]
  },
  {
   "param_range": [
    13597,
    13599
   ],
   "help_range": [
    13599,
    13689
   ]
  },
  {
   "param_range": [
    13699,
    13701
   ],
   "help_range": [
    13703,
    13838
   ]
  },
  {
   "param_range": [
    13848,
    13850
   ],
   "help_range": [
    13850,
    13975
   ]
  },
  {
   "param_range": [
    13985,
    13987
   ],
   "help_range": [
    13987,
    14213
   ]
  },
  {
   "param_range": [
    14223,
    14225
   ],
   "help_range": [
    14225,
    14768
   ]
  },
  {
   "param_range": [
    14778,
    14780
   ],
   "help_range": [
    14780,
    14857
   ]
  },
  {
   "param_range": [
    14867,
    14869
   ],
   "help_range": [
    14869,
    14925
   ]
  },
  {
   "param_range": [
    14935,
    14937
   ],
   "help_range": [
    14937,
    15113
   ]
  },
  {
   "param_range": [
    15123,
    15125
   ],
   "help_range": [
    15125,
    15242
   ]
  },
  {
   "param_range": [
    15252,
    15254
   ],
   "help_range": [
    15254,
    15377
   ]
  },
  {
   "param_range": [
    15387,
    15389
   ],
   "help_range": [
    15389,
    15523
   ]
  },
  {
   "param_range": [
    15533,
    15535
   ],
   "help_range": [
    15535,
    15823
   ]
  },
  {
   "param_range": [
    15833,
    15835
   ],
   "help_range": [
    15835,
    15957
   ]
  },
  {
   "param_range": [
    15967,
    15969
   ],
   "help_range": [
    15969,
    17509
   ]
  },
  {
   "param_range": [
    17519,
    17521
   ],
   "help_range": [
    17521,
    17560
   ]
  },
  {
   "param_range": [
    17570,
    17572
   ],
   "help_range": [
    17572,
    18913
   ]
  }
 ]
}