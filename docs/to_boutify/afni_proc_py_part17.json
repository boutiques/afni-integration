{"helptext": ["               default: yes", "", "            By default, if the results directory already exists, the script", "            will terminate before doing any processing.  Set this option to", "            'no' to remove that check.", "", "        -check_setup_errors yes/no : terminate on setup errors", "", "                e.g. -check_setup_errors yes", "                default: no", "", "            Have the script check $status after each command in the setup", "            processing block.  It is preferable to run the script using the", "            -e option to tcsh (as suggested), but maybe the user does not wish", "            to do so.", "", "        -copy_anat ANAT         : copy the ANAT dataset to the results dir", "", "                e.g. -copy_anat Elvis/mprage+orig", "", "            This will apply 3dcopy to copy the anatomical dataset(s) to the", "            results directory.  Note that if a +view is not given, 3dcopy will", "            attempt to copy +acpc and +tlrc datasets, also.", "", "            See also '3dcopy -help'.", "", "        -copy_files file1 ...   : copy file1, etc. into the results directory", "", "                e.g. -copy_files glt_AvsB.txt glt_BvsC.1D glt_eat_cheese.txt", "                e.g. -copy_files contrasts/glt_*.txt", "", "            This option allows the user to copy some list of files into the", "            results directory.  This would happen before the tcat block, so", "            such files may be used for other commands in the script (such as", "            contrast files in 3dDeconvolve, via -regress_opts_3dD).", "", "        -do_block BLOCK_NAME ...: add extra blocks in their default positions", "", "                e.g. -do_block despike ricor", "                e.g. -do_block align", "", "            With this option, any 'optional block' can be applied in its", "            default position.  This includes the following blocks, along with", "            their default positions:", "", "                despike : first (between tcat and tshift)", "                ricor   : just after despike (else first)", "                align   : before tlrc, before volreg", "                tlrc    : after align, before volreg", "                empty   : NO DEFAULT, cannot be applied via -do_block", "", "            Any block not included in -blocks can be added via this option", "            (except for 'empty').", "", "            See also '-blocks', as well as the \"PROCESSING BLOCKS\" section of", "            the -help output.", "", "        -dsets dset1 dset2 ...  : (REQUIRED) specify EPI run datasets", "", "                e.g. -dsets Elvis_run1+orig Elvis_run2+orig Elvis_run3+orig", "                e.g. -dsets Elvis_run*.HEAD", "", "            The user must specify the list of EPI run datasets to analyze.", "            When the runs are processed, they will be written to start with", "            run 1, regardless of whether the input runs were just 6, 7 and 21.", "", "            Note that when using a wildcard it is essential for the EPI", "            datasets to be alphabetical, as that is how the shell will list", "            them on the command line.  For instance, epi_run1+orig through", "            epi_run11+orig is not alphabetical.  If they were specified via", "            wildcard their order would end up as run1 run10 run11 run2 ...", "", "            Note also that when using a wildcard it is essential to specify", "            the datasets suffix, so that the shell doesn't put both the .BRIK", "            and .HEAD filenames on the command line (which would make it twice", "            as many runs of data).", "", "        -dsets_me_echo dset1 dset2 ...  : specify ME datasets for one echo", "                                          (all runs with each option)", "", "           These examples might correspond to 3 echoes across 4 runs.", "", "                e.g. -dsets_me_echo epi_run*.echo_1+orig.HEAD", "                     -dsets_me_echo epi_run*.echo_2+orig.HEAD", "                     -dsets_me_echo epi_run*.echo_3+orig.HEAD", "", "                e.g. -dsets_me_echo r?.e1.nii", "                     -dsets_me_echo r?.e2.nii", "                     -dsets_me_echo r?.e3.nii", "", "                e.g. -dsets_me_echo r1.e1.nii r2.e1.nii r3.e1.nii r4.e1.nii", "                     -dsets_me_echo r1.e2.nii r2.e2.nii r3.e2.nii r4.e2.nii", "                     -dsets_me_echo r1.e3.nii r2.e3.nii r3.e3.nii r4.e3.nii", "", "            This option is convenient when there are more runs than echoes.", "", "            When providing multi-echo data to afni_proc.py, doing all echoes", "            of all runs at once seems messy and error prone.  So one must", "            provide either one echo at a time (easier if there are more runs)", "            or one run at a time (easier if there are fewer runs).", "", "            With this option:", "", "               - use one option per echo (as opposed to per run, below)", "               - each option use should list all run datasets for that echo", "", "            For example, if there are 7 runs and 3 echoes, use 3 options, one", "            per echo, and pass the 7 runs of data for that echo in each.", "", "            See also -dsets_me_run.", "            See also -echo_times and -reg_echo.", "", "        -dsets_me_run dset1 dset2 ...   : specify ME datasets for one run", "                                          (all echoes with each option)", "", "           These examples might correspond to 4 echoes across 2 runs.", "", "                e.g. -dsets_me_run epi_run1.echo_*+orig.HEAD", "                     -dsets_me_run epi_run2.echo_*+orig.HEAD", "", "                e.g. -dsets_me_run r1.e*.nii", "                     -dsets_me_run r2.e*.nii", "", "                e.g. -dsets_me_run r1.e1.nii r1.e2.nii r1.e3.nii r1.e4.nii", "                     -dsets_me_run r2.e1.nii r2.e2.nii r2.e3.nii r2.e4.nii", "", "            This option is convenient when there are more echoes than runs.", "", "            When providing multi-echo data to afni_proc.py, doing all echoes", "            of all runs at once seems messy and error prone.  So one must", "            provide either one echo at a time (easier if there are more runs)", "            or one run at a time (easier if there are fewer runs).", "", "            With this option:", "", "               - use one option per run (as opposed to per echo, above)", "               - each option use should list all echo datasets for that run", "", "            For example, if there are 2 runs and 4 echoes, use 2 options, one", "            per run, and pass the 4 echoes of data for that run in each.", "", "            See also -dsets_me_echo.", "            See also -echo_times and -reg_echo.", "", "        -echo_times TE1 TE2 TE3 ... : specify echo-times for ME data processing", "", "                e.g. -echo_times 20 30.5 41.2", "", "            Use this option to specify echo times, if they are needed for the", "            'combine' processing block (OC/ME-ICA/tedana).", "", "            See also -combine_method.", "", "        -execute                : execute the created processing script", "", "            If this option is applied, not only will the processing script be", "            created, but it will then be executed in the \"suggested\" manner,", "            such as via:", "", "                tcsh -xef proc.sb23 |& tee output.proc.sb23", "", "            Note that it will actually use the bash format of the command,", "            since the system command (C and therefore python) uses /bin/sh.", "", "                tcsh -xef proc.sb23 2>&1 | tee output.proc.sb23", "", "        -gen_epi_review SCRIPT_NAME : specify script for EPI review", "", "                e.g. -gen_epi_review review_orig_EPI.txt", "", "            By default, the proc script call"], "params": [{"param_range": [1000, 1011], "help_range": [992, 1498]}, {"param_range": [1508, 1517], "help_range": [1500, 2361]}, {"param_range": [2371, 2377], "help_range": [2363, 3428]}, {"param_range": [3438, 3444], "help_range": [3430, 3708]}, {"param_range": [3730, 3736], "help_range": [3709, 3770]}, {"param_range": [3792, 3798], "help_range": [3771, 3879]}, {"param_range": [3901, 3907], "help_range": [3880, 3925]}, {"param_range": [3947, 3953], "help_range": [3926, 4048]}, {"param_range": [4070, 4076], "help_range": [4049, 4124]}, {"param_range": [4146, 4152], "help_range": [4125, 4991]}, {"param_range": [5001, 5007], "help_range": [4993, 5271]}, {"param_range": [5293, 5299], "help_range": [5272, 5378]}, {"param_range": [5400, 5406], "help_range": [5379, 5499]}, {"param_range": [5521, 5527], "help_range": [5500, 6366]}], "previous": "afni_proc.py_part16.json", "next": "afni_proc.py_part18.json"}