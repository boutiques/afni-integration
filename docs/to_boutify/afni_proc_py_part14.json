{"helptext": ["ove", "         -align_opts_aea -check_flip", "         -align_opts_aea -cost lpc+ZZ -giant_move -resample off", "         -align_opts_aea -skullstrip_opts -blur_fwhm 2", "", "    3. Testing alignment with align_epi_anat.py directly.", "", "       When having alignment problems, it may be more efficient to copy the", "       anat and EPI alignment base to a new directory, figure out a good cost", "       function or other options, and then apply them in a new afni_proc.py", "       command.", "", "       For testing purposes, it helps to test many cost functions at once.", "       Besides the cost specified by -cost, other cost functions can be applied", "       via -multi_cost.  This is efficient, since all of the other processing", "       does not need to be repeated.  For example:", "", "         align_epi_anat.py -anat2epi                    \\", "                -anat subj99_anat+orig                  \\", "                -epi pb01.subj99.r01.tshift+orig        \\", "                -epi_base 0 -volreg off -tshift off     \\", "                -giant_move                             \\", "                -cost lpc -multi_cost lpa lpc+ZZ mi", "", "       That adds -giant_move, and uses the basic lpc cost function along with", "       3 additional cost functions (lpa, lpc+ZZ, mi).  The result is 4 new", "       anatomies aligned to the EPI, 1 per cost function:", "", "               subj99_anat_al+orig         - cost func lpc      (see -cost opt)", "               subj99_anat_al_lpa+orig     - cost func lpa         (additional)", "               subj99_anat_al_lpc+ZZ+orig  - cost func lpc+ZZ      (additional)", "               subj99_anat_al_mi+orig      - cost func mi          (additional)", "", "       Also, if part of the dataset gets clipped in the case of -giant_move,", "       consider the align_epi_anat.py option '-resample off'.", "", "    --------------------------------------------------", "    WARP TO TLRC NOTE: ~2~", "", "    afni_proc.py can now apply a +tlrc transformation to the EPI data as part", "    of the volreg step via the option '-volreg_tlrc_warp'.  Note that it can", "    also align the EPI and anatomy at the volreg step via '-volreg_align_e2a'.", "", "    Manual Talairach transformations can also be applied, but separately, after", "    volreg.  See '-volreg_tlrc_adwarp'.", "", "    This tlrc transformation is recommended for many reasons, though some are", "    not yet implemented.  Advantages include:", "", "        - single interpolation of the EPI data", "", "            Done separately, volume registration, EPI to anat alignment and/or", "            the +tlrc transformation interpolate the EPI data 2 or 3 times.  By", "            combining these transformations into a single one, there is no", "            resampling penalty for the alignment or the warp to standard space.", "", "            Thanks to D Glen for the steps used in align_epi_anat.py.", "", "        - EPI time series become directly comparable across subjects", "", "            Since the volreg output is now in standard space, there is already", "            voxel correspondence across subjects with the EPI data.", "", "        - group masks and/or atlases can be applied to the EPI data without", "          additional warping", "", "            It becomes trivial to extract average time series data over ROIs", "            from standard atlases, say.", "", "            This could even be done automatically with afni_proc.py, as part", "            of the single-subject processing stream (not yet implemented).", "            One would have afni_proc.py extract average time series (or maybe", "            principal components) from all the ROIs in a dataset and apply", "            them as regressors of interest or of no interest.", "", "        - with 3dBlurToFWHM, using an AlphaSim look-up table might be possible", "", "            Since the blur and data grid could both be isotropic and integral,", "            and since the transformation could depend on a known anatomy (such", "            as the N27 Colin brain or icbm_452), it would be easy to create a", "            look-up table of AlphaSim results (so users would not actually need", "            to run it).", "", "            The known numbers would correspond to a cluster size (each for a", "            given, common voxel-wise threshold).  This correction could then", "            be applied automatically.  Again, not yet implemented...", "", "        - no interpolation of statistics", "", "            If the user wishes to include statistics as part of the group", "            analysis (e.g. using 3dMEMA.R), this warping becomes more needed.", "            Warping to standard space *after* statistics are generated is not", "            terribly valid.", "", "    --------------------------------------------------", "    RETROICOR NOTE: ~2~", "", "    ** Cardiac and respiratory regressors must be created from an external", "       source, such as the RetroTS.m matlab program written by Z Saad.  The", "       input to that would be the 2+ signals.  The output would be a single", "       file per run, containing 13 or more regressors for each slice.  That", "       set of output files would be applied here in afni_proc.py.", "", "    Removal of cardiac and respiratory regressors can be done using the 'ricor'", "    processing block.  By default, this would be done after 'despike', but", "    before any other processing block.", "", "    These card/resp signals would be regressed out of the MRI data in the", "    'ricor' block, after which processing would continue normally. In the final", "    'regress' block, regressors for slice 0 would be applied (to correctly", "    account for the degrees of freedom and also to remove residual effects).", "        --> This is now only true when using '-regress_apply_ricor yes'.", "            The default as of 30 Jan 2012 is to not include them in the final", "            regression (since degrees of freedom are really not important for a", "            subsequent correlation analysis).", "", "    Users have the option of removing the signal \"per-run\" or \"across-runs\".", "", "    Example R1: 7 runs of data, 13 card/resp regressors, process \"per-run\"", "", "        Since the 13 regressors are processed per run, the regressors can have", "        different magnitudes each run.  So the 'regress' block will actually", "        get 91 extra regressors (13 regressors times 7 runs each).", "", "    Example R2: process \"across-run\"", "", "        In this case the regressors are catenated across runs when they are", "        removed from the data.  The major difference between this and \"per-run\"", "        is that now only 1 best fit magnitude is applied per regressor (not the", "        best for each run).  So there would be only the 13 catenated regressors", "        for slice 0 added to the 'regress' block.", "", "    Those analyzing resting-state data might prefer the per-run method, as it", "    would remove more variance and degrees of freedom might not be as valuable.", "", "    Those analyzing a normal signal model might prefer doing it across-runs,", "    giving up only 13 degrees of freedom, and helping not to over-model the", "    data.", "", "    ** The minimum options would be specifying the 'ricor' block (preferably", "       after despike), along with -ricor_regs and -ricor_regress_method.", "", "    Example R3: afni_proc.py option usage:", "", "        Provide additional options to afni_proc.py to apply the despike and", "        ricor blocks (which will be the first 2 blocks by default), with each", "        regressor named 'slibase*.1D' going across all runs, and where the", "        first 3 TRs are removed from each run (matching -tcat_remove_first_trs,", "        most likely).", "", "            -do_block despike ricor", "            -ricor_regs slibase*.1D", "            -ricor_regress_method across-runs", "            -ricor_regs_nfirst 3", "", "    --------------------------------------------------", "    RUNS OF DIFFERENT LENGTHS NOTE: ~2~", "", "    In the case that the EPI datasets are not all of the same length, here", "    are some issues that may come up, listed by relevant option:", "", "        -volreg_align_to        OK, as of version 1.49.", "", "        -ricor_regress_method   OK, as of version 3.05.", "", "        -regress_polort         Probably no big deal.", "                                If this option is not used, then the degree of", "                                polynomial used for the baseline will come from", "                                the first run.  Only 1 polort may be applied.", "", "        -regress_est_blur_epits OK, as of version 1.49.", "", "     *  -regress_use_stim_files This may fail, as make_stim_times.py is not", "                                currently prepared to handle runs of different", "                                lengths.", "", "        -regress_censor_motion  OK, as of version 2.14", "", "     * probably will be f"], "params": [{"param_range": [1000, 1011], "help_range": [984, 7382]}, {"param_range": [7396, 7405], "help_range": [-87650, -87615]}, {"param_range": [7432, 7443], "help_range": [7420, 7501]}], "previous": "afni_proc.py_part13.json", "next": "afni_proc.py_part15.json"}