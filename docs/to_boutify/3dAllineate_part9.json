{"helptext": ["),", "                   write them to the 1D file 'q', then exit. (For you, Zman)", "                  * N.B.: If -fineblur is used, that amount of smoothing", "                          will be applied prior to the -allcostX evaluations.", "                          The parameters are the rotation, shift, scale,", "                          and shear values, not the affine transformation", "                          matrix. An identity matrix could be provided as", "                          \"0 0 0  0 0 0  1 1 1  0 0 0\" for instance or by", "                          using the word \"IDENTITY\"", "", "===========================================================================", "", "Modifying '-final wsinc5'", "-------------------------", " * The windowed (tapered) sinc function interpolation can be modified", "     by several environment variables.  This is expert-level stuff, and", "     you should understand what you are doing if you use these options.", "     The simplest way to use these would be on the command line, as in", "       -DAFNI_WSINC5_RADIUS=9 -DAFNI_WSINC5_TAPERFUN=Hamming", "", " * AFNI_WSINC5_TAPERFUN lets you choose the taper function.", "     The default taper function is the minimum sidelobe 3-term cosine:", "       0.4243801 + 0.4973406*cos(PI*x) + 0.0782793*cos(2*PI*x)", "     If you set this environment variable to 'Hamming', then the", "     minimum sidelobe 2-term cosine will be used instead:", "       0.53836 + 0.46164*cos(PI*x)", "     Here, 'x' is between 0 and 1, where x=0 is the center of the", "     interpolation mask and x=1 is the outer edge.", " ++  Unfortunately, the 3-term cosine doesn't have a catchy name; you can", "       find it (and many other) taper functions described in the paper", "         AH Nuttall, Some Windows with Very Good Sidelobe Behavior.", "         IEEE Trans. ASSP, 29:84-91 (1981).", "       In particular, see Fig.14 and Eq.36 in this paper.", "", " * AFNI_WSINC5_TAPERCUT lets you choose the start 'x' point for tapering:", "     This value should be between 0 and 0.8; for example, 0 means to taper", "     all the way from x=0 to x=1 (maximum tapering).  The default value", "     is 0.  Setting TAPERCUT to 0.5 (say) means only to taper from x=0.5", "     to x=1; thus, a larger value means that fewer points are tapered", "     inside the interpolation mask.", "", " * AFNI_WSINC5_RADIUS lets you choose the radius of the tapering window", "     (i.e., the interpolation mask region).  This value is an integer", "     between 3 and 21.  The default value is 5 (which used to be the", "     ONLY value, thus 'wsinc5').  RADIUS is measured in voxels, not mm.", "", " * AFNI_WSINC5_SPHERICAL lets you choose the shape of the mask region.", "     If you set this value to 'Yes', then the interpolation mask will be", "     spherical; otherwise, it defaults to cubical.", "", " * The Hamming taper function is a little faster than the 3-term function,", "     but will have a little more Gibbs phenomenon.", " * A larger TAPERCUT will give a little more Gibbs phenomenon; compute", "     speed won't change much with this parameter.", " * Compute time goes up with (at least) the 3rd power of the RADIUS; setting", "     RADIUS to 21 will be VERY slow.", " * Visually, RADIUS=3 is similar to quintic interpolation.  Increasing", "     RADIUS makes the interpolated images look sharper and more well-", "     defined.  However, values of RADIUS greater than or equal to 7 appear", "     (to Zhark's eagle eye) to be almost identical.  If you really care,", "     you'll have to experiment with this parameter yourself.", " * A spherical mask is also VERY slow, since the cubical mask allows", "     evaluation as a tensor product.  There is really no good reason", "     to use a spherical mask; I only put it in for experimental purposes.", "** For most users, there is NO reason to ever use these environment variables", "     to modify wsinc5.  You should only do this kind of thing if you have a", "     good and articulable reason!  (Or if you really like to screw around.)", "** The wsinc5 interpolation function is parallelized using OpenMP, which", "     makes its usage moderately tolerable.", "", "===========================================================================", "", "Hidden experimental cost functionals:", "-------------------------------------", "   sp   *OR*  spearman        = Spearman [rank] Correlation", "   je   *OR*  jointentropy    = Joint Entropy [H(b,s)]", "   lss  *OR*  signedPcor      = Signed Pearson Correlation", "   lpc  *OR*  localPcorSigned = Local Pearson Correlation Signed", "   lpa  *OR*  localPcorAbs    = Local Pearson Correlation Abs", "   lpc+ *OR*  localPcor+Others= Local Pearson Signed + Others", "   ncd  *OR*  NormCompDist    = Normalized Compression Distance", "", "Notes for the new [Feb 2010] lpc+ cost functional:", "--------------------------------------------------", " * The cost functional named 'lpc+' is a combination of several others:", "     lpc + hel*0.4 + crA*0.4 + nmi*0.2 + mi*0.2 + ov*0.4", "   ++ 'hel', 'crA', 'nmi', and 'mi' are the histogram-based cost", "      functionals also available as standalone options.", "   ++ 'ov' is a measure of the overlap of the automasks of the base and", "      source volumes; ov is not available as a standalone option.", " * The purpose of lpc+ is to avoid situations where the pure lpc cost", "   goes wild; this especially happens if '-source_automask' isn't used.", "   ++ Even with lpc+, you should use '-source_automask+2' (say) to be safe.", " * You can alter the weighting of the extra functionals by giving the", "   option in the form (for example)", "     '-lpc+hel*0.5+nmi*0+mi*0+crA*1.0+ov*0.5'", " * The quotes are needed to prevent the shell from wild-card expanding", "   the '*' character.", "   --> You can now use ':' in place of '*' to avoid this wildcard problem:", "         -lpc+hel:0.5+nmi:0+mi:0+crA:1+ov:0.5+ZZ", " * Notice the weight factors FOLLOW the name of the extra functionals.", "   ++ If you want a weight to be 0 or 1, you have to provide for that", "      explicitly -- if you leave a weight off, then it will get its", "      default value!", "   ++ The order of the weight factor names is unimportant here:", "        '-lpc+hel*0.5+nmi*0.8' == '-lpc+nmi*0.8+hel*0.5'", " * Only the 5 functionals listed (hel,crA,nmi,mi,ov) can be used in '-lpc+'.", " * In addition, if you want the initial alignments to be with '-lpc+' and", "   then finish the Final alignment with pure '-lpc', you can indicate this", "   by putting 'ZZ' somewhere in the option string, as in '-lpc+ZZ'.", " * This stuff should be considered really experimental at this moment!", "", "Cost functional descriptions (for use with -allcost output):", "------------------------------------------------------------", "   ls  :: 1 - abs(Pearson correlation coefficient)", "   sp  :: 1 - abs(Spearman correlation coefficient)", "   mi  :: - Mutual Information = H(base,source)-H(base)-H(source)", "   crM :: 1 - abs[ CR(base,source) * CR(source,base) ]", "   nmi :: 1/Normalized MI = H(base,source)/[H(base)+H(source)]", "   je  :: H(base,source) = joint entropy of image pair", "   hel :: - Hellinger distance(base,source)", "   crA :: 1 - abs[ CR(base,source) + CR(source,base) ]", "   crU :: CR(source,base) = Var(source|base) / Var(source)", "   lss :: Pearson correlation coefficient between image pair", "   lpc :: nonlinear average of Pearson cc over local neighborhoods", "   lpa :: 1 - abs(lpc)", "   lpc+:: lpc + hel + mi + nmi + crA + overlap", "   ncd :: mutual compressibility (via zlib) -- doesn't work yet", "", " * N.B.: Some cost functional values (as printed out above)", "   are negated from their theoretical descriptions (e.g., 'hel')", "   so that the best image alignment will be found when the cost", "   is minimized.  See the descriptions above and the references", "   below for more details for each functional.", "", " * For more information about the 'lpc' functional, see", "     ZS Saad, DR Glen, G Chen, MS Beauchamp, R Desai, RW Cox.", "       A new method for improving functional-to-structural", "       MRI alignment using local Pearson correlation.", "       NeuroImage 44: 839-848, 2009.", "     http://dx.doi.org/10.1016/j.neuroimage.2008.09.037", "     https://afni.nimh.nih.gov/sscc/rwcox/papers/LocalPearson2009.pdf", "   The '-blok' option can be used to control the regions", "   (size and shape) used to compute the local correlations.", " *** Using the 'lpc' functional wisely requires the use of", "     a proper weight volume.  We HIGHLY recommend you use", "     the align_epi_anat.py script if you want to use this", "     cost functional!  Otherwise, you are likely to get", "     less than optimal results (and then swear at us unjustly).", "", " * For more information about the 'cr' functionals, see", "     http://en.wikipedia.org/wiki/Correlation_ratio", "   Note that CR(x,y) is not the same as CR(y,x), which", "   is why there are symmetrized versions of it available.", "", " * For more information about the 'mi', 'nmi', and 'je'", "   cost functionals, see", "     http://en.wikipedia.org/wiki/Mutual_information", "     http://en.wikipedia.org/wiki/Joint_entropy", "     http://www.cs.jhu.edu/~cis/cista/746/papers/mutual_info_survey.pdf", "", " * For more information about the 'hel' functional, see", "     http://en.wikipedia.org/wiki/Hellinger_distance", "", " * Some cost functionals (e.g., 'mi', 'cr', 'hel') are", "   computed by creating a 2D joint histogram of the", "   base and source image pair.  Various options above", "   (e.g., '-histbin', etc.) can be used to control the", "   number of bins used in the histogram on each axis.", "   (If you care to control the program in such detail!)", "", " * Minimization of the chosen cost functional is done via", "   the NEWUOA software, described in detail in", "     MJD Powell. 'The NEWUOA software for unconstrained", "       optimization without derivatives.' In: GD Pillo,", "       M Roma (Eds), Large-Scale Nonlinear Optimization.", "       Springer, 2006.", "     http://www.damtp.cam.ac.uk/user/na/NA_papers/NA2004_08.pdf", "", "===========================================================================", "", " -nwarp type = Experimental nonlinear warping:", "", "              ***** Note that these '-nwarp' options are superseded  *****", "              ***** by the AFNI program 3dQwarp,  which does a more  *****", "              ***** accurate and better and job of nonlinear warping *****", "              ***** ------ Zhark the Warper ------ July 2013 ------- *****", "", "              * At present, the only 'type' is 'bilinear',", "                as in 3dWarpDrive, with 39 parameters.", "              * I plan to implement more complicated nonlinear", "                warps in the future, someday ....", "              * -nwarp can only be applied to a source dataset", "                that has a single sub-brick!", "              * -1Dparam_save and -1Dparam_apply work with", "                bilinear warps; see the Notes for more information.", "        ==>>*** Nov 2010: I have now added the following polynomial", "                warps: 'cubic', 'quintic', 'heptic', 'nonic' (using", "                3rd, 5th, 7th, and 9th order Legendre "], "params": [{"param_range": [1000, 1020], "help_range": [1022, 9710]}], "previous": "3dAllineate_part8.json", "next": "3dAllineate_part10.json"}